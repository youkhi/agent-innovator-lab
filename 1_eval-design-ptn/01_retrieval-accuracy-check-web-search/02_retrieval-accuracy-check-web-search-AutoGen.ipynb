{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Retrieval-score Check and Web search with [AutoGen](https://github.com/microsoft/autogen)\n",
    "\n",
    "This sample demonstrates how to evaluate the retrieval score of a RAG application and how to use the AutoGen library to search the web for relevant information.\n",
    "\n",
    "> âœ¨ **_Note_** <br>\n",
    "> Please check the Azure AI Agent Capability in [quick start page](https://learn.microsoft.com/en-us/azure/ai-services/agents/quickstart?pivots=programming-language-python-azure)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Configure a Python virtual environment for 3.10 or later:\n",
    "\n",
    "1.  open the Command Palette (Ctrl+Shift+P).\n",
    "1.  Search for Python: Create Environment.\n",
    "1.  select Venv / Conda and choose where to create the new environment.\n",
    "1.  Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "## Set up your environment\n",
    "\n",
    "Git clone the repository to your local machine.\n",
    "\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/Azure/rag-innovator-lab\n",
    "```\n",
    "\n",
    "Create a virtual environment and install the required packages.\n",
    "```bash\n",
    "python3 -m venv your_env_name\n",
    "source your_env_name/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¨ Current Support and Limitations (as of 2025-01-12)\n",
    "- Check the available models for bing grounding. Grounding with Bing Search only works with the following Azure OpenAI models: gpt-3.5-turbo-0125, gpt-4-0125-preview, gpt-4-turbo-2024-04-09, gpt-4o-0513 https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/bing-grounding?tabs=python&pivots=overview\n",
    "- Check the region support for the Azure AI Evaluation SDK. https://learn.microsoft.com/en-us/azure/ai-studio/concepts/evaluation-metrics-built-in?tabs=warning#region-support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get packages\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, SingleThreadedAgentRuntime, message_handler\n",
    "from autogen_core import DefaultTopicId, default_subscription, type_subscription\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import BingGroundingTool\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from autogen_core import (\n",
    "    MessageContext,\n",
    "    RoutedAgent,\n",
    "    SingleThreadedAgentRuntime,\n",
    "    TopicId,\n",
    "    TypeSubscription,\n",
    "    message_handler,\n",
    "    type_subscription,\n",
    ")\n",
    "from autogen_core.models import LLMMessage, ChatCompletionClient, SystemMessage, UserMessage, AssistantMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_core.tools import FunctionTool, Tool, ToolSchema\n",
    "from typing_extensions import Annotated\n",
    "from typing import List\n",
    "from autogen_core.tool_agent import ToolAgent, tool_agent_caller_loop\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "aoai_api_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "aoai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-06-01\")\n",
    "aoai_chat_deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "aoai_embedding_deployment_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "azure_openai_embedding_dimensions = int(os.getenv(\"AZURE_OPENAI_EMBEDDING_DIMENSIONS\", 1536))\n",
    "bing_connnection_name = os.getenv(\"BING_CONNECTION_NAME\")\n",
    "azure_ai_pjt_connection_str = os.getenv(\"AZURE_AI_PROJECT_CONNECTION_STR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Fun activities and attractions in Cornwall for tourists\"\n"
     ]
    }
   ],
   "source": [
    "# Query rewrite - Langchain based implementation \n",
    "from langchain_openai import AzureChatOpenAI \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = AzureChatOpenAI (\n",
    "    deployment_name=aoai_chat_deployment_name, \n",
    "    azure_endpoint=aoai_api_endpoint,\n",
    "    api_version=azure_openai_api_version,\n",
    "    openai_api_key=aoai_api_key,\n",
    "    )\n",
    "\n",
    "rewriter_prompt_template = \"\"\"\n",
    "Generate search keyword from a user question \n",
    "to be more specific, detailed, and likely to retrieve relevant information, allowing for a more accurate response through web search.\n",
    "Don't include the additional context from the user question.\n",
    "\n",
    "User question: {user_question}\n",
    "Revised web search query:\n",
    "\"\"\"\n",
    "\n",
    "rewriter_prompt = ChatPromptTemplate.from_template(rewriter_prompt_template)\n",
    "rewriter_chain = rewriter_prompt | llm | StrOutputParser()\n",
    "\n",
    "user_question =\"Tell me some fun things I can do in Cornwall\"\n",
    "\n",
    "search_query = rewriter_chain.invoke({\"user_question\": user_question})\n",
    "print(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n",
    "    source: str\n",
    "\n",
    "@dataclass\n",
    "class ClassifiedMessage:\n",
    "    intent: str\n",
    "    content: str\n",
    "    source: str\n",
    "\n",
    "default_topic_type = \"default\"\n",
    "general_type = \"GeneralAgent\"\n",
    "websearch_type = \"WebSearchAgent\"\n",
    "user_topic_type = \"User\"\n",
    "retrieve_topic_type = \"RetrieveAgent\"\n",
    "groundness_topic_type = \"EvalAgent\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the azclient\n",
    "aoai_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=aoai_api_endpoint,\n",
    "    model = aoai_chat_deployment_name,\n",
    "    api_version=azure_openai_api_version,\n",
    "    api_key=aoai_api_key\n",
    ")\n",
    "\n",
    "from pydantic import BaseModel\n",
    "class IntentType(BaseModel):\n",
    "    type: str\n",
    "\n",
    "# Step 1: Create an client object which will contain the connection string\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    # conn_str='Your Azure AI Foundation Connection String',\n",
    "    # copied from your Azure AI Foundry project.\n",
    "    conn_str=azure_ai_pjt_connection_str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@type_subscription(topic_type=default_topic_type)\n",
    "class IntentRouterAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"A Intent classification agent.\")\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"\n",
    "                    You are an expert at routing a user question to LLM or vectorstore or websearch.\n",
    "                    The LLM covers casual topic such as greeting, small talks.\n",
    "                    Use the LLM for questions on casual topics.\n",
    "                    The vectorstore contains documents related to hotel information in New York.\n",
    "                    Use the vectorstore for questions on the hotel related topics. For all else, websearch.\n",
    "                    response inent_type such as LLM, vectorstore, or websearch.\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "        self._model_client = model_client\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_question(self, message: UserMessage, ctx: MessageContext) -> None:\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{message.content}\")\n",
    "        prompt = f\"User question: {message.content}\"\n",
    "        llm_result = await self._model_client.create(\n",
    "            messages=[self._system_message, UserMessage(content=prompt, source=self.id.key)],\n",
    "            extra_create_args={\"response_format\": IntentType},\n",
    "            cancellation_token=ctx.cancellation_token\n",
    "        )\n",
    "        response = llm_result.content\n",
    "        assert isinstance(response, str)\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{response}\")\n",
    "        \n",
    "        await self.publish_message(ClassifiedMessage(intent=json.loads(response)[\"type\"], content=prompt, source=self.id.key), topic_id=TopicId(type=retrieve_topic_type, source=\"default\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@type_subscription(topic_type=retrieve_topic_type)\n",
    "class GeneralAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"A general agent.\")\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"\n",
    "                    You are an helper agent that can answer general questions.\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "        self._model_client = model_client\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_question(self, message: ClassifiedMessage, ctx: MessageContext) -> None:\n",
    "        print(message)\n",
    "        if(message.intent == \"LLM\"):\n",
    "            prompt = message.content\n",
    "            llm_result = await self._model_client.create(\n",
    "                messages=[self._system_message, UserMessage(content=prompt, source=self.id.key)],\n",
    "                cancellation_token=ctx.cancellation_token,\n",
    "            )\n",
    "            response = llm_result.content\n",
    "            assert isinstance(response, str)\n",
    "            print(f\"{'-'*80}\\n{self.id.type}:\\n{response}\")\n",
    "            \n",
    "            await self.publish_message(AssistantMessage(content=response, source=self.id.key), topic_id=TopicId(type=user_topic_type, source=self.id.key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and connect a new Grounding with Bing Search resource\n",
    "> âœ¨ **_Note_** <br>\n",
    "> Your usage of Grounding with Bing Search may incur costs. See the pricing page for details. [pricing](https://www.microsoft.com/en-us/bing/apis/grounding-pricing)\n",
    "\n",
    "1. Create a new Grounding with Bing Search resource in the Azure portal, and select the different fields in the creation form. Make sure you create this Grounding with Bing Search resource in the same resource group as your Azure AI Agent, AI Project, and other resources.\n",
    "![bing grounding](https://learn.microsoft.com/en-us/azure/ai-services/agents/media/tools/bing/resource-azure-portal.png#lightbox)\n",
    "2. Select the Grounding with Bing Search resource you have created and copy any of the API keys.\n",
    "![copy keys](https://learn.microsoft.com/en-us/azure/ai-services/agents/media/tools/bing/key-resource-azure-portal.png#lightbox)\n",
    "3. Go to the Azure AI Foundry > management center > Create Connection > API key \n",
    "- Endpoint: https://api.bing.microsoft.com/\n",
    "- Key: YOUR_API_KEY\n",
    "- Connection name: YOUR_CONNECTION_NAME. This name will be used in the notebook to connect to the Bing Search resource.\n",
    "- Access: you can choose either this project only or shared to all projects.\n",
    "4. Copy your connection name and paste it in the .env file.\n",
    "5. Copy your project connection string and paste it in the .env file.\n",
    "![copy project string](../images/portal-connection-string.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Enable the Grounding with Bing search tool\n",
    "# Azure Open AI connectionì´ ë§ì€ ê²½ìš° ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë‹ˆ ì£¼ì˜ \n",
    "# https://github.com/Azure/azure-sdk-for-python/issues/38921\n",
    "\n",
    "\n",
    "bing_connection = project_client.connections.get(\n",
    "    # connection_name='Your Bing Connection Name'\n",
    "    connection_name=bing_connnection_name\n",
    ")\n",
    "\n",
    "conn_id = bing_connection.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To bing grounding connection Test\n",
    "# once you test the connection, you need to restart the kernel to use the new connection in the other code block\n",
    "\n",
    "bing = BingGroundingTool(connection_id=conn_id)\n",
    "\n",
    "agent = project_client.agents.create_agent(\n",
    "    model=aoai_chat_deployment_name,\n",
    "    name=\"my-assistant\",\n",
    "    instructions=\"\"\"\n",
    "        web search\n",
    "    \"\"\",\n",
    "    tools=bing.definitions,\n",
    "    headers={\"x-ms-enable-preview\": \"true\"}\n",
    ")\n",
    "print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "# Create thread for communication\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "# Create message to thread\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"ì‚¼ì„±ì „ì CES 2025 ëª¨ë‹ˆí„° ì‹ ëª¨ë¸\",\n",
    ")\n",
    "\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_core.tools import FunctionTool, ToolSchema\n",
    "\n",
    "# Step 3: Create agent using project client with the bing tool and process assistant run\n",
    "async def bing_search_tool(query: str) -> str:\n",
    "    print(\"This is Bing for Azure AI Agent Service .......\")\n",
    "    bing = BingGroundingTool(connection_id=conn_id)\n",
    "    print(f\"query ID: {query}\")\n",
    "    print(project_client)\n",
    "        \n",
    "    \n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=aoai_chat_deployment_name,\n",
    "        name=\"bing-search-assistant\",\n",
    "        instructions=\"\"\"\n",
    "            Your only tool is websearch_tool - use it to find information.\n",
    "            You make only one search call at a time.\n",
    "            Once you have the results, you never do calculations based on them.\n",
    "        \"\"\",\n",
    "        tools=bing.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"}\n",
    "    )\n",
    "    print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create thread for communication\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "    # Create message to thread\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=query,\n",
    "    )\n",
    "    print(f\"SMS: {message}\")\n",
    "    # Create and process agent run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "    # Delete the assistant when done\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")\n",
    "\n",
    "    # Fetch and log all messages\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(\"Messages:\"+ messages[\"data\"][0][\"content\"][0][\"text\"][\"value\"])\n",
    "    return messages[\"data\"][0][\"content\"][0][\"text\"][\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@type_subscription(topic_type=retrieve_topic_type)\n",
    "class WebSearchUseAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient, tool_schema: List[ToolSchema], tool_agent_type: str) -> None:\n",
    "        super().__init__(\"Use tools to solve tasks.\")\n",
    "        self._model_client = model_client\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"\n",
    "                You are a tool usage agent who can delegate your task to the ToolAgent.\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "        self._tool_schema = tool_schema\n",
    "        self._tool_agent_id = AgentId(tool_agent_type, self.id.key)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_question(self, message: ClassifiedMessage, ctx: MessageContext) -> None:\n",
    "        if(message.intent == \"websearch\"):\n",
    "            \n",
    "            # Create a session of messages.\n",
    "            session: List[LLMMessage] = [UserMessage(content=message.content, source=\"user\")]\n",
    "            # Run the caller loop to handle tool calls.\n",
    "            messages = await tool_agent_caller_loop(\n",
    "                self,\n",
    "                tool_agent_id=self._tool_agent_id,\n",
    "                model_client=self._model_client,\n",
    "                input_messages=session,\n",
    "                tool_schema=self._tool_schema,\n",
    "                cancellation_token=ctx.cancellation_token,\n",
    "            )\n",
    "\n",
    "            # Return the final response.\n",
    "            assert isinstance(messages[-1].content, str)\n",
    "            await self.publish_message(AssistantMessage(content=messages[-1].content, source=self.id.key), topic_id=TopicId(type=user_topic_type, source=self.id.key))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@type_subscription(topic_type=user_topic_type)\n",
    "class UserAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"A user agent that outputs the final copy to the user.\")\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_final_copy(self, message: AssistantMessage, ctx: MessageContext) -> None:\n",
    "        print(f\"\\n{'-'*80}\\n{self.id.type} received final copy:\\n{message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='User')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "\n",
    "tools: List[Tool] = [FunctionTool(bing_search_tool, description=\"web search tool\")]\n",
    "\n",
    "await IntentRouterAgent.register(runtime, type=default_topic_type, factory=lambda: IntentRouterAgent(model_client=aoai_client))\n",
    "\n",
    "await GeneralAgent.register(runtime, type=general_type, factory=lambda: GeneralAgent(model_client=aoai_client))\n",
    "\n",
    "await ToolAgent.register(runtime, \"tool_executor_agent\", lambda: ToolAgent(\"tool_executor_agent\", tools))\n",
    "\n",
    "await WebSearchUseAgent.register(runtime, type=websearch_type, factory=lambda: WebSearchUseAgent(aoai_client, [tool.schema for tool in tools], \"tool_executor_agent\"))\n",
    "\n",
    "await UserAgent.register(runtime, type=user_topic_type, factory=lambda: UserAgent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "default:\n",
      "ì‚¼ì„±ì „ì CES 2025 ëª¨ë‹ˆí„° ì‹ ëª¨ë¸\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "default:\n",
      "{\"type\":\"websearch\"}\n",
      "ClassifiedMessage(intent='websearch', content='User question: ì‚¼ì„±ì „ì CES 2025 ëª¨ë‹ˆí„° ì‹ ëª¨ë¸', source='default')\n",
      "This is Bing for Azure AI Agent Service .......\n",
      "query ID: ì‚¼ì„±ì „ì CES 2025 ëª¨ë‹ˆí„° ì‹ ëª¨ë¸\n",
      "<azure.ai.projects._patch.AIProjectClient object at 0x7f3fc39f3e50>\n",
      "Created agent, ID: asst_idILSFOvwT3GVA1sobIV5KEY\n",
      "Created thread, ID: thread_dQtDTtIwGPWjgOhCBiGSgEr1\n",
      "SMS: {'id': 'msg_4dguem1NYgsOwWjNVyZS6TsP', 'object': 'thread.message', 'created_at': 1736556043, 'assistant_id': None, 'thread_id': 'thread_dQtDTtIwGPWjgOhCBiGSgEr1', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'ì‚¼ì„±ì „ì CES 2025 ëª¨ë‹ˆí„° ì‹ ëª¨ë¸', 'annotations': []}}], 'attachments': [], 'metadata': {}}\n",
      "Run finished with status: completed\n",
      "Deleted agent\n",
      "Messages:ì‚¼ì„±ì „ìëŠ” CES 2025ì—ì„œ ì´ 5ì¢…ì˜ ìƒˆë¡œìš´ ëª¨ë‹ˆí„°ë¥¼ ê³µê°œí–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ëª¨ë‹ˆí„° ëª¨ë¸ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì œí’ˆë“¤ì´ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ìŠ¤ë§ˆíŠ¸ ëª¨ë‹ˆí„° M9**: AI ê¸°ëŠ¥ì´ ëŒ€í­ í–¥ìƒëœ 32í˜• ìŠ¤ë§ˆíŠ¸ ëª¨ë‹ˆí„°.\n",
      "2. **ì˜¤ë””ì„¸ì´ OLED G8**: ì—…ê³„ ìµœì´ˆë¡œ 27í˜• í¬ê¸°ì— 4K í•´ìƒë„ì™€ 240Hz ì£¼ì‚¬ìœ¨ì„ ì§€ì›í•˜ëŠ” OLED ëª¨ë‹ˆí„°.\n",
      "3. **ì˜¤ë””ì„¸ì´ OLED G6**: ê³ ì„±ëŠ¥ OLED ê²Œì´ë° ëª¨ë‹ˆí„°.\n",
      "4. **ì˜¤ë””ì„¸ì´ 3D**: ìƒˆë¡œìš´ 3D ê¸°ìˆ ì´ ì ìš©ëœ ëª¨ë‹ˆí„°.\n",
      "5. **ë·°í”¼ë‹ˆí‹° S8**: ìƒì„¸ ëª¨ë¸ëª…ê³¼ í•¨ê»˜ ê³ ê¸‰ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ëª¨ë‹ˆí„°ã€0â€ sourceã€‘ã€1â€ sourceã€‘ã€2â€ sourceã€‘.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "User received final copy:\n",
      "ì‚¼ì„±ì „ìëŠ” CES 2025ì—ì„œ ì´ 5ì¢…ì˜ ìƒˆë¡œìš´ ëª¨ë‹ˆí„°ë¥¼ ê³µê°œí–ˆìŠµë‹ˆë‹¤. ì£¼ìš” ì‹ ëª¨ë¸ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ìŠ¤ë§ˆíŠ¸ ëª¨ë‹ˆí„° M9**: AI ê¸°ëŠ¥ì´ ëŒ€í­ í–¥ìƒëœ 32í˜• ìŠ¤ë§ˆíŠ¸ ëª¨ë‹ˆí„°ì…ë‹ˆë‹¤.\n",
      "2. **ì˜¤ë””ì„¸ì´ OLED G8**: ì—…ê³„ ìµœì´ˆë¡œ 27í˜• í¬ê¸°ì— 4K í•´ìƒë„ì™€ 240Hz ì£¼ì‚¬ìœ¨ì„ ì§€ì›í•˜ëŠ” OLED ëª¨ë‹ˆí„°ì…ë‹ˆë‹¤.\n",
      "3. **ì˜¤ë””ì„¸ì´ OLED G6**: ê³ ì„±ëŠ¥ OLED ê²Œì´ë° ëª¨ë‹ˆí„°ì…ë‹ˆë‹¤.\n",
      "4. **ì˜¤ë””ì„¸ì´ 3D**: ìƒˆë¡œìš´ 3D ê¸°ìˆ ì´ ì ìš©ëœ ëª¨ë‹ˆí„°ì…ë‹ˆë‹¤.\n",
      "5. **ë·°í”¼ë‹ˆí‹° S8**: ìƒì„¸ ëª¨ë¸ëª…ê³¼ í•¨ê»˜ ê³ ê¸‰ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ëª¨ë‹ˆí„°ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì‹ ëª¨ë¸ë“¤ì€ ê°ê¸° ë‹¤ë¥¸ ì²¨ë‹¨ ê¸°ìˆ ê³¼ ë””ìì¸ì„ ë„ì…í•˜ì—¬ ì‚¬ìš©ìë“¤ì—ê²Œ ë‹¤ì–‘í•œ ì„ íƒì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "runtime.start()\n",
    "\n",
    "await runtime.publish_message(UserMessage(content=\"ì‚¼ì„±ì „ì CES 2025 ëª¨ë‹ˆí„° ì‹ ëª¨ë¸\", source=\"User\"), topic_id=TopicId(type=default_topic_type, source=\"default\"))\n",
    "\n",
    "await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
