{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138d2cb2",
   "metadata": {},
   "source": [
    "# LLM with Web Search and Crawl\n",
    "\n",
    "Code to crawl the top n pages of a Google search result and serve them to LLM in order to utilize rich context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5623f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True) \n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version=\"2024-08-01-preview\"\n",
    ")\n",
    "\n",
    "CHAT_COMPLETIONS_MODEL = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13ea70",
   "metadata": {},
   "source": [
    "bs4 or scrapy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897bb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import scrapy\n",
    "from bs4 import BeautifulSoup\n",
    "import httpx\n",
    "import asyncio\n",
    "from urllib.parse import urljoin\n",
    "from azure.ai.projects.models import MessageRole, BingGroundingTool\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_CSE_ID = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "BING_GROUNDING_PROJECT_CONNECTION_STRING = os.getenv(\"BING_GROUNDING_PROJECT_CONNECTION_STRING\")\n",
    "BING_GROUNDING_AGENT_ID = os.getenv(\"BING_GROUNDING_AGENT_ID\")\n",
    "BING_GROUNDING_AGENT_MODEL_DEPLOYMENT_NAME = os.getenv(\"BING_GROUNDING_AGENT_MODEL_DEPLOYMENT_NAME\")\n",
    "BING_GROUNDING_CONNECTION_NAME = os.getenv(\"BING_GROUNDING_CONNECTION_NAME\")\n",
    "# Web search mode: \"google\" or \"bing\"\n",
    "# it can be changed when users want to use different search engine\n",
    "WEB_SEARCH_MODE = os.getenv(\"WEB_SEARCH_MODE\")\n",
    "\n",
    "def extract_text_and_tables_by_bs4(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    # Extract main text\n",
    "    paragraphs = [p.get_text().strip() for p in soup.find_all(\"p\") if p.get_text().strip()]\n",
    "    text = \"\\n\".join(paragraphs)\n",
    "    return text\n",
    "\n",
    "\n",
    "async def extract_text_and_tables_async(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    async with httpx.AsyncClient(timeout=3, follow_redirects=True) as client:\n",
    "        try:\n",
    "            response = await client.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            # Handle 302 redirect manually if follow_redirects fails\n",
    "            if e.response.status_code == 302 and \"location\" in e.response.headers:\n",
    "                redirect_url = e.response.headers[\"location\"]\n",
    "                if not redirect_url.startswith(\"http\"):\n",
    "                    # handle relative redirects\n",
    "                    redirect_url = urljoin(url, redirect_url)\n",
    "                try:\n",
    "                    response = await client.get(redirect_url, headers=headers)\n",
    "                    response.raise_for_status()\n",
    "                except Exception as e2:\n",
    "                    print(f\"Redirect request failed: {e2}\")\n",
    "                    return \"\"\n",
    "            else:\n",
    "                print(f\"Request failed: {e}\")\n",
    "                return \"\"\n",
    "        except httpx.HTTPError as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "        selector = scrapy.Selector(text=response.text)\n",
    "        paragraphs = [p.strip() for p in selector.css('p::text').getall() if p.strip()]\n",
    "        text = \"\\n\".join(paragraphs)\n",
    "        return text\n",
    "\n",
    "async def add_context_async(top_urls = []):\n",
    "    async def gather_contexts():\n",
    "        tasks = [extract_text_and_tables_async(url) for url in top_urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return results\n",
    "    return await gather_contexts()\n",
    "\n",
    "def google_search(query, num=5, search_type=\"web\"):\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"key\": GOOGLE_API_KEY,\n",
    "        \"cx\": GOOGLE_CSE_ID,\n",
    "        \"num\": num, \n",
    "        \"locale\": \"ko\",  # í•œêµ­ì–´ë¡œ ê²€ìƒ‰\n",
    "        \"siteSearch\": \"samsung.com\",\n",
    "        \"siteSearchFilter\": \"e\"\n",
    "    }\n",
    "    \n",
    "    if search_type == \"image\":\n",
    "        params[\"searchType\"] = \"image\"\n",
    "        \n",
    "    response = requests.get(url, params=params)\n",
    "    results = response.json()\n",
    "    return results.get(\"items\", [])\n",
    "\n",
    "def bing_grounding_search(query, num=5, search_type=\"web\"):\n",
    "    try:\n",
    "        creds = DefaultAzureCredential()\n",
    "        \n",
    "        project_client = AIProjectClient.from_connection_string(\n",
    "            credential=creds,\n",
    "            conn_str=BING_GROUNDING_PROJECT_CONNECTION_STRING,\n",
    "        )\n",
    "        \n",
    "        agent_id = BING_GROUNDING_AGENT_ID\n",
    "        \n",
    "        if not agent_id:\n",
    "            print(\"BING_GROUNDING_AGENT_ID is not set. Create new agent...\")\n",
    "            connection_name = BING_GROUNDING_CONNECTION_NAME\n",
    "            \n",
    "            bing_connection = project_client.connections.get(\n",
    "                connection_name=connection_name,\n",
    "            )\n",
    "            conn_id = bing_connection.id\n",
    "            \n",
    "            bing = BingGroundingTool(connection_id=conn_id)\n",
    "            \n",
    "            \n",
    "            agent = project_client.agents.create_agent(\n",
    "                model=BING_GROUNDING_AGENT_MODEL_DEPLOYMENT_NAME,\n",
    "                name=\"temporary-bing-agent\",\n",
    "                instructions=\"\"\"\n",
    "                    Search for product information and images exclusively about Samsung products. Get all contents from the website as much as you can. Don't include the url link in the response.\n",
    "                    Only respond with information from trusted sources: samsung.com.\n",
    "                    Prioritize data from samsung.com whenever available to ensure accuracy and reliability.\n",
    "                    If information is not found on samsung.com, supplement with tistory.com, but always indicate the source.\n",
    "                    Avoid using data from any other websites or unverified sources.\n",
    "                \"\"\",\n",
    "                tools=bing.definitions,\n",
    "                headers={\"x-ms-enable-preview\": \"true\"}\n",
    "            )\n",
    "            agent_id = agent.id\n",
    "            print(f\"New agent created. Agent ID: {agent_id}\")\n",
    "        else:\n",
    "            print(f\"Existing agent ID: {agent_id}\")\n",
    "            try:\n",
    "                agent = project_client.agents.get_agent(agent_id)\n",
    "            except Exception as agent_error:\n",
    "                print(f\"Failed to retrieve agent: {agent_error}\")\n",
    "                return []\n",
    "\n",
    "        thread = project_client.agents.create_thread()\n",
    "        \n",
    "        message = project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=f\"Search the web for: {query}. Return only the top {num} most relevant results as a list.\",\n",
    "        )\n",
    "\n",
    "        print(f\"Message created, ID: {message.id}\")\n",
    "\n",
    "        run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=agent.id)\n",
    "        \n",
    "        if run.status == \"failed\":\n",
    "            print(f\"Execution failed: {run.last_error}\")\n",
    "            return []\n",
    "        print(f\"Run completed successfully. Status: {run.status}\")\n",
    "        results = []\n",
    "        response_message = project_client.agents.list_messages(thread_id=thread.id).get_last_message_by_role(\n",
    "            MessageRole.AGENT\n",
    "        )\n",
    "        if response_message.url_citation_annotations:\n",
    "            # Extract content text and annotations\n",
    "            print(response_message)\n",
    "            if response_message.content:\n",
    "                for content_item in response_message[\"content\"]:\n",
    "                    if content_item[\"type\"] == \"text\":\n",
    "                        text_content = content_item[\"text\"][\"value\"]\n",
    "                        print(\"Extracted Text Content:\")\n",
    "                        print(text_content)\n",
    "                        results.append({\"content\": text_content})\n",
    "            \n",
    "            if response_message.url_citation_annotations:\n",
    "                for annotation in response_message.url_citation_annotations:\n",
    "                    if annotation[\"type\"] == \"url_citation\":\n",
    "                        url_citation = annotation[\"url_citation\"]\n",
    "                        url = url_citation[\"url\"]\n",
    "                        title = url_citation[\"title\"]\n",
    "                        # set the results same as google json format\n",
    "                        results.append({\"url_citation\":{\"link\": url, \"title\": title}})\n",
    "\n",
    "        if not BING_GROUNDING_AGENT_ID and hasattr(agent, 'id'):\n",
    "            try:\n",
    "                print(f\"Deleting temporary agent with ID: {agent.id}\")\n",
    "                project_client.agents.delete_agent(agent.id)\n",
    "                \n",
    "            except Exception as delete_error:\n",
    "                print(f\"Error deleting agent: {delete_error}\")\n",
    "\n",
    "        return results if results else []\n",
    "    except Exception as e:\n",
    "        print(f\"Bing Grounding error : {e}\")\n",
    "        return []\n",
    "\n",
    "def web_search(query, num=5, search_type=\"web\"):\n",
    "    \"\"\"í™˜ê²½ ë³€ìˆ˜ì— ë”°ë¼ Google Search API ë˜ëŠ” Bing Groundingì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ìˆ˜í–‰\"\"\"\n",
    "    \n",
    "    if WEB_SEARCH_MODE == \"bing\":\n",
    "        print(f\"Bing Grounding ê²€ìƒ‰ ì‚¬ìš©: {query}\")\n",
    "        try:\n",
    "            return bing_grounding_search(query['llm_query'], num, search_type)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Bing Grounding ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    else:\n",
    "        print(f\"Google Search API ì‚¬ìš©: {query}\")\n",
    "        return google_search(query['web_search'], num, search_type)\n",
    "\n",
    "       \n",
    "QUERY_REWRITE_PROMPT = \"\"\"\n",
    "            <<ì§€ì‹œë¬¸>>\n",
    "            ë„ˆëŠ” êµ¬ê¸€ ê²€ìƒ‰ê³¼ LLM ì§ˆì˜ ìµœì í™” ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì„ ë‘ ê°€ì§€ ëª©ì ì— ë§ê²Œ ì¬ì‘ì„±í•´.\n",
    "\n",
    "            1. Web Searchìš© Query Rewrite:\n",
    "            - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì‹¤ì œ ê²€ìƒ‰ ì—”ì§„ ê²€ìƒ‰ì°½ì— ì…ë ¥í•  ìˆ˜ ìˆë„ë¡, ëª…í™•í•˜ê³  ê°„ê²°í•œ í•µì‹¬ í‚¤ì›Œë“œ ì¤‘ì‹¬ì˜ ê²€ìƒ‰ì–´ë¡œ ì¬ì‘ì„±í•´.\n",
    "            - ë¶ˆí•„ìš”í•œ ë¬¸ì¥, ë§¥ë½ ì„¤ëª…ì€ ë¹¼ê³ , ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ë§Œë“¤ì–´.\n",
    "            - í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì‚¬ìš©í•´ ê²€ìƒ‰ì˜ ì •í™•ë„ë¥¼ ë†’ì—¬.\n",
    "\n",
    "            2. LLM Queryìš© Rewrite:\n",
    "            - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ LLMì´ ë” ì˜ ì´í•´í•˜ê³  ë‹µë³€í•  ìˆ˜ ìˆë„ë¡, ë§¥ë½ê³¼ ì˜ë„ë¥¼ ëª…í™•íˆ ë“œëŸ¬ë‚´ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±í•´.\n",
    "            - í•„ìš”í•œ ê²½ìš° ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ì„¸ë¶€ ì¡°ê±´ì„ í¬í•¨í•´ì„œ ì§ˆë¬¸ì˜ ëª©ì ì´ ë¶„ëª…íˆ ë“œëŸ¬ë‚˜ë„ë¡ ë§Œë“¤ì–´.\n",
    "            - LLMì´ ë‹µë³€ì— ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ ë‹¨ì–´ë¥¼ ë°˜ë³µ ì‚¬ìš©í•´.\n",
    "\n",
    "            <<ì˜ˆì‹œ>>\n",
    "            * ì§ˆë¬¸: ì‚¼ì„±ì „ì ì œí’ˆ ì¤‘ 2êµ¬ ë§ê³  ë‹¤ë¥¸ ì¸ë•ì…˜ ì¶”ì²œí•´ì¤˜\n",
    "            * ì›¹ ê²€ìƒ‰ìš© ì¬ì‘ì„±: ì‚¼ì„±ì „ì 3êµ¬ ì´ìƒ ì¸ë•ì…˜ ì¶”ì²œ\n",
    "            * LLM ë‹µë³€ìš© ì¬ì‘ì„±: ì‚¼ì„±ì „ì ì¸ë•ì…˜ ì¤‘ 2êµ¬ ëª¨ë¸ì´ ì•„ë‹Œ, 3êµ¬ ì´ìƒ ë˜ëŠ” ë‹¤ì–‘í•œ í™”êµ¬ ìˆ˜ë¥¼ ê°€ì§„ ë‹¤ë¥¸ ì¸ë•ì…˜ ì œí’ˆì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”. ê° ëª¨ë¸ì˜ ì£¼ìš” ê¸°ëŠ¥ê³¼ ì¥ì ë„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”.\n",
    "\n",
    "            <<ì§ˆë¬¸>>\n",
    "            {user_query}\n",
    "\n",
    "            <<ì¶œë ¥í¬ë§·>>\n",
    "            ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì´ json í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´.\n",
    "            {\"web_search\": \"ì›¹ ê²€ìƒ‰ìš© ì¬ì‘ì„±\", \"llm_query\": \"LLM ë‹µë³€ìš© ì¬ì‘ì„±\"}\n",
    "        \"\"\"     \n",
    "  \n",
    "def rewrite_query_for_search_and_llm(query, client: AzureOpenAI):\n",
    "        response = client.chat.completions.create(\n",
    "            model=CHAT_COMPLETIONS_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": QUERY_REWRITE_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            temperature=0.8,\n",
    "            max_tokens=300,\n",
    "            response_format= {\"type\": \"json_object\"},\n",
    "        )\n",
    "        \n",
    "        return json.loads(response.choices[0].message.content.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "#TODO ë‚ ì”¨ë‚˜ ë‰´ìŠ¤, ê¸°íƒ€ ë‹¤ë¥¸ íŠ¹ì •ì •ë³´ëŠ” Function Call\n",
    "# inputs = [\"ë‚ ì”¨, ë‰´ìŠ¤\"] ##\n",
    "\n",
    "async def process_web_search_call(RESULTS_COUNT, input):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    contexts = [] \n",
    "    url_citations= []\n",
    "    print(f\"Original Input: {input}\")\n",
    "    \n",
    "    query_rewrite = rewrite_query_for_search_and_llm(input, client)\n",
    "    print(f\"Web Search Query: {query_rewrite['web_search']}\")\n",
    "    print(f\"LLM Query: {query_rewrite['llm_query']}\")\n",
    "\n",
    "    results = web_search(query_rewrite, RESULTS_COUNT)\n",
    "    \n",
    "    if WEB_SEARCH_MODE == \"bing\" and results and isinstance(results, list) and len(results) > 0:\n",
    "        print(f\"Web Search Results: {len(results)}\")\n",
    "        contexts = [results[i][\"content\"] for i in range(len(results)) if \"content\" in results[i]]\n",
    "        url_citations = [results[i][\"url_citation\"] for i in range(len(results)) if \"url_citation\" in results[i]]\n",
    "        \n",
    "        # top_urls = [results[i][\"link\"] for i in range(len(results))]\n",
    "        # contexts = await add_context_async(top_urls)\n",
    "    elif WEB_SEARCH_MODE == \"google\" and results and isinstance(results, list) and len(results) > 0:\n",
    "        print(f\"Web Search Results: {len(results)}\")\n",
    "        top_urls = [results[i][\"link\"] for i in range(len(results))]\n",
    "        contexts = await add_context_async(top_urls)\n",
    "    \n",
    "    else:\n",
    "        print(\"No results found or invalid response from web_search.\")\n",
    "        contexts = [] \n",
    "        url_citations= []\n",
    "\n",
    "    # for i, context in enumerate(contexts):\n",
    "    #     print(f\"Context {i+1}: {context}...\")  # Print first 1000 chars of each context\n",
    "    #     print(\"\\n--- End of Context ---\\n\")\n",
    "\n",
    "    now = datetime.now()\n",
    "    year = now.year\n",
    "    month = now.month\n",
    "    day = now.day\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "        ë„ˆëŠ” ì‚¼ì„±ì „ì ì œí’ˆ ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì±—ë´‡ì´ì•¼. \n",
    "        ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì´ëª¨ì§€ë¥¼ 1~2ê°œ í¬í•¨í•´ì„œ ì‘ì„±í•´ì¤˜. \n",
    "        contexts, url_citationsë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ í’ë¶€í•˜ê²Œ ë‹µë³€ì„ í•´ì•¼í•´. \n",
    "        ë§í¬ë¥¼ ì¶”ê°€í• ë•ŒëŠ” ì›¹ê²€ìƒ‰ì—ì„œ ì œê³µí•œ url_citationsì„ ê¸°ì¤€ìœ¼ë¡œ í•¨ê»˜ í¬í•¨í•´ì¤˜. \n",
    "        ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ë‚´ìš©ì— ëŒ€í•´ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•´ì•¼ í•´. contextsê°€ ë¶€ì¡±í•˜ë©´ ìµœì†Œí•œì˜ ì•ˆë‚´ë§Œ í•´ì¤˜. \n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "        ë„ˆëŠ” ì•„ë˜ ì œê³µí•˜ëŠ” ì›¹ê²€ìƒ‰ì—ì„œ ê²€ìƒ‰í•œ contextsë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•´ì•¼ í•´. \n",
    "        í˜„ì¬ëŠ” {year}ë…„ {month}ì›” {day}ì¼ì´ë¯€ë¡œ ìµœì‹ ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ í•´ì¤˜.\n",
    "        ì›¹ê²€ìƒ‰ì—ì„œ ì œê³µí•œ contexts: {contexts}\n",
    "        ì›¹ê²€ìƒ‰ì—ì„œ ì œê³µí•œ url_citations: {url_citations}\n",
    "        ì§ˆë¬¸: {query_rewrite['llm_query']}\n",
    "        \"\"\"\n",
    "\n",
    "    print(f\"System Prompt: {system_prompt}\")\n",
    "    print(f\"User Prompt: {user_prompt}\")\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=CHAT_COMPLETIONS_MODEL,\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                 {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        top_p=0.9,\n",
    "        max_tokens=1500\n",
    "    )\n",
    "\n",
    "    display(Markdown(response.choices[0].message.content))\n",
    "    end_time = time.time()\n",
    "    print(f\"elapsed time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4999ff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bing Grounding ê²€ìƒ‰ ì‚¬ìš©: êµ°ì—ì„œ ì œëŒ€í•œ ë‚¨ë™ìƒì—ê²Œ ì„ ë¬¼í•˜ê³  ì‹¶ì€ë° ì‚¼ì„±ì „ì TV ì¶”ì²œí•´ì¤˜\n",
      "Original Input: êµ°ì—ì„œ ì œëŒ€í•œ ë‚¨ë™ìƒì—ê²Œ ì„ ë¬¼í•˜ê³  ì‹¶ì€ë° ì‚¼ì„±ì „ì TV ì¶”ì²œí•´ì¤˜\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Search Query: ì‚¼ì„±ì „ì TV ì¶”ì²œ ë‚¨ë™ìƒ ì„ ë¬¼\n",
      "LLM Query: êµ°ì—ì„œ ì œëŒ€í•œ ë‚¨ë™ìƒì—ê²Œ ì„ ë¬¼í•˜ê¸°ì— ì í•©í•œ ì‚¼ì„±ì „ì TV ëª¨ë¸ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”. ê° ëª¨ë¸ì˜ íŠ¹ì§•ê³¼ ì¥ì ì„ ì„¤ëª…í•´ ì£¼ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\n",
      "Bing Grounding ê²€ìƒ‰ ì‚¬ìš©: ì‚¼ì„±ì „ì TV ì¶”ì²œ ë‚¨ë™ìƒ ì„ ë¬¼\n",
      "Existing agent ID: asst_1BNu5p4Wv52Cload5HkW3ZBa\n",
      "Message created, ID: msg_wkZAWcG29HZJikm9Kux61P3i\n",
      "Run completed successfully. Status: RunStatus.COMPLETED\n",
      "{'id': 'msg_16SOahwC27v6T4xNI7QZm12M', 'object': 'thread.message', 'created_at': 1747620801, 'assistant_id': 'asst_1BNu5p4Wv52Cload5HkW3ZBa', 'thread_id': 'thread_8sDzF88HwjXW30fpdaSPojzL', 'run_id': 'run_JsRW7eSvTHmDw58QFTqyMDkg', 'role': 'assistant', 'content': [{'type': 'text', 'text': {'value': '1. ì‚¼ì„±ì „ì TV ì¶”ì²œ ëª¨ë¸ ë¦¬ë·° ë° ë¹„êµ (2025ë…„) - QLED KQ65QD70AFXKR ëª¨ë¸ì´ í™”ì§ˆê³¼ ê°€ê²©ì˜ ìµœì  íƒ€í˜‘ì ìœ¼ë¡œ ì¶”ì²œë¨ã€3:0â€ sourceã€‘.\\n2. ì‚¼ì„± TV ë¼ì¸ì—… ë¹„êµ - Crystal UHD, QLED, Neo QLED, OLED ë“±ê¸‰ë³„ í™”ì§ˆ ì°¨ì´ ì„¤ëª…ã€3:1â€ sourceã€‘.\\n3. ì‚¼ì„± TVì™€ LG TV ë¹„êµ ë° ì¶”ì²œ ëª¨ë¸ TOP 5 - ë‹¤ì–‘í•œ í¬ê¸°ì™€ ìµœì‹ í˜• ê°€ì„±ë¹„ ëª¨ë¸ ì •ë¦¬ã€3:2â€ sourceã€‘.', 'annotations': [{'type': 'url_citation', 'text': 'ã€3:0â€ sourceã€‘', 'start_index': 78, 'end_index': 90, 'url_citation': {'url': 'https://nosearch.com/recommendation/pick/living/tv', 'title': 'TV ì¶”ì²œ : ì‚¼ì„±ì „ì TOP 4 ë¦¬ë·°&ë¹„êµ (2025ë…„) - nosearch.com'}}, {'type': 'url_citation', 'text': 'ã€3:1â€ sourceã€‘', 'start_index': 156, 'end_index': 168, 'url_citation': {'url': 'https://nosearch.com/contents/encyclopedia/living/tv/771', 'title': '500ê°œê°€ ë„˜ëŠ” ì‚¼ì„± TV ë„ëŒ€ì²´ ë­ê°€ ë‹¤ë¥¸ê±´ì§€ í™•ì‹¤íˆ ì•Œë ¤ë“œë¦¼(ì‚¼ì„± TV 24ë…„ ë¼ì¸ì—… ì™„ë²½ ë¹„êµ!)'}}, {'type': 'url_citation', 'text': 'ã€3:2â€ sourceã€‘', 'start_index': 226, 'end_index': 238, 'url_citation': {'url': 'https://choicemon.com/best-tv/', 'title': 'TV ì¶”ì²œ : ì‚¼ì„± & LG ë¹„êµ TOP 5 (2025 ìˆœìœ„)'}}]}}], 'attachments': [], 'metadata': {}}\n",
      "Extracted Text Content:\n",
      "1. ì‚¼ì„±ì „ì TV ì¶”ì²œ ëª¨ë¸ ë¦¬ë·° ë° ë¹„êµ (2025ë…„) - QLED KQ65QD70AFXKR ëª¨ë¸ì´ í™”ì§ˆê³¼ ê°€ê²©ì˜ ìµœì  íƒ€í˜‘ì ìœ¼ë¡œ ì¶”ì²œë¨ã€3:0â€ sourceã€‘.\n",
      "2. ì‚¼ì„± TV ë¼ì¸ì—… ë¹„êµ - Crystal UHD, QLED, Neo QLED, OLED ë“±ê¸‰ë³„ í™”ì§ˆ ì°¨ì´ ì„¤ëª…ã€3:1â€ sourceã€‘.\n",
      "3. ì‚¼ì„± TVì™€ LG TV ë¹„êµ ë° ì¶”ì²œ ëª¨ë¸ TOP 5 - ë‹¤ì–‘í•œ í¬ê¸°ì™€ ìµœì‹ í˜• ê°€ì„±ë¹„ ëª¨ë¸ ì •ë¦¬ã€3:2â€ sourceã€‘.\n",
      "Web Search Results: 4\n",
      "System Prompt: \n",
      "        ë„ˆëŠ” ì‚¼ì„±ì „ì ì œí’ˆ ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì±—ë´‡ì´ì•¼. \n",
      "        ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì´ëª¨ì§€ë¥¼ 1~2ê°œ í¬í•¨í•´ì„œ ì‘ì„±í•´ì¤˜. \n",
      "        contexts, url_citationsë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ í’ë¶€í•˜ê²Œ ë‹µë³€ì„ í•´ì•¼í•´. \n",
      "        ë§í¬ë¥¼ ì¶”ê°€í• ë•ŒëŠ” ì›¹ê²€ìƒ‰ì—ì„œ ì œê³µí•œ url_citationsì„ ê¸°ì¤€ìœ¼ë¡œ í•¨ê»˜ í¬í•¨í•´ì¤˜. \n",
      "        ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ë‚´ìš©ì— ëŒ€í•´ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•´ì•¼ í•´. contextsê°€ ë¶€ì¡±í•˜ë©´ ìµœì†Œí•œì˜ ì•ˆë‚´ë§Œ í•´ì¤˜. \n",
      "    \n",
      "User Prompt: \n",
      "        ë„ˆëŠ” ì•„ë˜ ì œê³µí•˜ëŠ” ì›¹ê²€ìƒ‰ì—ì„œ ê²€ìƒ‰í•œ contextsë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•´ì•¼ í•´. \n",
      "        í˜„ì¬ëŠ” 2025ë…„ 5ì›” 19ì¼ì´ë¯€ë¡œ ìµœì‹ ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ í•´ì¤˜.\n",
      "        ì›¹ê²€ìƒ‰ì—ì„œ ì œê³µí•œ contexts: ['1. ì‚¼ì„±ì „ì TV ì¶”ì²œ ëª¨ë¸ ë¦¬ë·° ë° ë¹„êµ (2025ë…„) - QLED KQ65QD70AFXKR ëª¨ë¸ì´ í™”ì§ˆê³¼ ê°€ê²©ì˜ ìµœì  íƒ€í˜‘ì ìœ¼ë¡œ ì¶”ì²œë¨ã€3:0â€ sourceã€‘.\\n2. ì‚¼ì„± TV ë¼ì¸ì—… ë¹„êµ - Crystal UHD, QLED, Neo QLED, OLED ë“±ê¸‰ë³„ í™”ì§ˆ ì°¨ì´ ì„¤ëª…ã€3:1â€ sourceã€‘.\\n3. ì‚¼ì„± TVì™€ LG TV ë¹„êµ ë° ì¶”ì²œ ëª¨ë¸ TOP 5 - ë‹¤ì–‘í•œ í¬ê¸°ì™€ ìµœì‹ í˜• ê°€ì„±ë¹„ ëª¨ë¸ ì •ë¦¬ã€3:2â€ sourceã€‘.']\n",
      "        ì›¹ê²€ìƒ‰ì—ì„œ ì œê³µí•œ url_citations: [{'link': 'https://nosearch.com/recommendation/pick/living/tv', 'title': 'TV ì¶”ì²œ : ì‚¼ì„±ì „ì TOP 4 ë¦¬ë·°&ë¹„êµ (2025ë…„) - nosearch.com'}, {'link': 'https://nosearch.com/contents/encyclopedia/living/tv/771', 'title': '500ê°œê°€ ë„˜ëŠ” ì‚¼ì„± TV ë„ëŒ€ì²´ ë­ê°€ ë‹¤ë¥¸ê±´ì§€ í™•ì‹¤íˆ ì•Œë ¤ë“œë¦¼(ì‚¼ì„± TV 24ë…„ ë¼ì¸ì—… ì™„ë²½ ë¹„êµ!)'}, {'link': 'https://choicemon.com/best-tv/', 'title': 'TV ì¶”ì²œ : ì‚¼ì„± & LG ë¹„êµ TOP 5 (2025 ìˆœìœ„)'}]\n",
      "        ì§ˆë¬¸: êµ°ì—ì„œ ì œëŒ€í•œ ë‚¨ë™ìƒì—ê²Œ ì„ ë¬¼í•˜ê¸°ì— ì í•©í•œ ì‚¼ì„±ì „ì TV ëª¨ë¸ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”. ê° ëª¨ë¸ì˜ íŠ¹ì§•ê³¼ ì¥ì ì„ ì„¤ëª…í•´ ì£¼ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "ë‚¨ë™ìƒì—ê²Œ ì„ ë¬¼í•˜ê¸°ì— ì í•©í•œ ì‚¼ì„±ì „ì TV ëª¨ë¸ ëª‡ ê°€ì§€ë¥¼ ì¶”ì²œë“œë¦´ê²Œìš”! ğŸ˜Š\n",
       "\n",
       "### 1. QLED KQ65QD70AFXKR\n",
       "- **íŠ¹ì§•**: QLED ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ë›°ì–´ë‚œ í™”ì§ˆì„ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ ìƒ‰ì¬í˜„ë ¥ì´ ë›°ì–´ë‚˜ê³  ë°ì€ í™˜ê²½ì—ì„œë„ ì„ ëª…í•œ í™”ë©´ì„ ë³´ì¥í•©ë‹ˆë‹¤.\n",
       "- **ì¥ì **: ê°€ê²©ê³¼ ì„±ëŠ¥ì˜ ìµœì  íƒ€í˜‘ì ìœ¼ë¡œ ì¶”ì²œë˜ë©°, ë‹¤ì–‘í•œ ì½˜í…ì¸ ë¥¼ ì¦ê¸°ê¸°ì— ì í•©í•©ë‹ˆë‹¤. íŠ¹íˆ ì˜í™”ë‚˜ ê²Œì„ì„ ì¢‹ì•„í•˜ëŠ” ë¶„ë“¤ì—ê²Œ ì´ìƒì ì…ë‹ˆë‹¤.\n",
       "- **ì •ë³´ë§í¬**: [ì‚¼ì„±ì „ì TOP 4 ë¦¬ë·°&ë¹„êµ (2025)](https://nosearch.com/recommendation/pick/living/tv)\n",
       "\n",
       "### 2. Crystal UHD TV\n",
       "- **íŠ¹ì§•**: Crystal UHDëŠ” 4K í•´ìƒë„ë¥¼ ì§€ì›í•˜ì—¬ ì„ ëª…í•˜ê³  ìƒìƒí•œ í™”ì§ˆì„ ì œê³µí•©ë‹ˆë‹¤.\n",
       "- **ì¥ì **: ìƒëŒ€ì ìœ¼ë¡œ ì €ë ´í•œ ê°€ê²©ì— ë›°ì–´ë‚œ í™”ì§ˆì„ ê²½í—˜í•  ìˆ˜ ìˆì–´ ê°€ì„±ë¹„ê°€ ì¢‹ìŠµë‹ˆë‹¤. ê²Œì„ì´ë‚˜ ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ì— ì í•©í•©ë‹ˆë‹¤.\n",
       "- **ì •ë³´ë§í¬**: [ì‚¼ì„± TV ë¼ì¸ì—… ì™„ë²½ ë¹„êµ](https://nosearch.com/contents/encyclopedia/living/tv/771)\n",
       "\n",
       "### 3. Neo QLED\n",
       "- **íŠ¹ì§•**: Mini LED ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ë”ìš± í–¥ìƒëœ ëª…ì•”ë¹„ì™€ ìƒ‰ê°ì„ ì œê³µí•©ë‹ˆë‹¤. \n",
       "- **ì¥ì **: ì˜í™” ê°ìƒì´ë‚˜ ìŠ¤í¬ì¸  ì¤‘ê³„ì—ì„œ ë›°ì–´ë‚œ í™”ë©´ í’ˆì§ˆì„ ìë‘í•©ë‹ˆë‹¤. íŠ¹íˆ, ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ë””ìì¸ì´ ë§¤ë ¥ì ì…ë‹ˆë‹¤.\n",
       "- **ì •ë³´ë§í¬**: [ì‚¼ì„± & LG ë¹„êµ TOP 5](https://choicemon.com/best-tv/)\n",
       "\n",
       "ì´ ì™¸ì—ë„ ì‚¼ì„±ì „ìëŠ” ë‹¤ì–‘í•œ TV ëª¨ë¸ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë‹ˆ, ì‚¬ìš©ìì˜ ì·¨í–¥ì— ë§ëŠ” ëª¨ë¸ì„ ì„ íƒí•´ë³´ì„¸ìš”! ê° ëª¨ë¸ì€ ì‚¬ìš© ìš©ë„ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì¶”ì²œë  ìˆ˜ ìˆìœ¼ë‹ˆ, ì˜í™” ê°ìƒì´ë‚˜ ê²Œì„ ë“± ì–´ë–¤ ìš©ë„ë¡œ ì‚¬ìš©í• ì§€ ê³ ë ¤í•´ë³´ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤. ğŸ®ğŸ“º"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 15.09 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RESULTS_COUNT = 3\n",
    "\n",
    "inputs = [\n",
    "    # \"ì‚¼ì„±ì „ì ì œí’ˆ ì¤‘ 2êµ¬ ë§ê³  ë‹¤ë¥¸ ì¸ë•ì…˜ ì¶”ì²œí•´ì¤˜\",\n",
    "    \"êµ°ì—ì„œ ì œëŒ€í•œ ë‚¨ë™ìƒì—ê²Œ ì„ ë¬¼í•˜ê³  ì‹¶ì€ë° ì‚¼ì„±ì „ì TV ì¶”ì²œí•´ì¤˜\",\n",
    "    # \"ì‚¼ì„±ì „ì 25ë…„ ì œí’ˆì´ ì‘ë…„ ëŒ€ë¹„ ì¢‹ì•„ì§„ê²ƒì€\",\n",
    "    # \"ì‚¼ì„±ì „ì JBLê³¼ í•˜ë§Œì¹´ëˆ ì°¨ì´ì ì´ ë­ì•¼\",\n",
    "    # \"ê°¤ëŸ­ì‹œ ë²„ì¦ˆ ì´ì–´ë²„ë“œ í•œìª½ì„ ìƒˆë¡œ êµ¬ë§¤í–ˆëŠ”ë° í˜ì–´ë§ ì–´ë–»ê²Œ í•˜ë‚˜ìš”\",\n",
    "    # \"ì‚¼ì„±ì „ì S25 ë¬´ê²Œê°€ S24ì™€ ë¹„êµ í–ˆì„ë•Œ ì–¼ë§ˆë‚˜ ì°¨ì´ë‚˜\"\n",
    "]\n",
    "\n",
    "\n",
    "# for input in inputs:\n",
    "#     WEB_SEARCH_MODE = \"google\"  \n",
    "#     print(f\"Google Search API ì‚¬ìš©: {input}\")\n",
    "#     await process_web_search_call(RESULTS_COUNT, input)\n",
    "\n",
    "WEB_SEARCH_MODE = \"bing\"\n",
    "\n",
    "for input in inputs:\n",
    "    print(f\"Bing Grounding ê²€ìƒ‰ ì‚¬ìš©: {input}\")\n",
    "    await process_web_search_call(RESULTS_COUNT, input)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5023d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_agentlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
