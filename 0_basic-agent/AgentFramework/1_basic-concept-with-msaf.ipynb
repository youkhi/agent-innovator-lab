{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f475a9",
   "metadata": {},
   "source": [
    "# Understand Microsoft Agent Framework with code samples\n",
    "\n",
    "----\n",
    "Microsoft Agent Framework is the open-source engine for building production-ready agentic AI applications. It unifies the enterprise-ready foundations of Semantic Kernel with the innovative orchestration patterns of AutoGen, providing a single framework for both experimentation and production deployment.\n",
    "\n",
    "| Components | Description |\n",
    "|------------|-------------|\n",
    "| **1. Chat Agents** | Core agents that handle conversational interactions using any compatible chat client (Azure OpenAI, OpenAI, Azure AI, etc.) |\n",
    "| **2. Tools & Functions** | Extensible capabilities including built-in tools (Code Interpreter, File Search, Bing Grounding) and custom function tools |\n",
    "| **3. Multi-Agent Orchestration** | Patterns for coordinating multiple agents (Sequential, Concurrent, Group Chat, Handoff, Magentic) |\n",
    "| **4. Open Standards** | Native support for MCP (Model Context Protocol), A2A (Agent-to-Agent), and OpenAPI for interoperability |\n",
    "\n",
    "![Microsoft Agent Framework](https://devblogs.microsoft.com/foundry/wp-content/uploads/sites/89/2025/09/AgentStack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35d02e5",
   "metadata": {},
   "source": [
    "## Microsoft Agent Framework Architecture\n",
    "---\n",
    "\n",
    "Microsoft Agent Framework represents the evolution and unification of Semantic Kernel and AutoGen, bringing together the best of both worlds:\n",
    "\n",
    "**Key Design Principles:**\n",
    "\n",
    "1. **Open Standards First** - Built on MCP, A2A, and OpenAPI for maximum interoperability\n",
    "2. **Research to Production Pipeline** - Cutting-edge orchestration patterns from Microsoft Research, production-ready\n",
    "3. **Extensible by Design** - Modular architecture with pluggable components\n",
    "4. **Enterprise Ready** - Built-in observability, security, durability, and human-in-the-loop support\n",
    "\n",
    "**Comparison with Semantic Kernel:**\n",
    "- Simplified agent creation without Kernel coupling\n",
    "- Native thread management built into agents\n",
    "- Inline tool registration without attribute decorators\n",
    "- Direct integration with Azure AI Foundry Agent Service\n",
    "\n",
    "**Comparison with AutoGen:**\n",
    "- Unified message types (ChatMessage with clear roles)\n",
    "- Graph-based Workflow API with checkpointing\n",
    "- Built-in OpenTelemetry observability\n",
    "- Stronger composability and durability for multi-agent systems\n",
    "\n",
    "## Learn More:\n",
    "- [Microsoft Agent Framework Documentation](https://learn.microsoft.com/en-us/agent-framework/)\n",
    "- [GitHub Repository](https://github.com/microsoft/agent-framework)\n",
    "- [Azure AI Foundry](https://ai.azure.com/)\n",
    "- [Agent Framework Blog](https://devblogs.microsoft.com/foundry/introducing-microsoft-agent-framework-the-open-source-engine-for-agentic-ai-apps/)\n",
    "\n",
    "\n",
    "This notebook will explore the core capabilities of Microsoft Agent Framework using Azure AI and Azure OpenAI as the backend services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e77081",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37a63f0",
   "metadata": {},
   "source": [
    "Install the Microsoft Agent Framework packages. The framework is modular - you can install just what you need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0ee44",
   "metadata": {},
   "source": [
    "Import required libraries for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3a8110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from typing import Annotated\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Microsoft Agent Framework core\n",
    "from agent_framework import ChatAgent, ChatMessage, TextContent, Role\n",
    "\n",
    "# Azure integrations\n",
    "from agent_framework.azure import AzureOpenAIChatClient, AzureAIAgentClient\n",
    "from azure.identity.aio import DefaultAzureCredential, AzureCliCredential\n",
    "\n",
    "# Tool decorators\n",
    "from agent_framework import ai_function\n",
    "\n",
    "load_dotenv(override=True)\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb061d",
   "metadata": {},
   "source": [
    "Configure environment variables. You can use either Azure OpenAI or Azure AI Foundry endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd443e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking environment variables...\n",
      "‚úì Azure OpenAI configuration found\n",
      "\n",
      "Using service: azure_openai\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gpt-4.1-mini'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check required environment variables\n",
    "print(\"Checking environment variables...\")\n",
    "\n",
    "# For Azure OpenAI\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "# For Azure AI Foundry\n",
    "azure_project_endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "azure_ai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "if azure_openai_endpoint and azure_openai_deployment:\n",
    "    print(\"‚úì Azure OpenAI configuration found\")\n",
    "    SERVICE_TYPE = \"azure_openai\"\n",
    "else:\n",
    "    print(\"‚ùå Missing required environment variables!\")\n",
    "    print(\"\\nFor Azure OpenAI, set:\")\n",
    "    print(\"  - AZURE_OPENAI_ENDPOINT\")\n",
    "    print(\"  - AZURE_OPENAI_API_KEY\")\n",
    "    print(\"  - AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "    print(\"\\nOR for Azure AI Foundry, set:\")\n",
    "    print(\"  - AZURE_AI_PROJECT_ENDPOINT\")\n",
    "    print(\"  - AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "    \n",
    "print(f\"\\nUsing service: {SERVICE_TYPE}\")\n",
    "azure_openai_deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f284bc6",
   "metadata": {},
   "source": [
    "# Case 1: Basic Agent Creation and Execution\n",
    "\n",
    "In Microsoft Agent Framework, creating an agent is straightforward. Unlike Semantic Kernel which requires a Kernel instance, Agent Framework agents are created directly from chat clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e4e66",
   "metadata": {},
   "source": [
    "## üß™ Case 1.1: Simple Agent with Azure OpenAI\n",
    "---\n",
    "Create a basic ChatAgent using AzureOpenAIChatClient. The agent handles thread management automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e134ca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Microsoft is a multinational technology company founded in 1975 by Bill Gates and Paul Allen, known for developing the Windows operating system and Office productivity suite. It is a global leader in software, hardware, cloud computing, and artificial intelligence services. Microsoft also produces devices like the Xbox gaming console and Surface tablets, serving both consumer and enterprise markets worldwide.\n"
     ]
    }
   ],
   "source": [
    "# Create a chat client and agent with Azure OpenAI\n",
    "azure_openai_chat_client = AzureOpenAIChatClient(\n",
    "    deployment_name=azure_openai_deployment,\n",
    "    endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    api_version=azure_openai_version\n",
    ")\n",
    "\n",
    "# Create an agent - no Kernel needed!\n",
    "agent = ChatAgent(\n",
    "    chat_client=azure_openai_chat_client,\n",
    "    instructions=\"You are a helpful assistant that provides concise, informative answers.\",\n",
    "    name=\"SimpleAssistant\"\n",
    ")\n",
    "\n",
    "# Run the agent with a simple question\n",
    "async def run_simple_agent():\n",
    "    result = await agent.run(\"Tell me about Microsoft in 3 sentences.\")\n",
    "    print(f\"Agent: {result.text}\")\n",
    "\n",
    "await run_simple_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4c219",
   "metadata": {},
   "source": [
    "## üß™ Case 1.2: Streaming Response\n",
    "---\n",
    "Agent Framework supports streaming responses for real-time output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b40307b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Agentic AI refers to artificial intelligence systems designed to act independently, make decisions, and take actions on their own to achieve specific goals‚Äîmuch like an agent. Instead of just following direct instructions, agentic AI can plan, adapt, and interact with its environment to accomplish tasks.\n"
     ]
    }
   ],
   "source": [
    "async def run_streaming_agent():\n",
    "    print(\"Agent: \", end=\"\", flush=True)\n",
    "    async for update in agent.run_stream(\"Explain what agentic AI is in simple terms.\"):\n",
    "        if update.text:\n",
    "            print(update.text, end=\"\", flush=True)\n",
    "    print()  # New line after streaming\n",
    "\n",
    "await run_streaming_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d67e4c3",
   "metadata": {},
   "source": [
    "## üß™ Case 1.3: Multi-turn Conversation with Thread\n",
    "---\n",
    "Agents automatically maintain conversation context using threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2043ff8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Nice to meet you, Alex! If you have any questions about Python programming or need help with a project, feel free to ask!\n",
      "\n",
      "Agent: Your name is Alex.\n",
      "\n",
      "Agent: You said you love Python programming.\n"
     ]
    }
   ],
   "source": [
    "async def multi_turn_conversation():\n",
    "    \n",
    "    # Create a new thread.\n",
    "    thread = agent.get_new_thread()\n",
    "    \n",
    "    response1 = await agent.run(\"My name is Alex and I love Python programming.\", thread=thread)\n",
    "    print(f\"Agent: {response1.text}\\n\")\n",
    "    \n",
    "    # Get the thread from the result\n",
    "    serialized = await thread.serialize()\n",
    "\n",
    "    # Later, deserialize and continue conversation\n",
    "    new_thread = await agent.deserialize_thread(serialized)\n",
    "    \n",
    "    # Second message - uses the same thread to maintain context\n",
    "    response2 = await agent.run(\"What's my name?\", thread=new_thread)\n",
    "    print(f\"Agent: {response2.text}\\n\")\n",
    "    \n",
    "    # Third message - agent remembers both previous exchanges\n",
    "    response3 = await agent.run(\"What programming language did I say I love?\", thread=new_thread)\n",
    "    print(f\"Agent: {response3.text}\")\n",
    "\n",
    "await multi_turn_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a440a2",
   "metadata": {},
   "source": [
    "# Case 2: Agents with Custom Tools/Functions\n",
    "---\n",
    "Agent Framework makes it easy to extend agents with custom functions using the `@ai_function` decorator. <br>\n",
    "Define custom functions and register them with the agent. No plugin wrappers needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b80208",
   "metadata": {},
   "source": [
    "### üß™ Case 2.1.1: Azure Open AI Client with Custom Function Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1ce96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: The weather in Seoul is currently sunny with a temperature of 22¬∞C.\n",
      "\n",
      "Agent: The current time in Korea Standard Time (KST) is 01:15 AM.\n"
     ]
    }
   ],
   "source": [
    "# Define custom functions using @ai_function decorator\n",
    "@ai_function(description=\"Get the current weather for a location\")\n",
    "def get_weather(location: Annotated[str, \"The city name\"]) -> str:\n",
    "    \"\"\"Returns mock weather data for the given location.\"\"\"\n",
    "    # In a real scenario, this would call a weather API\n",
    "    weather_data = {\n",
    "        \"Seoul\": \"Sunny, 22¬∞C\",\n",
    "        \"New York\": \"Cloudy, 18¬∞C\",\n",
    "        \"London\": \"Rainy, 15¬∞C\",\n",
    "        \"Tokyo\": \"Clear, 20¬∞C\"\n",
    "    }\n",
    "    return weather_data.get(location, f\"Weather data not available for {location}\")\n",
    "\n",
    "@ai_function(description=\"Get the current time in a timezone\")\n",
    "def get_time(timezone: Annotated[str, \"Timezone (e.g., 'UTC', 'EST', 'KST')\"]) -> str:\n",
    "    \"\"\"Returns mock time for the given timezone.\"\"\"\n",
    "    from datetime import datetime\n",
    "    # Simplified for demo - in production use proper timezone handling\n",
    "    return f\"Current time in {timezone}: {datetime.now().strftime('%H:%M:%S')}\"\n",
    "\n",
    "# Create an agent with these tools\n",
    "weather_agent = ChatAgent(\n",
    "    chat_client=azure_openai_chat_client,\n",
    "    instructions=\"You are a helpful assistant that can provide weather and time information.\",\n",
    "    name=\"WeatherAssistant\",\n",
    "    tools=[get_weather, get_time]\n",
    ")\n",
    "\n",
    "# Test the agent with tool calls\n",
    "async def test_tools():\n",
    "    result = await weather_agent.run(\"What's the weather like in Seoul?\")\n",
    "    print(f\"Agent: {result.text}\\n\")\n",
    "    \n",
    "    result2 = await weather_agent.run(\"What time is it in KST?\")\n",
    "    print(f\"Agent: {result2.text}\")\n",
    "\n",
    "await test_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106791d5",
   "metadata": {},
   "source": [
    "### üß™ Case 2.1.2: Azure AI Agent Client with Custom Function Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f96eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnvironmentName    HomeTenantId                          IsDefault    Name                                     State    TenantDefaultDomain    TenantDisplayName         TenantId\n",
      "-----------------  ------------------------------------  -----------  ---------------------------------------  -------  ---------------------  ------------------------  ------------------------------------\n",
      "AzureCloud         16b3c013-d300-468d-ac64-7eda0820b6d3  True         MCAPS-Hybrid-REQ-86467-2024-hyokeunchoi  Enabled  fdpo.onmicrosoft.com   Microsoft Non-Production  16b3c013-d300-468d-ac64-7eda0820b6d3\n"
     ]
    }
   ],
   "source": [
    "# Azure CLI Î°úÍ∑∏Ïù∏ÏùÄ ÌÑ∞ÎØ∏ÎÑêÏóêÏÑú Î®ºÏ†Ä ÏàòÌñâÌï¥Ï£ºÏÑ∏Ïöî:\n",
    "# az login --use-device-code\n",
    "# az account set --subscription \"your-subscription-id\"\n",
    "\n",
    "# ÌòÑÏû¨ Î°úÍ∑∏Ïù∏ ÏÉÅÌÉú Î∞è subscription ÌôïÏù∏\n",
    "!az account show --output table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26c072d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: What are today's specials?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Today's specials are:\n",
      "- Special Soup: Clam Chowder\n",
      "- Special Salad: Cobb Salad\n",
      "- Special Drink: Chai Tea\n",
      "\n",
      "Would you like to know the prices or details of any of these specials?\n",
      "\n",
      "User: How much does the Clam Chowder cost?\n",
      "Agent: The Clam Chowder costs $9.99.\n"
     ]
    }
   ],
   "source": [
    "# Menu class\n",
    "class MenuTool:\n",
    "    #Azure AI Agent doesn't need to use decorator\n",
    "    #@ai_function(description=\"Get the specials from the menu\")\n",
    "    def get_specials(self) -> str:\n",
    "        \"\"\"Returns the daily specials.\"\"\"\n",
    "        return \"\"\"\n",
    "        Special Soup: Clam Chowder\n",
    "        Special Salad: Cobb Salad\n",
    "        Special Drink: Chai Tea\n",
    "        \"\"\"\n",
    "\n",
    "    #@ai_function(description=\"Get the price of a menu item\")\n",
    "    def get_item_price(self, menu_item: Annotated[str, \"The name of the menu item\"]) -> str:\n",
    "        \"\"\"Returns the price of the requested item.\"\"\"\n",
    "        return \"$9.99\"\n",
    "\n",
    "# Create agent using Azure AI\n",
    "async def azure_ai_agent_demo():\n",
    "\n",
    "    credential = AzureCliCredential()\n",
    "    \n",
    "    # Create an instance of the tool\n",
    "    menu_tool = MenuTool()\n",
    "    async with AzureAIAgentClient(\n",
    "        async_credential=credential,\n",
    "        project_endpoint=azure_project_endpoint,\n",
    "        model_deployment_name=azure_ai_deployment\n",
    "    ) as azure_ai_agent_client:\n",
    "    \n",
    "        ai_agent = ChatAgent(\n",
    "            chat_client=azure_ai_agent_client,\n",
    "            instructions=\"You are a helpful restaurant assistant. Answer questions about the menu.\",\n",
    "            name=\"MenuAssistant\",\n",
    "            tool_choice=\"auto\",\n",
    "            tools=[menu_tool.get_specials, menu_tool.get_item_price],\n",
    "            # When conversation_id is set, store must be True for service-managed threads.\n",
    "            store=True\n",
    "        )\n",
    "    \n",
    "    # Test the agent\n",
    "    questions = [\n",
    "        \"What are today's specials?\",\n",
    "        \"How much does the Clam Chowder cost?\"\n",
    "    ]\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"\\nUser: {question}\")\n",
    "        result = await ai_agent.run(question)\n",
    "        print(f\"Agent: {result.text}\")\n",
    "\n",
    "await azure_ai_agent_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd9ded",
   "metadata": {},
   "source": [
    "### üß™ Case 2.1.3: Azure OpenAI Responses Client with Custom Function Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "253881c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Non-streaming Response ===\n",
      "\n",
      "User: What are today's specials?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Today's specials are:\n",
      "- Special Soup: Clam Chowder\n",
      "- Special Salad: Cobb Salad\n",
      "- Special Drink: Chai Tea\n",
      "\n",
      "Would you like to know the prices or details of any of these specials?\n",
      "\n",
      "User: How much does the Clam Chowder cost?\n",
      "Agent: The Clam Chowder costs $9.99.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Streaming Response ===\n",
      "\n",
      "User: What are today's specials?\n",
      "Agent: Today's specials are:\n",
      "- Special Soup: Clam Chowder\n",
      "- Special Salad: Cobb Salad\n",
      "- Special Drink: Chai Tea\n",
      "\n",
      "Would you like to know the prices or details of any of these?\n",
      "\n",
      "User: How much does the Clam Chowder cost?\n",
      "Agent: The Clam Chowder costs $9.99.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agent_framework.azure import AzureOpenAIResponsesClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "# Menu class\n",
    "class MenuTool:\n",
    "    def get_specials(self) -> str:\n",
    "        \"\"\"Returns the daily specials.\"\"\"\n",
    "        return \"\"\"\n",
    "        Special Soup: Clam Chowder\n",
    "        Special Salad: Cobb Salad\n",
    "        Special Drink: Chai Tea\n",
    "        \"\"\"\n",
    "\n",
    "    def get_item_price(self, menu_item: Annotated[str, \"The name of the menu item\"]) -> str:\n",
    "        \"\"\"Returns the price of the requested item.\"\"\"\n",
    "        return \"$9.99\"\n",
    "\n",
    "# Create agent using Azure OpenAI Responses Client\n",
    "async def azure_openai_responses_demo():\n",
    "    \"\"\"\n",
    "    Demonstrates AzureOpenAIResponsesClient with both non-streaming and streaming responses.\n",
    "    This client provides structured response generation using Azure OpenAI.\n",
    "    \"\"\"\n",
    "    \n",
    "    # For authentication, run `az login` command in terminal\n",
    "    menu_tool = MenuTool()\n",
    "    \n",
    "    # Create agent using AzureOpenAIResponsesClient\n",
    "    agent = AzureOpenAIResponsesClient(\n",
    "            endpoint=azure_openai_endpoint,\n",
    "            api_key=azure_openai_key,\n",
    "            deployment_name=azure_openai_deployment,\n",
    "            api_version=\"preview\" # Use \"preview\" for Azure OpenAI Responses. Currently, the api_version must be \"preview\".\n",
    "            ).create_agent(\n",
    "        instructions=\"You are a helpful restaurant assistant. Answer questions about the menu.\",\n",
    "        tools=[menu_tool.get_specials, menu_tool.get_item_price],\n",
    "        \n",
    "    )\n",
    "    \n",
    "    # Test questions\n",
    "    questions = [\n",
    "        \"What are today's specials?\",\n",
    "        \"How much does the Clam Chowder cost?\"\n",
    "    ]\n",
    "    \n",
    "    # 1. Non-streaming Example (get complete result at once)\n",
    "    print(\"=== Non-streaming Response ===\\n\")\n",
    "    for question in questions:\n",
    "        print(f\"User: {question}\")\n",
    "        result = await agent.run(question)\n",
    "        print(f\"Agent: {result.text}\\n\")\n",
    "    \n",
    "    print(\"-\" * 80 + \"\\n\")\n",
    "    \n",
    "    # 2. Streaming Example (get results as they are generated)\n",
    "    print(\"=== Streaming Response ===\\n\")\n",
    "    for question in questions:\n",
    "        print(f\"User: {question}\")\n",
    "        print(\"Agent: \", end=\"\", flush=True)\n",
    "        async for chunk in agent.run_stream(question):\n",
    "            if chunk.text:\n",
    "                print(chunk.text, end=\"\", flush=True)\n",
    "        print(\"\\n\")\n",
    "\n",
    "await azure_openai_responses_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65620073",
   "metadata": {},
   "source": [
    "# Case 3: Understand the differences b/w Agent Clients\n",
    "\n",
    "Take a look at the table below to understand the differences between three main agent clients in Microsoft Agent Framework: `AzureOpenAIChatClient`, `AzureAIAgentClient`, and `AzureOpenAIResponsesClient`.\n",
    "\n",
    "| Case | Client Type | Tool Used | Execution Location |\n",
    "|------|------------|-----------|-------------------|\n",
    "| **3.1** | `AzureOpenAIChatClient` | Custom `@ai_function` | **Local (subprocess)** |\n",
    "| **3.2** | `AzureAIAgentClient` | `HostedCodeInterpreterTool` | **Azure AI Service** |\n",
    "| **3.3** | `AzureOpenAIResponsesClient` | `HostedCodeInterpreterTool` | **Azure OpenAI Service** | \n",
    "\n",
    "### When to Use Each Approach:\n",
    "\n",
    "- **Use Case 3.1** when:\n",
    "  - You need full control over code execution\n",
    "  - You want to run code in your own environment\n",
    "  - You don't have access to Azure AI services\n",
    "  - You need custom execution logic (e.g., specific Python packages)\n",
    "\n",
    "- **Use Case 3.2** when:\n",
    "  - You're building enterprise applications\n",
    "  - You need managed, secure code execution\n",
    "  - You want to leverage Azure AI Foundry features\n",
    "  - You need integration with other Azure AI services\n",
    "\n",
    "- **Use Case 3.3** when:\n",
    "  - You're using Azure OpenAI Responses API\n",
    "  - You want to extract and inspect generated code\n",
    "  - You need structured response format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e67f96",
   "metadata": {},
   "source": [
    "## üß™ Case 3.1: Azure Open AI Client with function calling (runs on subprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "971b601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Calculate the first 10 numbers in the Fibonacci sequence. Provide the result as a Python list.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: The first 10 numbers in the Fibonacci sequence are: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Custom Python code execution function\n",
    "@ai_function(description=\"Execute Python code and return the result\")\n",
    "def execute_python_code(code: Annotated[str, \"Python code to execute\"]) -> str:\n",
    "    \"\"\"\n",
    "    Executes Python code in a temporary file and returns the output.\n",
    "    \n",
    "    Args:\n",
    "        code: Python code to execute\n",
    "        \n",
    "    Returns:\n",
    "        The output of the code execution or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a temporary file to store the code\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as temp_file:\n",
    "            temp_file.write(code)\n",
    "            temp_file_path = temp_file.name\n",
    "        \n",
    "        # Execute the Python code\n",
    "        result = subprocess.run(\n",
    "            ['python', temp_file_path],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5  # 5 seconds timeout for safety\n",
    "        )\n",
    "        \n",
    "        # Clean up\n",
    "        os.unlink(temp_file_path)\n",
    "        \n",
    "        # Return output or error\n",
    "        if result.returncode == 0:\n",
    "            return f\"Success:\\n{result.stdout}\" if result.stdout else \"Code executed successfully with no output\"\n",
    "        else:\n",
    "            return f\"Error:\\n{result.stderr}\"\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        os.unlink(temp_file_path)\n",
    "        return \"Error: Code execution timed out (5 seconds limit)\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "async def code_interpreter_demo_using_subprocess():\n",
    "    \n",
    "    thread = agent.get_new_thread()\n",
    "\n",
    "    code_agent = ChatAgent(\n",
    "        chat_client=azure_openai_chat_client,\n",
    "        instructions=\"You are a helpful assistant that can write and get the result of the Python code.\",\n",
    "        name=\"CodeAssistant\",\n",
    "        tools=[execute_python_code]\n",
    "    )\n",
    "    \n",
    "    # Ask the agent to solve a problem using code\n",
    "    task = \"Calculate the first 10 numbers in the Fibonacci sequence. Provide the result as a Python list.\"\n",
    "    print(f\"User: {task}\")\n",
    "    \n",
    "    result = await code_agent.run(task, thread=thread)\n",
    "    print(f\"\\nAgent: {result.text}\")\n",
    "\n",
    "await code_interpreter_demo_using_subprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031ae20",
   "metadata": {},
   "source": [
    "## üß™ Case 3.2: Azure AI Agent Client with Hosted Code Interpreter Tool (runs on server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "489e629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Calculate the first 10 numbers in the Fibonacci sequence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: The first 10 numbers in the Fibonacci sequence are:\n",
      "\n",
      "0, 1, 1, 2, 3, 5, 8, 13, 21, 34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from agent_framework import HostedCodeInterpreterTool\n",
    "\n",
    "async def code_interpreter_demo_using_subprocess():\n",
    "    credential = AzureCliCredential()\n",
    "    # Create agent with code interpreter capability\n",
    "    code_agent = ChatAgent(\n",
    "        chat_client=AzureAIAgentClient(\n",
    "            async_credential=credential,\n",
    "            project_endpoint=azure_project_endpoint,\n",
    "            model_deployment_name=azure_ai_deployment\n",
    "        ),\n",
    "        instructions=\"You are a helpful assistant that can write and execute Python code.\",\n",
    "        name=\"CodeAssistant\",\n",
    "        tools=[HostedCodeInterpreterTool()]\n",
    "    )\n",
    "    \n",
    "    # Ask the agent to solve a problem using code\n",
    "    task = \"Calculate the first 10 numbers in the Fibonacci sequence.\"\n",
    "    print(f\"User: {task}\")\n",
    "    \n",
    "    result = await code_agent.run(task)\n",
    "    print(f\"\\nAgent: {result.text}\")\n",
    "\n",
    "await code_interpreter_demo_using_subprocess()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c71b43",
   "metadata": {},
   "source": [
    "## üß™ Case 3.3: Azure OpenAI Responses Client with Hosted Code Interpreter Tool (runs on server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da5fbeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Azure OpenAI Responses Client with Hosted Code Interpreter ===\n",
      "\n",
      "User: Use code to calculate the factorial of 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: import math\n",
      "\n",
      "# Calculate the factorial of 100\n",
      "factorial_100 = math.factorial(100)\n",
      "factorial_100 The factorial of 100 is:\n",
      "\n",
      "93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000\n",
      "\n",
      "üìù Generated code:\n",
      "```python\n",
      "import math\n",
      "\n",
      "# Calculate the factorial of 100\n",
      "factorial_100 = math.factorial(100)\n",
      "factorial_100\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "User: Calculate the first 15 numbers in the Fibonacci sequence\n",
      "Agent: The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, usually starting with 0 and 1. I will calculate the first 15 numbers for you. def fibonacci_sequence(n):\n",
      "    sequence = [0, 1]\n",
      "    while len(sequence) < n:\n",
      "        sequence.append(sequence[-1] + sequence[-2])\n",
      "    return sequence\n",
      "\n",
      "first_15_fibonacci = fibonacci_sequence(15)\n",
      "first_15_fibonacci The first 15 numbers in the Fibonacci sequence are:\n",
      "\n",
      "0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "User: Generate a list of prime numbers less than 100\n",
      "Agent: I will generate a list of prime numbers less than 100. Let me do the calculation. def is_prime(n):\n",
      "    if n < 2:\n",
      "        return False\n",
      "    for i in range(2, int(n**0.5) + 1):\n",
      "        if n % i == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "primes_less_than_100 = [x for x in range(100) if is_prime(x)]\n",
      "primes_less_than_100 The list of prime numbers less than 100 is:\n",
      "[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agent_framework import ChatAgent, ChatResponse, HostedCodeInterpreterTool\n",
    "from agent_framework.azure import AzureOpenAIResponsesClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from openai.types.responses.response import Response as OpenAIResponse\n",
    "from openai.types.responses.response_code_interpreter_tool_call import ResponseCodeInterpreterToolCall\n",
    "\n",
    "async def code_interpreter_responses_demo():\n",
    "    \"\"\"\n",
    "    Demonstrates using HostedCodeInterpreterTool with Azure OpenAI Responses Client.\n",
    "    \n",
    "    This example shows how to execute Python code on Azure OpenAI service using\n",
    "    the Responses API with the hosted code interpreter tool.\n",
    "    \"\"\"\n",
    "    print(\"=== Azure OpenAI Responses Client with Hosted Code Interpreter ===\\n\")\n",
    "    \n",
    "    # For authentication, run `az login` command in terminal\n",
    "    agent = ChatAgent(\n",
    "        chat_client=AzureOpenAIResponsesClient(\n",
    "            credential=AzureCliCredential(),\n",
    "            endpoint=azure_openai_endpoint,\n",
    "            deployment_name=azure_openai_deployment,\n",
    "            api_version=\"preview\" # Use \"preview\" for Azure OpenAI Responses. Currently, the api_version must be \"preview\".\n",
    "        ),\n",
    "        instructions=\"You are a helpful assistant that can write and execute Python code to solve problems.\",\n",
    "        tools=[HostedCodeInterpreterTool()],\n",
    "    )\n",
    "    \n",
    "    # Test questions that require code execution\n",
    "    questions = [\n",
    "        \"Use code to calculate the factorial of 100\",\n",
    "        \"Calculate the first 15 numbers in the Fibonacci sequence\",\n",
    "        \"Generate a list of prime numbers less than 100\"\n",
    "    ]\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"User: {question}\")\n",
    "        result = await agent.run(question)\n",
    "        print(f\"Agent: {result.text}\\n\")\n",
    "        \n",
    "        # Extract and display the generated code if available\n",
    "        if (\n",
    "            isinstance(result.raw_representation, ChatResponse)\n",
    "            and isinstance(result.raw_representation.raw_representation, OpenAIResponse)\n",
    "            and len(result.raw_representation.raw_representation.output) > 0\n",
    "            and isinstance(\n",
    "                result.raw_representation.raw_representation.output[0], \n",
    "                ResponseCodeInterpreterToolCall\n",
    "            )\n",
    "        ):\n",
    "            generated_code = result.raw_representation.raw_representation.output[0].code\n",
    "            print(f\"üìù Generated code:\\n```python\\n{generated_code}\\n```\\n\")\n",
    "        \n",
    "        print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "await code_interpreter_responses_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a66fd4",
   "metadata": {},
   "source": [
    "## üß™ Case 4: Tool use examples with Azure AI Agent Client\n",
    "---\n",
    "examples demonstrating different ways to create and use Agents and tools with the Azure AI Agent Client from the agent_framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7310bf",
   "metadata": {},
   "source": [
    "# Case 4: Enterprise Tools with Azure AI Agent Client\n",
    "---\n",
    "Microsoft Agent Framework provides powerful enterprise-grade hosted tools that integrate seamlessly with Azure services. These tools enable agents to perform advanced operations like web search, document retrieval, and external integrations.\n",
    "\n",
    "## Hosted Tools Comparison\n",
    "\n",
    "| Tool | Purpose | Service | Key Features |\n",
    "|------|---------|---------|--------------|\n",
    "| **HostedFileSearchTool** | Document/Data Search | Azure AI Search | ‚úÖ Index-based search<br>‚úÖ Semantic search<br>‚úÖ Configurable ranking |\n",
    "| **HostedWebSearchTool** | Real-time Web Search | Bing Grounding | ‚úÖ Current information<br>‚úÖ Source citations<br>‚úÖ Web grounding |\n",
    "| **Local MCP** | Custom Integrations | Local Server | ‚úÖ Full control<br>‚úÖ Custom logic<br>‚úÖ Local resources |\n",
    "| **Hosted MCP** | External Services | Remote Server | ‚úÖ Third-party APIs<br>‚úÖ Scalable<br>‚úÖ Managed infrastructure |\n",
    "\n",
    "### Prerequisites for Case 4:\n",
    "\n",
    "**For Azure AI Search (Case 4.1):**\n",
    "- Azure AI Search service with indexed data\n",
    "- Search connection configured in Azure AI Project\n",
    "- Index name (e.g., \"hotels-sample-index\")\n",
    "\n",
    "**For Bing Grounding (Case 4.2):**\n",
    "- Bing Grounding connection in Azure AI Project\n",
    "- `BING_CONNECTION_NAME` or `BING_CONNECTION_ID` environment variable\n",
    "\n",
    "**For MCP Tools (Case 4.3 & 4.4):**\n",
    "- Understanding of Model Context Protocol (MCP)\n",
    "- MCP server configuration (local or hosted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3665f2",
   "metadata": {},
   "source": [
    "## üß™ Case 4.1: Azure AI Search with HostedFileSearchTool\n",
    "---\n",
    "Demonstrates using Azure AI Search to search through indexed hotel data and answer questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e12291",
   "metadata": {},
   "source": [
    "> **Note**: Before running this case, first execute the `1_basic-rag.ipynb` notebook in the `0_basic-rag` folder and create a connection to set up the required Azure AI Search index and vector store.\n",
    "\n",
    "**Prerequisites:**\n",
    "1. Set AZURE_AI_PROJECT_ENDPOINT and AZURE_AI_MODEL_DEPLOYMENT_NAME environment variables\n",
    "2. Ensure you have an Azure AI Search connection configured in your Azure AI project\n",
    "3. The search index \"hotels-sample-index\" should exist in your Azure AI Search service\n",
    "   (you can create this using **1_basic-rag.ipynb** in the **0_basic-rag folder** with sample hotel data)\n",
    "\n",
    "**Environment variables:**\n",
    "- AZURE_AI_PROJECT_ENDPOINT: Your Azure AI project endpoint\n",
    "- AZURE_AI_MODEL_DEPLOYMENT_NAME: The name of your model deployment\n",
    "\n",
    "**Key Modules:**\n",
    "- `HostedFileSearchTool` from `agent_framework`\n",
    "- Uses Azure AI Search vector stores for semantic search capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c11c823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file from: employees.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file, file ID: assistant-EqpJ4iYoGy7DUvDn8mF9Hv\n",
      "Created vector store, ID: vs_5P43SpPT32ZmYzfJM8P0aXF8\n",
      "\n",
      "=== Azure AI Agent with File Search (Employee PDF) ===\n",
      "This agent can search through employee data to answer questions.\n",
      "\n",
      "User: Who is the youngest employee?\n",
      "Agent: The youngest employee is Alice Johnson from the Sales department, who is 24 years old„Äê4:0‚Ä†employees.pdf„Äë.\n",
      "==================================================\n",
      "\n",
      "User: Who works in sales?\n",
      "Agent: The person who works in Sales is Alice Johnson. \n",
      "\n",
      "„Äê4:0‚Ä†employees.pdf„Äë\n",
      "==================================================\n",
      "\n",
      "User: I have a customer request, who can help me?\n",
      "Agent: Could you please provide more details about the customer request? This will help me identify the right person who can assist you.\n",
      "==================================================\n",
      "\n",
      "Employee search conversation completed!\n",
      "Deleted vector store: vs_5P43SpPT32ZmYzfJM8P0aXF8\n",
      "Deleted file: assistant-EqpJ4iYoGy7DUvDn8mF9Hv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from agent_framework import ChatAgent, HostedFileSearchTool, HostedVectorStoreContent\n",
    "from azure.ai.agents.models import FileInfo, VectorStore\n",
    "\n",
    "async def employee_search_demo():\n",
    "    \"\"\"\n",
    "    Demonstrates Azure AI agent with file search capabilities using uploaded PDF.\n",
    "    This example uploads an employee PDF file and creates a vector store for searching.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Create Azure AI Agent client with credential\n",
    "    credential = AzureCliCredential()\n",
    "    \n",
    "    file: FileInfo | None = None\n",
    "    vector_store: VectorStore | None = None\n",
    "    \n",
    "    try:\n",
    "        # Create a chat client and agent with Azure OpenAI\n",
    "        azure_openai_chat_client = AzureOpenAIChatClient(\n",
    "            deployment_name=azure_openai_deployment,\n",
    "            endpoint=azure_openai_endpoint,\n",
    "            api_key=azure_openai_key,\n",
    "            api_version=azure_openai_version\n",
    "        )\n",
    "\n",
    "        azure_ai_agent_client = AzureAIAgentClient(\n",
    "            async_credential=credential,\n",
    "            project_endpoint=azure_project_endpoint,\n",
    "            model_deployment_name=azure_ai_deployment\n",
    "        )\n",
    "            \n",
    "        # 1. Upload employee PDF file\n",
    "        pdf_file_path = \"employees.pdf\"\n",
    "        print(f\"Uploading file from: {pdf_file_path}\")\n",
    "        \n",
    "        file = await azure_ai_agent_client.project_client.agents.files.upload_and_poll(\n",
    "            file_path=str(pdf_file_path), \n",
    "            purpose=\"assistants\"\n",
    "        )\n",
    "        print(f\"Uploaded file, file ID: {file.id}\")\n",
    "        \n",
    "        # 2. Create vector store with the uploaded file\n",
    "        vector_store = await azure_ai_agent_client.project_client.agents.vector_stores.create_and_poll(\n",
    "            file_ids=[file.id], \n",
    "            name=\"employee_vectorstore\"\n",
    "        )\n",
    "        print(f\"Created vector store, ID: {vector_store.id}\\n\")\n",
    "        \n",
    "        # 3. Create file search tool with the vector store\n",
    "        file_search_tool = HostedFileSearchTool(\n",
    "            inputs=[HostedVectorStoreContent(vector_store_id=vector_store.id)]\n",
    "        )\n",
    "        \n",
    "        # 4. Create agent with file search capability\n",
    "        agent = ChatAgent(\n",
    "            #chat_client=azure_ai_agent_client,\n",
    "            chat_client=azure_ai_agent_client,\n",
    "            name=\"Employee Search Assistant\",\n",
    "            instructions=\"You are a helpful assistant that can search through uploaded employee files to answer questions about employees.\",\n",
    "            tools=file_search_tool\n",
    "        )\n",
    "        \n",
    "        # 5. Test questions about employees\n",
    "        USER_INPUTS = [\n",
    "            \"Who is the youngest employee?\",\n",
    "            \"Who works in sales?\",\n",
    "            \"I have a customer request, who can help me?\"\n",
    "        ]\n",
    "        \n",
    "        print(\"=== Azure AI Agent with File Search (Employee PDF) ===\")\n",
    "        print(\"This agent can search through employee data to answer questions.\\n\")\n",
    "        \n",
    "        # 6. Simulate conversation with the agent\n",
    "        for user_input in USER_INPUTS:\n",
    "            print(f\"User: {user_input}\")\n",
    "            print(\"Agent: \", end=\"\", flush=True)\n",
    "            \n",
    "            # Stream the response for better user experience\n",
    "            async for chunk in agent.run_stream(user_input):\n",
    "                if chunk.text:\n",
    "                    print(chunk.text, end=\"\", flush=True)\n",
    "            print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        \n",
    "        print(\"Employee search conversation completed!\")\n",
    "            \n",
    "    finally:\n",
    "        # 7. Cleanup: Delete the vector store and file\n",
    "        # Refresh client if needed (agent closes it when used as context manager)\n",
    "        try:\n",
    "            cleanup_client = AzureAIAgentClient(\n",
    "                async_credential=AzureCliCredential(),\n",
    "                project_endpoint=azure_project_endpoint,\n",
    "                model_deployment_name=azure_ai_deployment\n",
    "            )\n",
    "            await cleanup_client.close()\n",
    "\n",
    "            if azure_ai_agent_client:\n",
    "                await azure_ai_agent_client.close()\n",
    "\n",
    "            if vector_store:\n",
    "                await cleanup_client.project_client.agents.vector_stores.delete(vector_store.id)\n",
    "                print(f\"Deleted vector store: {vector_store.id}\")\n",
    "            if file:\n",
    "                await cleanup_client.project_client.agents.files.delete(file.id)\n",
    "                print(f\"Deleted file: {file.id}\")\n",
    "                \n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Cleanup warning: {e}\")\n",
    "\n",
    "await employee_search_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e6d8e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Azure AI Agent with Azure AI Search ===\n",
      "This agent can search through hotel data to help you find accommodations.\n",
      "\n",
      "User: Search hotels in USA and give me detailed information.\n",
      "Agent: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-27 01:18:58 - /anaconda/envs/venv_agentlab/lib/python3.12/asyncio/base_events.py:1833 - ERROR] Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fe3b6454230>\n",
      "[2025-10-27 01:18:58 - /anaconda/envs/venv_agentlab/lib/python3.12/asyncio/base_events.py:1833 - ERROR] Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x7fe3b4717bf0>, 3459979.628858652)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x7fe3b63cd7f0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " USA is a large country with many cities and a wide range of hotels. Could you please specify the city or region you are"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-27 01:18:58 - /anaconda/envs/venv_agentlab/lib/python3.12/asyncio/base_events.py:1833 - ERROR] Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fe3b4ce3d40>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " interested in? Also, let me know any preferences you have, such as hotel star rating, budget, or amenities. This will help me provide detailed and relevant hotel information for you.\n",
      "==================================================\n",
      "\n",
      "Hotel search conversation completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from agent_framework import HostedFileSearchTool\n",
    "from agent_framework import ChatAgent\n",
    "\n",
    "\n",
    "async def ai_search_tool_responses_demo():\n",
    "\n",
    "    try:\n",
    "        # Create Azure AI Agent client with credential\n",
    "        credential = AzureCliCredential()\n",
    "\n",
    "        \n",
    "        # Create file search tool with vector store\n",
    "        azure_ai_search_tool = HostedFileSearchTool(\n",
    "            additional_properties={\n",
    "                \"index_name\": \"hotels-sample-index\",  # Name of your search index\n",
    "                \"query_type\": \"simple\",  # Use simple search\n",
    "                \"top_k\": 10,  # Get more comprehensive results\n",
    "            },\n",
    "        )\n",
    "\n",
    "        azure_openai_chat_client = AzureOpenAIChatClient(\n",
    "                deployment_name=azure_openai_deployment,\n",
    "                endpoint=azure_openai_endpoint,\n",
    "                api_key=azure_openai_key,\n",
    "                api_version=azure_openai_version\n",
    "            )\n",
    "\n",
    "        # TODO: Not work with Azure AI Agent Client yet - https://github.com/microsoft/agent-framework/issues/1381\n",
    "        # azure_ai_agent_client = AzureAIAgentClient(\n",
    "        #     async_credential=credential,\n",
    "        #     project_endpoint=project_endpoint,\n",
    "        #     model_deployment_name=azure_ai_deployment\n",
    "        # )\n",
    "    \n",
    "        # Create agent with file search capability\n",
    "        agent = ChatAgent(\n",
    "            chat_client=azure_openai_chat_client,\n",
    "            name=\"Hotel Search Assistant\",\n",
    "            instructions=\"You are a helpful travel assistant that searches hotel information.\",\n",
    "            tools=azure_ai_search_tool\n",
    "        )\n",
    "\n",
    "        USER_INPUTS = [\n",
    "            \"Search hotels in USA and give me detailed information.\",\n",
    "        ]\n",
    "        \n",
    "        print(\"=== Azure AI Agent with Azure AI Search ===\")\n",
    "        print(\"This agent can search through hotel data to help you find accommodations.\\n\")\n",
    "\n",
    "        # 3. Simulate conversation with the agent\n",
    "        for user_input in USER_INPUTS:\n",
    "            print(f\"User: {user_input}\")\n",
    "            print(\"Agent: \", end=\"\", flush=True)\n",
    "\n",
    "            # Stream the response for better user experience\n",
    "            async for chunk in agent.run_stream(user_input):\n",
    "                if chunk.text:\n",
    "                    print(chunk.text, end=\"\", flush=True)\n",
    "            print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "        print(\"Hotel search conversation completed!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "    finally:\n",
    "        cleanup_client = AzureAIAgentClient(\n",
    "            async_credential=AzureCliCredential(),\n",
    "            project_endpoint=azure_project_endpoint,\n",
    "            model_deployment_name=azure_ai_deployment\n",
    "        )\n",
    "        await cleanup_client.close()\n",
    "\n",
    "await ai_search_tool_responses_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d99553",
   "metadata": {},
   "source": [
    "## üß™ Case 4.2: Bing Grounding with HostedWebSearchTool\n",
    "---\n",
    "Demonstrates using Bing Search API for web grounding to answer questions with real-time web data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c7cff",
   "metadata": {},
   "source": [
    "**Setup:**\n",
    "- Azure AI Project with Bing Search connection\n",
    "- Environment variables: `AZURE_AI_PROJECT_ENDPOINT`, `BING_CONNECTION_NAME`\n",
    "\n",
    "**Key Modules:**\n",
    "- `HostedWebSearchTool` from `agent_framework.azure_ai.tools`\n",
    "- Provides grounded responses with web search results and citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "907e4458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Azure AI Agent with Bing Grounding Search ===\n",
      "This agent can search the web for current information and provide grounded answers.\n",
      "\n",
      "User: Tell me what day it is today and What is the latest exciting news in South Korea?\n",
      "Agent: I'm sorry, but I cannot assist with that request.\n",
      "==================================================\n",
      "\n",
      "Web search conversation completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from agent_framework.azure import AzureAIAgentClient, AzureOpenAIChatClient\n",
    "from agent_framework import HostedWebSearchTool\n",
    "from agent_framework import ChatAgent\n",
    "\n",
    "\n",
    "async def bing_grounding_demo():\n",
    "    \"\"\"\n",
    "    Demonstrates using Bing Search API for web grounding to answer questions with real-time web data.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Get Azure AI Project endpoint\n",
    "        bing_connection_id = os.environ.get(\"BING_GROUNDING_CONNECTION_ID\")\n",
    "        \n",
    "        # Create Azure AI Agent client with credential\n",
    "        credential = AzureCliCredential()\n",
    "        \n",
    "        # Create web search tool with Bing connection\n",
    "        web_search_tool = HostedWebSearchTool(\n",
    "            \n",
    "            additional_properties={\n",
    "                \"connection_id\": bing_connection_id,\n",
    "                \"top_k\": 3,  # Get top 3 search results\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # TODO: Not work with Azure OpenAI Chat Client\n",
    "        # azure_openai_chat_client = AzureOpenAIChatClient(\n",
    "        #     deployment_name=azure_openai_deployment,\n",
    "        #     endpoint=azure_openai_endpoint,\n",
    "        #     api_key=azure_openai_key,\n",
    "        #     api_version=azure_openai_version\n",
    "        # )\n",
    "        \n",
    "        azure_ai_agent_client = AzureAIAgentClient(\n",
    "            async_credential=credential,\n",
    "            project_endpoint=azure_project_endpoint,\n",
    "            model_deployment_name=azure_ai_deployment\n",
    "        )\n",
    "        \n",
    "        # Create agent with web search capability\n",
    "        agent = ChatAgent(\n",
    "            #chat_client=azure_openai_chat_client,\n",
    "            chat_client=azure_ai_agent_client,\n",
    "            name=\"Web Research Assistant\",\n",
    "            instructions=\"You are a helpful research assistant. Use web search to find current information and provide grounded answers with citations.\",\n",
    "            tools=[web_search_tool]\n",
    "        )\n",
    "        \n",
    "        # Test questions that require web search\n",
    "        USER_INPUTS = [\n",
    "            \"Tell me what day it is today and What is the latest exciting news in South Korea?\"\n",
    "        ]\n",
    "        \n",
    "        print(\"=== Azure AI Agent with Bing Grounding Search ===\")\n",
    "        print(\"This agent can search the web for current information and provide grounded answers.\\n\")\n",
    "        \n",
    "        # Simulate conversation with the agent\n",
    "        for user_input in USER_INPUTS:\n",
    "            print(f\"User: {user_input}\")\n",
    "            print(\"Agent: \", end=\"\", flush=True)\n",
    "            \n",
    "            # Stream the response for better user experience\n",
    "            async for chunk in agent.run_stream(user_input):\n",
    "                if chunk.text:\n",
    "                    print(chunk.text, end=\"\", flush=True)\n",
    "            print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        \n",
    "        print(\"Web search conversation completed!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "    finally:\n",
    "        # Cleanup: Close Azure AI Agent client if it was created\n",
    "        try:\n",
    "            await azure_ai_agent_client.close()    \n",
    "        except Exception as cleanup_error:\n",
    "            print(f\"Cleanup warning: {cleanup_error}\")\n",
    "\n",
    "await bing_grounding_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec96b02",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d9c7a85",
   "metadata": {},
   "source": [
    "## üß™ Case 4.3: Local MCP Server Integration\n",
    "---\n",
    "Demonstrates connecting to a local Model Context Protocol (MCP) server to extend agent capabilities with custom tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c76f84",
   "metadata": {},
   "source": [
    "**Setup:**\n",
    "- Local MCP server running (e.g., file system tools, database connectors)\n",
    "- MCP server URL or configuration\n",
    "- Environment variable: `AZURE_OPENAI_ENDPOINT`\n",
    "\n",
    "**Key Modules:**\n",
    "- Discovers and registers tools from MCP server dynamically\n",
    "- Works with any MCP-compliant server implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "885c80d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Azure AI Agent with Local MCP Server ===\n",
      "This agent can use MCP tools to access Microsoft documentation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How to create an Azure storage account using az cli? response with a simple answer and an example.\n",
      "Agent: To create an Azure storage account using Azure CLI, use the `az storage account create` command with parameters for resource group, storage account name, and location.\n",
      "\n",
      "Example:\n",
      "```bash\n",
      "az storage account create --name mystorageaccount --resource-group myResourceGroup --location eastus --sku Standard_LRS\n",
      "```\n",
      "==================================================\n",
      "\n",
      "User: What is Microsoft Agent Framework? response with key concepts and a main python code example.\n",
      "Agent: Microsoft Agent Framework is a comprehensive framework provided by Microsoft to build and manage intelligent AI agents equipped with advanced conversational AI capabilities. It supports multiple types of agents, all derived from a common base class called AIAgent, enabling a consistent interface and allowing for building complex functionalities like multi-agent orchestrations.\n",
      "\n",
      "Key concepts of Microsoft Agent Framework include:\n",
      "1. **Simple Agents Based on Inference Services**: Easy creation of agents using various inference services that implement the IChatClient interface.\n",
      "2. **Complex Custom Agents**: Custom agents can be created by subclassing the base agent type to have full control over behavior.\n",
      "3. **Proxies for Remote Agents**: Support for connecting to remote agents using protocols like A2A.\n",
      "4. **Workflows**: Orchestrate intelligent automation blending AI agents with business processes.\n",
      "5. **Tools Integration**: Support for function calling, custom service tools, and structured output.\n",
      "6. **Multi-turn Conversations**: Management of conversation history for dynamic dialogs.\n",
      "7. **Type Safety and Flexible Control Flow**: For robust workflow design.\n",
      "8. **Authentication and Security**: Integrations with Azure identity mechanisms.\n",
      "\n",
      "Microsoft Agent Framework supports various underlying AI services including Azure AI Foundry, Azure OpenAI, and OpenAI services, with specific agents built for each.\n",
      "\n",
      "Below is a main Python example of creating a simple agent using Azure AI in Microsoft Agent Framework. This example shows the usage of an agent that can execute Python code using the HostedCodeInterpreterTool:\n",
      "\n",
      "```python\n",
      "import asyncio\n",
      "from agent_framework import ChatAgent, HostedCodeInterpreterTool\n",
      "from agent_framework.azure import AzureAIAgentClient\n",
      "from azure.identity.aio import DefaultAzureCredential\n",
      "\n",
      "async def main():\n",
      "    async with (\n",
      "        DefaultAzureCredential() as credential,\n",
      "        ChatAgent(\n",
      "            chat_client=AzureAIAgentClient(async_credential=credential),\n",
      "            instructions=\"You are a helpful assistant that can execute Python code.\",\n",
      "            tools=HostedCodeInterpreterTool()\n",
      "        ) as agent\n",
      "    ):\n",
      "        response = await agent.run(\"Calculate the factorial of 100 using Python\")\n",
      "        print(response.text)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    asyncio.run(main())\n",
      "```\n",
      "\n",
      "This example does the following:\n",
      "- Uses Azure CLI or any default Azure credential for authentication.\n",
      "- Creates a ChatAgent with Azure AI backend capable of handling chat and code execution via the HostedCodeInterpreterTool.\n",
      "- Runs the agent with input to calculate the factorial of 100 using Python.\n",
      "- Prints the agent's response with the calculation result.\n",
      "\n",
      "For more detailed usage and agent customization, Microsoft documentation provides extensive guides and examples:  \n",
      "- https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-types/  \n",
      "- https://learn.microsoft.com/en-us/agent-framework/tutorials/overview  \n",
      "\n",
      "Let me know if you want code examples with other AI backends or need details on workflows and orchestration!\n",
      "==================================================\n",
      "\n",
      "MCP tool conversation completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from agent_framework.azure import AzureOpenAIChatClient, AzureAIAgentClient\n",
    "from agent_framework import ChatAgent, MCPStreamableHTTPTool\n",
    "\n",
    "\n",
    "async def local_mcp_demo():\n",
    "    \"\"\"\n",
    "    Demonstrates connecting to a local Model Context Protocol (MCP) server \n",
    "    to extend agent capabilities with custom tools.\n",
    "    \n",
    "    This example shows how to use Microsoft Learn MCP server with Azure AI Agent.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create Azure AI Agent client with credential\n",
    "        credential = AzureCliCredential()\n",
    "        \n",
    "        print(\"=== Azure AI Agent with Local MCP Server ===\")\n",
    "        print(\"This agent can use MCP tools to access Microsoft documentation.\\n\")\n",
    "        \n",
    "        # Connect to local MCP server and create agent with MCP tools\n",
    "        async with (\n",
    "            AzureAIAgentClient(\n",
    "                async_credential=credential,\n",
    "                project_endpoint=azure_project_endpoint,\n",
    "                model_deployment_name=azure_ai_deployment\n",
    "            ) as azure_ai_agent_client,\n",
    "            MCPStreamableHTTPTool(\n",
    "                name=\"Local Microsoft Learn MCP\",\n",
    "                url=\"https://learn.microsoft.com/api/mcp\",\n",
    "            ) as mcp_server\n",
    "        ):\n",
    "            # Create agent with MCP tools\n",
    "            agent = ChatAgent(\n",
    "                chat_client=azure_ai_agent_client,\n",
    "                name=\"Local MCP Assistant\",\n",
    "                instructions=\"You are a helpful assistant that can help with Microsoft documentation questions using MCP tools.\",\n",
    "                tools=mcp_server,\n",
    "                store=True\n",
    "            )\n",
    "            \n",
    "            # Test questions that use MCP tools\n",
    "            USER_INPUTS = [\n",
    "                \"How to create an Azure storage account using az cli? response with a simple answer and an example.\",\n",
    "                \"What is Microsoft Agent Framework? response with key concepts and a main python code example.\"\n",
    "            ]\n",
    "            \n",
    "            # Simulate conversation with the agent\n",
    "            for user_input in USER_INPUTS:\n",
    "                print(f\"User: {user_input}\")\n",
    "                print(\"Agent: \", end=\"\", flush=True)\n",
    "                \n",
    "                # Stream the response for better user experience\n",
    "                async for chunk in agent.run_stream(user_input):\n",
    "                    if chunk.text:\n",
    "                        print(chunk.text, end=\"\", flush=True)\n",
    "                print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "            \n",
    "            print(\"MCP tool conversation completed!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "await local_mcp_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66086eea",
   "metadata": {},
   "source": [
    "## üß™ Case 4.4: Hosted MCP Server with Human in the loop (Azure AI Project)\n",
    "---\n",
    "Demonstrates using MCP servers hosted in Azure AI Project with human-in-the-loop capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3d9ce",
   "metadata": {},
   "source": [
    "**Setup:**\n",
    "- Azure AI Project with hosted MCP server connection\n",
    "- MCP server deployed and registered in Azure AI Project\n",
    "- Environment variable: `AZURE_AI_PROJECT_ENDPOINT`\n",
    "\n",
    "**Key Modules:**\n",
    "- `HostedMCPTool` from `agent_framework`\n",
    "- Connects to MCP servers hosted in Azure AI infrastructure\n",
    "- Human-in-the-loop support for review and approval workflows\n",
    "- Provides secure, managed access to MCP tools without local server setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a0e7d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Azure AI Agent with Hosted MCP Server ===\n",
      "This agent uses hosted MCP tools to access Microsoft documentation.\n",
      "\n",
      "User: How to create an Azure storage account using az cli?\n",
      "Agent: \n",
      "‚ö†Ô∏è Function call approval needed: microsoft_docs_search\n",
      "   Arguments: {\"query\":\"create Azure storage account using az cli\",\"question\":\"How to create an Azure storage account using az cli?\"}\n",
      ".....user approval simulated. yes! \n",
      "\n",
      "To create an Azure storage account using Azure CLI, you can use the `az storage account create` command. Here's a basic example:\n",
      "\n",
      "```azurecli\n",
      "az storage account create \\\n",
      "  --name <account-name> \\\n",
      "  --resource-group <resource-group-name> \\\n",
      "  --location <location> \\\n",
      "  --sku Standard_RAGRS \\\n",
      "  --kind StorageV2 \\\n",
      "  --min-tls-version TLS1_2 \\\n",
      "  --allow-blob-public-access false\n",
      "```\n",
      "\n",
      "Replace the placeholders with your own values:\n",
      "- `<account-name>`: The unique name for your storage account.\n",
      "- `<resource-group-name>`: The name of your Azure resource group.\n",
      "- `<location>`: The Azure region where you want to create the storage account (e.g., eastus).\n",
      "\n",
      "Explanation of parameters:\n",
      "- `--sku`: Specifies the SKU for the storage account. In this example, Standard_RAGRS (read-access geo-redundant storage) is used.\n",
      "- `--kind`: Specifies the type of storage account. StorageV2 is recommended for general purpose v2 accounts.\n",
      "- `--min-tls-version`: Sets the minimum TLS version to use.\n",
      "- `--allow-blob-public-access`: Set to false to disallow public access to blobs.\n",
      "\n",
      "Before you create the storage account, ensure you have a resource group created:\n",
      "```azurecli\n",
      "az group create --name <resource-group-name> --location <location>\n",
      "```\n",
      "\n",
      "For more details, you can refer to the official Microsoft documentation:  \n",
      "https://learn.microsoft.com/en-us/azure/storage/common/storage-account-create#create-a-storage-account\n",
      "\n",
      "==================================================\n",
      "\n",
      "User: What is Microsoft Agent Framework?\n",
      "Agent: \n",
      "‚ö†Ô∏è Function call approval needed: microsoft_docs_search\n",
      "   Arguments: {\"query\":\"Microsoft Agent Framework\",\"question\":\"What is Microsoft Agent Framework?\"}\n",
      ".....user approval simulated. yes! \n",
      "\n",
      "The Microsoft Agent Framework is a framework that supports creating, managing, and orchestrating AI agents. It is designed to accommodate different use cases and requirements by providing several types of agents derived from a common base class called `AIAgent`. This base class provides a consistent interface for all agent types, allowing for building common, agent-agnostic, higher-level functionality such as multi-agent orchestrations.\n",
      "\n",
      "Key points about Microsoft Agent Framework:\n",
      "\n",
      "- Simple agents can be created based on various inference services that implement the `Microsoft.Extensions.AI.IChatClient` interface.\n",
      "- These agents support features like function calling, multi-turn conversations with chat history management, custom service-provided tools, and structured output.\n",
      "- There are also complex custom agents that allow complete control over the agent's behavior and capabilities by subclassing `AIAgent`.\n",
      "- The framework supports proxies for remote agents via common service-hosted agent protocols.\n",
      "- It provides integration with Azure AI services, Azure OpenAI, OpenAI services, and other chat client implementations.\n",
      "- The framework includes workflows for intelligent automation systems that blend AI agents with business processes, offering type-safe architecture and flexible control flow.\n",
      "\n",
      "For more detailed information, you can visit the official documentation:  \n",
      "https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-types/\n",
      "\n",
      "==================================================\n",
      "\n",
      "Hosted MCP tool conversation completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from agent_framework import HostedMCPTool, ChatMessage\n",
    "from agent_framework import ChatAgent\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "async def handle_approvals_with_thread(query: str, agent, thread):\n",
    "    \"\"\"Handle user approval requests for function calls.\"\"\"\n",
    "    result = await agent.run(query, thread=thread, store=True)\n",
    "    \n",
    "    while len(result.user_input_requests) > 0:\n",
    "        new_input: list[Any] = []\n",
    "        for user_input_needed in result.user_input_requests:\n",
    "            print(\n",
    "                f\"\\n‚ö†Ô∏è Function call approval needed: {user_input_needed.function_call.name}\"\n",
    "                f\"\\n   Arguments: {user_input_needed.function_call.arguments}\"\n",
    "            )\n",
    "            # Visual feedback with dots for 1 second\n",
    "            for _ in range(5):\n",
    "                print(\".\", end=\"\", flush=True)\n",
    "                await asyncio.sleep(0.33)\n",
    "            print(\"user approval simulated. yes! \\n\")\n",
    "            # Auto-approve for demo purposes (in production, you'd want user input)\n",
    "            user_approval = \"y\"  # or use: input(\"Approve? (y/n): \")\n",
    "            new_input.append(\n",
    "                ChatMessage(\n",
    "                    role=\"user\",\n",
    "                    contents=[user_input_needed.create_response(user_approval.lower() == \"y\")],\n",
    "                )\n",
    "            )\n",
    "        result = await agent.run(new_input, thread=thread, store=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "async def hosted_mcp_demo():\n",
    "    \"\"\"\n",
    "    Demonstrates using MCP servers hosted in Azure AI Project for enterprise-ready tool integration.\n",
    "    \n",
    "    This example shows how to connect to a hosted MCP server with proper approval workflow.\n",
    "    Based on: https://github.com/microsoft/agent-framework/tree/main/python/samples\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "\n",
    "        # Create Azure AI Agent client with credential\n",
    "        credential = AzureCliCredential()\n",
    "        \n",
    "        print(\"=== Azure AI Agent with Hosted MCP Server ===\")\n",
    "        print(\"This agent uses hosted MCP tools to access Microsoft documentation.\\n\")\n",
    "        \n",
    "        async with AzureAIAgentClient(\n",
    "            async_credential=credential,\n",
    "            project_endpoint=azure_project_endpoint,\n",
    "            model_deployment_name=azure_ai_deployment,\n",
    "            ) as chat_client:\n",
    "            \n",
    "            # Enable Azure AI observability (optional but recommended)\n",
    "            #await chat_client.setup_azure_ai_observability()\n",
    "            \n",
    "            # Create agent with hosted MCP tools using create_agent method\n",
    "            agent = chat_client.create_agent(\n",
    "                name=\"Hosted MCP Assistant\",\n",
    "                instructions=\"You are a helpful assistant that can help with Microsoft documentation questions using MCP tools.\",\n",
    "                tools=HostedMCPTool(\n",
    "                    name=\"Microsoft Learn MCP\",\n",
    "                    url=\"https://learn.microsoft.com/api/mcp\",\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Create a new thread for conversation\n",
    "            thread = agent.get_new_thread()\n",
    "            \n",
    "            # Test questions using MCP tools\n",
    "            USER_INPUTS = [\n",
    "                \"How to create an Azure storage account using az cli?\",\n",
    "                \"What is Microsoft Agent Framework?\"\n",
    "            ]\n",
    "            \n",
    "            # Simulate conversation with approval workflow\n",
    "            for user_input in USER_INPUTS:\n",
    "                print(f\"User: {user_input}\")\n",
    "                print(\"Agent: \", end=\"\", flush=True)\n",
    "                \n",
    "                # Handle query with approval workflow\n",
    "                result = await handle_approvals_with_thread(user_input, agent, thread)\n",
    "                print(f\"{result.text}\")\n",
    "                print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "            \n",
    "            print(\"Hosted MCP tool conversation completed!\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        import traceback\n",
    "\n",
    "    finally:\n",
    "        # Cleanup: Close Azure AI Agent client if it was created\n",
    "        try:\n",
    "            await chat_client.close()    \n",
    "        except Exception as cleanup_error:\n",
    "            print(f\"Cleanup warning: {cleanup_error}\")\n",
    "\n",
    "await hosted_mcp_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe959d",
   "metadata": {},
   "source": [
    "## üìä Case 4 Comparison: Enterprise Tools\n",
    "\n",
    "| Feature | AI Search (4.1) | Bing Grounding (4.2) | Local MCP (4.3) | Hosted MCP (4.4) |\n",
    "|---------|----------------|---------------------|----------------|------------------|\n",
    "| **Tool Type** | `HostedFileSearchTool` | `HostedWebSearchTool` | `MCPClient` | `HostedMCPTool` |\n",
    "| **Client Type** | `AzureAIAgentClient` | `AzureAIAgentClient` | `AzureOpenAIChatClient` | `AzureAIAgentClient` |\n",
    "| **Data Source** | Azure AI Search vector stores | Bing Search API | Local MCP server process | Azure-hosted MCP server |\n",
    "| **Setup Complexity** | Medium (requires vector store) | Low (requires Bing connection) | Medium (requires local server) | Low (requires Azure connection) |\n",
    "| **Use Cases** | Internal document search, knowledge base | Real-time web information | Custom local tools, file system | Enterprise-grade custom tools |\n",
    "| **Authentication** | `DefaultAzureCredential` | `DefaultAzureCredential` | `AzureCliCredential` | `DefaultAzureCredential` |\n",
    "| **Grounding** | Citations from indexed docs | Web citations and sources | N/A (custom tool output) | Depends on MCP server |\n",
    "| **Scalability** | High (Azure managed) | High (Azure managed) | Low (local process) | High (Azure managed) |\n",
    "| **Customization** | Limited to indexed data | Limited to web search | Full (custom MCP tools) | Full (custom MCP tools) |\n",
    "| **Cost** | AI Search + AI Project | Bing API + AI Project | Azure OpenAI only | MCP hosting + AI Project |\n",
    "\n",
    "**Key Takeaways:**\n",
    "- **AI Search (4.1)**: Best for searching through your own documents and knowledge bases with semantic search\n",
    "- **Bing Grounding (4.2)**: Best for real-time web information with source citations\n",
    "- **Local MCP (4.3)**: Best for development and testing with custom tools on local machine\n",
    "- **Hosted MCP (4.4)**: Best for production deployment of custom tools with enterprise security and scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca8dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_agentlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
