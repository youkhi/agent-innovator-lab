{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26ab996",
   "metadata": {},
   "source": [
    "# Understand the kernel with code samples\n",
    "\n",
    "----\n",
    "The kernel is the central component of Semantic Kernel. At its simplest, the kernel is a Dependency Injection container that manages all of the services and plugins necessary to run your AI application. If you provide all of your services and plugins to the kernel, they will then be seamlessly used by the AI as needed. \n",
    "\n",
    "| Components | Description |\n",
    "|------------|-------------|\n",
    "| **1. Services** | These consist of both AI services (e.g., chat completion) and other services (e.g., logging and HTTP clients) that are necessary to run your application. This was modeled after the Service Provider pattern in .NET to support dependency injection across all languages. |\n",
    "| **2. Plugins** | These are components used by your AI services and prompt templates to perform work. For example, AI services can use plugins to retrieve data from a database or call an external API to perform actions. |\n",
    "\n",
    "![kernel](images/the-kernel-is-at-the-center-of-everything.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e456fe",
   "metadata": {},
   "source": [
    "## Hierarchical Architecture Diagram\n",
    "---\n",
    "\n",
    "Architecture of a Retrieval-Augmented Generation (RAG) based chatbot using the latest Semantic Kernel. The diagram highlights how the Agent Framework (for chat interactions) and Process Framework (for workflow orchestration) sit above the core Kernel, leveraging it to perform AI tasks. The Semantic Kernel core orchestrates between user requests and the underlying AI services, memory stores, and plugins. It integrates with external LLM services for generation, uses a vector DB for semantic memory (retrieval of relevant data), and can invoke plugins which may call other external APIs or services as needed.\n",
    "\n",
    "![Hierarchical](images/semantic_kernel_component.png)\n",
    "\n",
    "***AI Agent (Agent Framework)***: The Agent Framework in Semantic Kernel is an optional layer that helps create conversational AI agents (like chatbots) using the core kernelâ€™s capabilitiesâ€‹. It is not a replacement for the kernel but builds on top of it â€“ your application still includes the Semantic Kernel library, and the agent uses the kernelâ€™s functions internally. In a chatbot scenario, the Agent Framework manages the dialogue (turn-taking, system prompts, etc.) while delegating AI tasks to the kernel.\n",
    "\n",
    "***Semantic Kernel (Core)***: The Semantic Kernel core is the heart of the system. It orchestrates calls to AI models, retrieves memories, and executes plugin functions. The kernel provides abstractions to connect to AI services (LLM APIs for text generation, embedding models, etc.) and to various memory stores (for example, vector databases)â€‹. It also manages context (prompts) and can use Planners to chain or select functions dynamically to fulfill a user requestâ€‹. The kernel itself is part of your appâ€™s runtime, coordinating all other components.\n",
    "\n",
    "***Plugins (Skills/Functions)***: Plugins (also called skills or functions) are units of functionality that the kernel can invoke. They might be defined with natural language prompts (semantic functions) or as native code functions. Plugins can perform calculations, transform data, or call external services/APIs. They are registered with and executed via the kernel, meaning they depend on the kernel to be invoked as part of an AI workflowâ€‹. However, the plugin implementations (e.g. an HTTP call to a web service, a database query) run outside the kernel â€“ the kernel just orchestrates their usage. In essence, plugins extend the kernelâ€™s abilities, and the kernel can automatically chain plugins to accomplish complex tasks for the userâ€‹.\n",
    "\n",
    "***AI Services***: These are external AI model endpoints that the kernel calls through its connectors. For example, the OpenAI or Azure OpenAI service provides the GPT-4 model for text generation, and there are embedding model services for vector generation. The kernel has integrations for many AI services (text completion, chat, image generation, speech recognition, etc.) and it uses them by calling out to the respective APIsâ€‹. These services are not â€œinsideâ€ the kernel â€“ instead, the kernel depends on them to provide the intelligence. In the architecture, they appear as external components that the kernel invokes (e.g. sending a prompt to the GPT model and getting a completion).\n",
    "\n",
    "***Semantic Memory (Vector DB)***: The Semantic Kernel includes a memory abstraction that allows storing and retrieving contextual information. Under the hood, this is often backed by a vector database or search index. In a RAG-based chatbot, this is critical: documents or knowledge are embedded into vector representations and stored, so that relevant pieces can be retrieved to ground the AIâ€™s answers. Semantic Kernelâ€™s memory can integrate with many vector stores (e.g. Azure Cognitive Search, ChromaDB, Qdrant, Redis, Pinecone, etc.)â€‹. This means â€œMemoryâ€ is essentially an AI Search over a vector DB, enabling the bot to find relevant information by semantic similarity. The memory component is used by the kernel but the database itself is external â€“ the kernel just sends queries and gets results.\n",
    "\n",
    "***Process Framework (Workflow Orchestration)***: The Process Framework is another optional layer in the latest Semantic Kernel, aimed at long-running or multi-step workflows. It lets developers define structured processes composed of multiple steps, where each step can call kernel functions (AI or non-AI tasks) in an event-driven sequenceâ€‹. Like the Agent Framework, the Process Framework builds on the kernel rather than enclosing it. It uses the kernel to execute AI functions at each step of a business workflow. This is especially useful if your chatbot or assistant needs to carry out complex transactions or procedures (for example, an order processing workflow or a support ticket resolution that involves several back-and-forth steps) beyond a single conversational turn. The Process Framework uses technologies like Orleans or Dapr under the hood for reliability and can reuse any existing kernel plugins within those processesâ€‹."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b243d6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae1d038",
   "metadata": {},
   "source": [
    "Let's define our kernel for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651e17cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Annotated\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "from enum import Enum\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "from semantic_kernel.prompt_template import PromptTemplateConfig\n",
    "from semantic_kernel.agents import AssistantAgentThread, AzureAssistantAgent\n",
    "from semantic_kernel.kernel_pydantic import KernelBaseSettings\n",
    "from semantic_kernel.connectors.search.bing import BingSearch\n",
    "from semantic_kernel.functions import KernelArguments, KernelParameterMetadata, KernelPlugin\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "from semantic_kernel.filters import FilterTypes, FunctionInvocationContext\n",
    "from collections.abc import Awaitable, Callable\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings, AzureAIAgentThread\n",
    "from semantic_kernel.agents import AzureResponsesAgent, ResponsesAgentThread\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.agents import AzureResponsesAgent\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from semantic_kernel.agents.strategies.termination.termination_strategy import TerminationStrategy\n",
    "from semantic_kernel.agents import AgentGroupChat\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from azure.ai.projects.models import OpenApiAnonymousAuthDetails, OpenApiTool, CodeInterpreterTool\n",
    "from semantic_kernel.contents import AuthorRole\n",
    "\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "\n",
    "\n",
    "class Service(Enum):\n",
    "    \"\"\"Attributes:\n",
    "    OpenAI (str): Represents the OpenAI service.\n",
    "    AzureOpenAI (str): Represents the Azure OpenAI service.\n",
    "    HuggingFace (str): Represents the HuggingFace service.\n",
    "    \"\"\"\n",
    "\n",
    "    OpenAI = \"openai\"\n",
    "    AzureOpenAI = \"azureopenai\"\n",
    "    HuggingFace = \"huggingface\"\n",
    "\n",
    "class ServiceSettings(KernelBaseSettings):\n",
    "    \"\"\"The Learn Resources Service Settings.\n",
    "\n",
    "    The settings are first loaded from environment variables. If the\n",
    "    environment variables are not found, the settings can be loaded from a .env file with the\n",
    "    encoding 'utf-8' as default or the specific encoding. If the settings are not found in the\n",
    "    .env file, the settings are ignored; however, validation will fail alerting that the settings\n",
    "    are missing.\n",
    "\n",
    "    Args:\n",
    "        global_llm_service (str | None): The LLM service to use for the samples, either \"OpenAI\" or \"AzureOpenAI\"\n",
    "            If not provided, defaults to \"AzureOpenAI\".\n",
    "    \"\"\"\n",
    "\n",
    "    global_llm_service: str | None = None\n",
    "    \n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b01f0",
   "metadata": {},
   "source": [
    "We will load our settings and get the LLM service to use for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b0c8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using service type: Service.AzureOpenAI\n"
     ]
    }
   ],
   "source": [
    "service_settings = ServiceSettings.create()\n",
    "\n",
    "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "selectedService = (\n",
    "    Service.AzureOpenAI\n",
    "    if service_settings.global_llm_service is None\n",
    "    else Service(service_settings.global_llm_service.lower())\n",
    ")\n",
    "print(f\"Using service type: {selectedService}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793ed61f",
   "metadata": {},
   "source": [
    "We now configure our Chat Completion service on the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed56686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all services so that this cell can be re-run without restarting the kernel\n",
    "kernel.remove_all_services()\n",
    "\n",
    "service_id = None\n",
    "if selectedService == Service.OpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        OpenAIChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )\n",
    "elif selectedService == Service.AzureOpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c79873",
   "metadata": {},
   "source": [
    "# Run a Semantic Function (No Agent, No Process)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fd6ea0",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 1.1 running a prompt without plugin\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97a84f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robots prioritize human safety above all.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the request settings\n",
    "req_settings = kernel.get_prompt_execution_settings_from_service_id(service_id)\n",
    "req_settings.max_tokens = 2000\n",
    "req_settings.temperature = 0.7\n",
    "req_settings.top_p = 0.8\n",
    "\n",
    "prompt = \"\"\"\n",
    "1) A robot may not injure a human being or, through inaction,\n",
    "allow a human being to come to harm.\n",
    "\n",
    "2) A robot must obey orders given it by human beings except where\n",
    "such orders would conflict with the First Law.\n",
    "\n",
    "3) A robot must protect its own existence as long as such protection\n",
    "does not conflict with the First or Second Law.\n",
    "\n",
    "Give me the TLDR in exactly 5 words.\"\"\"\n",
    "\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"tldr\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    execution_settings=req_settings,\n",
    ")\n",
    "\n",
    "function = kernel.add_function(\n",
    "    function_name=\"tldr_function\",\n",
    "    plugin_name=\"tldr_plugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")\n",
    "\n",
    "\n",
    "result = await kernel.invoke(function)\n",
    "print(result) # => Robots must not harm humans.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef0c277",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 1.2 running a prompt with plugin\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b34af3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plugin = kernel.add_plugin(parent_directory=\"prompt_template_samples/\", plugin_name=\"FunPlugin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d008b3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the time traveler bring a ladder to the dinosaur age?\n",
      "\n",
      "Because they heard the T-Rex was a little \"short-tempered\" and wanted to reach new heights in their friendship!\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "joke_function = plugin[\"Joke\"]\n",
    "\n",
    "joke = await kernel.invoke(\n",
    "    joke_function,\n",
    "    KernelArguments(input=\"time travel to dinosaur age\", style=\"super silly\"),\n",
    ")\n",
    "print(joke)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece006e",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 1.3 running a prompt with web search plugin\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eee4e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the chat bot!    \n",
      "  Type 'exit' to exit.    \n",
      "  Try to search weather, news and more using bing search tool.\n",
      "Calling Bing search with arguments:\n",
      "  Query: \"today's news\"\n",
      "Bing search completed.\n",
      "SearchChatbot:> Here are some of today's news highlights:\n",
      "\n",
      "1. **CNN** - Offers the latest news and breaking news today for the U.S., world, weather, entertainment, politics, and health.\n",
      "   \n",
      "2. **SVT Nyheter** - Provides updates on the day's most important news, live local news, weather, reviews, and sports.\n",
      "\n",
      "3. **CBS News** - Covers breaking news and today's top headlines, focusing on significant stories with balanced reporting.\n",
      "\n",
      "4. **Sky News** - Delivers breaking news, headlines, and top stories from business, politics, entertainment, and more, both in the UK and worldwide.\n",
      "\n",
      "5. A study suggests that counting calories or fasting yields the best results for weight loss. NATO reports on dwindling supplies, which may impact Russian capabilities. Additionally, there are concerns about Russian disinformation and its implications for security.\n",
      "\n",
      "If you want more detailed information on any specific topic, let me know!\n",
      "Calling Bing search with arguments:\n",
      "  Query: \"today's news\"\n",
      "Bing search completed.\n",
      "SearchChatbot:> Here are some highlights from today's news:\n",
      "\n",
      "1. **CNN** - Offers the latest breaking news for the U.S., world, weather, entertainment, politics, and health.\n",
      "\n",
      "2. **SVT Nyheter** - Provides updates on the day's most important news, including live local news, weather, reviews, and sports.\n",
      "\n",
      "3. **CBS News** - Covers breaking news and today's top headlines, focusing on significant stories with balanced reporting.\n",
      "\n",
      "4. A recent study suggests that counting calories or fasting yields the best results for weight loss. There are reports of dwindling supplies according to NATO, which may impact Russian capabilities. Additionally, concerns about Russian disinformation have been raised, particularly regarding security.\n",
      "\n",
      "5. **BBC** - Provides live updates and content about world news.\n",
      "\n",
      "If you would like more details on any specific story, feel free to ask!\n",
      "\n",
      "\n",
      "Exiting chat...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kernel = Kernel()\n",
    "kernel.add_service(AzureChatCompletion(service_id=\"chat\"))\n",
    "kernel.add_plugin(KernelPlugin.from_text_search_with_search(\n",
    "        BingSearch(),\n",
    "        plugin_name=\"bing\",\n",
    "        description=\"Search the web information using bing search.\",\n",
    "        parameters=[\n",
    "            KernelParameterMetadata(\n",
    "                name=\"query\",\n",
    "                description=\"The search query.\",\n",
    "                type=\"str\",\n",
    "                is_required=True,\n",
    "                type_object=str,\n",
    "            ),\n",
    "            KernelParameterMetadata(\n",
    "                name=\"top\",\n",
    "                description=\"The number of results to return.\",\n",
    "                type=\"int\",\n",
    "                is_required=False,\n",
    "                default_value=2,\n",
    "                type_object=int,\n",
    "            ),\n",
    "            KernelParameterMetadata(\n",
    "                name=\"skip\",\n",
    "                description=\"The number of results to skip.\",\n",
    "                type=\"int\",\n",
    "                is_required=False,\n",
    "                default_value=0,\n",
    "                type_object=int,\n",
    "            ),\n",
    "            # KernelParameterMetadata(\n",
    "            #     name=\"site\",\n",
    "            #     description=\"The site to search.\",\n",
    "            #     default_value=\"https://github.com/microsoft/semantic-kernel/tree/main/python\",\n",
    "            #     type=\"str\",\n",
    "            #     is_required=False,\n",
    "            #     type_object=str,\n",
    "            # ),\n",
    "        ],\n",
    "    ))\n",
    "\n",
    "chat_function = kernel.add_function(\n",
    "    prompt=\"{{$chat_history}}{{$user_input}}\",\n",
    "    plugin_name=\"ChatBot\",\n",
    "    function_name=\"Chat\",\n",
    ")\n",
    "execution_settings = AzureChatPromptExecutionSettings(\n",
    "    service_id=\"chat\",\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8,\n",
    "    function_choice_behavior=FunctionChoiceBehavior.Auto(auto_invoke=True),\n",
    ")\n",
    "\n",
    "history = ChatHistory()\n",
    "system_message = \"\"\"\n",
    "You are a chat bot, use bing plugin to find answers.\n",
    "\"\"\"\n",
    "history.add_system_message(system_message)\n",
    "history.add_user_message(\"Hi there, who are you?\")\n",
    "history.add_assistant_message(\"I am Information Finder, a chat bot. use bing plugin to find answers.\")\n",
    "\n",
    "arguments = KernelArguments(settings=execution_settings)\n",
    "\n",
    "@kernel.filter(filter_type=FilterTypes.FUNCTION_INVOCATION)\n",
    "async def log_bing_filter(\n",
    "    context: FunctionInvocationContext, next: Callable[[FunctionInvocationContext], Awaitable[None]]\n",
    "):\n",
    "    if context.function.plugin_name == \"bing\":\n",
    "        print(\"Calling Bing search with arguments:\")\n",
    "        if \"query\" in context.arguments:\n",
    "            print(f'  Query: \"{context.arguments[\"query\"]}\"')\n",
    "        if \"count\" in context.arguments:\n",
    "            print(f'  Count: \"{context.arguments[\"count\"]}\"')\n",
    "        if \"skip\" in context.arguments:\n",
    "            print(f'  Skip: \"{context.arguments[\"skip\"]}\"')\n",
    "        await next(context)\n",
    "        print(\"Bing search completed.\")\n",
    "    else:\n",
    "        await next(context)\n",
    "\n",
    "\n",
    "async def chat() -> bool:\n",
    "    try:\n",
    "        user_input = input(\"User:> \")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "    except EOFError:\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "\n",
    "    if user_input == \"exit\":\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "    arguments[\"user_input\"] = user_input\n",
    "    arguments[\"chat_history\"] = history\n",
    "    result = await kernel.invoke(chat_function, arguments=arguments)\n",
    "    print(f\"SearchChatbot:> {result}\")\n",
    "    history.add_user_message(user_input)\n",
    "    history.add_assistant_message(str(result))\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "chatting = True\n",
    "print(\n",
    "    \"Welcome to the chat bot!\\\n",
    "    \\n  Type 'exit' to exit.\\\n",
    "    \\n  Try to search weather, news and more using bing search tool.\"\n",
    ")\n",
    "while chatting:\n",
    "    chatting = await chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8505e28c",
   "metadata": {},
   "source": [
    "# Use single agent to chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6154e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# The following sample demonstrates how to create a simple,       #\n",
    "# Azure AI agent, ChatCompletionAgent, AzureResponsesAgent        #\n",
    "# that answers questions about a sample menu                      #\n",
    "# using a Semantic Kernel Plugin.                                 #\n",
    "###################################################################\n",
    "\n",
    "\n",
    "# Define a sample plugin for the sample\n",
    "class MenuPlugin:\n",
    "    \"\"\"A sample Menu Plugin used for the concept sample.\"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Provides a list of specials from the menu.\")\n",
    "    def get_specials(self) -> Annotated[str, \"Returns the specials from the menu.\"]:\n",
    "        return \"\"\"\n",
    "        Special Soup: Clam Chowder\n",
    "        Special Salad: Cobb Salad\n",
    "        Special Drink: Chai Tea\n",
    "        \"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Provides the price of the requested menu item.\")\n",
    "    def get_item_price(\n",
    "        self, menu_item: Annotated[str, \"The name of the menu item.\"]\n",
    "    ) -> Annotated[str, \"Returns the price of the menu item.\"]:\n",
    "        return \"$9.99\"\n",
    "\n",
    "\n",
    "# Simulate a conversation with the agent\n",
    "USER_INPUTS = [\n",
    "    \"Hello\",\n",
    "    \"What is the special soup?\",\n",
    "    \"How much does that cost?\",\n",
    "    \"Thank you\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f952185",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 2.1 chat with Azure AI Agent \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65844e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_415008/988828850.py:9: RuntimeWarning: coroutine 'AgentsOperations.create_agent' was never awaited\n",
      "  agent_definition = await client.agents.create_agent(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: Hello\n",
      "# Host: Hi there! How can I assist you today?\n",
      "# User: What is the special soup?\n",
      "# Host: The special soup is Clam Chowder. Would you like to know more about it or anything else on the menu?\n",
      "# User: How much does that cost?\n",
      "# Host: The Clam Chowder costs $9.99. If you have any other questions or need further assistance, feel free to ask!\n",
      "# User: Thank you\n",
      "# Host: You're welcome! If you need anything else, just let me know. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "# Make sure to set the environment variables for the Azure AI Agent\n",
    "ai_agent_settings = AzureAIAgentSettings.create()\n",
    "\n",
    "async with (\n",
    "    DefaultAzureCredential() as creds,\n",
    "    AzureAIAgent.create_client(credential=creds) as client,\n",
    "):\n",
    "    # 1. Create an agent on the Azure AI agent service\n",
    "    agent_definition = await client.agents.create_agent(\n",
    "        model=ai_agent_settings.model_deployment_name,\n",
    "        name=\"Host\",\n",
    "        instructions=\"Answer questions about the menu.\",\n",
    "    )\n",
    "\n",
    "    # 2. Create a Semantic Kernel agent for the Azure AI agent\n",
    "    agent = AzureAIAgent(\n",
    "        client=client,\n",
    "        definition=agent_definition,\n",
    "        plugins=[MenuPlugin()],  # Add the plugin to the agent\n",
    "    )\n",
    "\n",
    "    # 3. Create a thread for the agent\n",
    "    # If no thread is provided, a new thread will be\n",
    "    # created and returned with the initial response\n",
    "    thread: AzureAIAgentThread = None\n",
    "\n",
    " \n",
    "    for user_input in USER_INPUTS:\n",
    "        print(f\"# User: {user_input}\")\n",
    "        # 4. Invoke the agent for the specified thread for response\n",
    "        async for response in agent.invoke(\n",
    "            messages=user_input,\n",
    "            thread=thread,\n",
    "        ):\n",
    "            print(f\"# {response.name}: {response}\")\n",
    "            thread = response.thread\n",
    "    \n",
    "    await thread.delete() if thread else None    \n",
    "\n",
    "########################################\n",
    "# invoke_stream mode \n",
    "########################################\n",
    "    # try:\n",
    "    #     for user_input in USER_INPUTS:\n",
    "    #         print(f\"# User: '{user_input}'\")\n",
    "    #         first_chunk = True\n",
    "    #         # 4. Invoke the agent for the current message and print the response\n",
    "    #         async for response in agent.invoke_stream(messages=user_input, thread=thread):\n",
    "    #             thread = response.thread\n",
    "    #             if first_chunk:\n",
    "    #                 print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "    #                 first_chunk = False\n",
    "    #             print(response.content, end=\"\", flush=True)\n",
    "    #         print()\n",
    "    # finally:\n",
    "    #         # Cleanup: Delete the thread and agent\n",
    "    #         await thread.delete() if thread else None\n",
    "    #         await client.agents.delete_agent(agent.id)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024625db",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 2.2 chat with ChatCompletionAgent\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68221ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: Hello\n",
      "# Host: Hello! How can I assist you today? \n",
      "# User: What is the special soup?\n",
      "# Host: The special soup is Clam Chowder. Is there anything else you'd like to know? \n",
      "# User: How much does that cost?\n",
      "# Host: The Clam Chowder costs $9.99. Would you like to know anything else? \n",
      "# User: Thank you\n",
      "# Host: You're welcome! If you have any more questions in the future, feel free to ask. Have a great day! \n"
     ]
    }
   ],
   "source": [
    "agent = ChatCompletionAgent(\n",
    "        service=AzureChatCompletion(),\n",
    "        name=\"Host\",\n",
    "        instructions=\"Answer questions based on web search\",\n",
    "        plugins=[MenuPlugin()],\n",
    "    )\n",
    "\n",
    "# 2. Create a thread to hold the conversation\n",
    "# If no thread is provided, a new thread will be\n",
    "# created and returned with the initial response\n",
    "thread: ChatHistoryAgentThread = None\n",
    "\n",
    "for user_input in USER_INPUTS:\n",
    "    print(f\"# User: {user_input}\")\n",
    "    # 4. Invoke the agent for a response\n",
    "    response = await agent.get_response(messages=user_input, thread=thread)\n",
    "    print(f\"# {response.name}: {response} \")\n",
    "    thread = response.thread\n",
    "\n",
    "########################################\n",
    "# invoke_stream mode \n",
    "########################################\n",
    "# for user_input in USER_INPUTS:\n",
    "#         print(f\"# User: '{user_input}'\")\n",
    "#         first_chunk = True\n",
    "#         # 4. Invoke the agent for the current message and print the response\n",
    "#         async for response in agent.invoke_stream(messages=user_input, thread=thread):\n",
    "#             thread = response.thread\n",
    "#             if first_chunk:\n",
    "#                 print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "#                 first_chunk = False\n",
    "#             print(response.content, end=\"\", flush=True)\n",
    "#         print()\n",
    "\n",
    "\n",
    "await thread.delete() if thread else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732bbee4",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 2.3 chat with ResponseAgent (OpenAI Responses API)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f82cb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'Hello'\n",
      "# Host: Hello! How can I assist you today?\n",
      "# User: 'What is the special soup?'\n",
      "# Host: The special soup is Clam Chowder. Would you like to know more about anything else?\n",
      "# User: 'How much does that cost?'\n",
      "# Host: The Clam Chowder costs $9.99. Would you like to explore more options?\n",
      "# User: 'Thank you'\n",
      "# Host: You're welcome! If you have any more questions, feel free to ask. Enjoy your day!\n"
     ]
    }
   ],
   "source": [
    "client, model = AzureResponsesAgent.setup_resources()\n",
    "\n",
    "# 2. Create a Semantic Kernel agent for the OpenAI Responses API\n",
    "agent = AzureResponsesAgent(\n",
    "    ai_model_id=model,\n",
    "    client=client,\n",
    "    instructions=\"Answer questions about the menu.\",\n",
    "    name=\"Host\",\n",
    "    plugins=[MenuPlugin()],\n",
    ")\n",
    "\n",
    "# 3. Create a thread for the agent\n",
    "# If no thread is provided, a new thread will be\n",
    "# created and returned with the initial response\n",
    "thread: ResponsesAgentThread = None\n",
    "\n",
    "for user_input in USER_INPUTS:\n",
    "    print(f\"# User: '{user_input}'\")\n",
    "    # 4. Invoke the agent for the current message and print the response\n",
    "    response = await agent.get_response(messages=user_input, thread=thread)\n",
    "    print(f\"# {response.name}: {response.content}\")\n",
    "    thread = response.thread\n",
    "\n",
    "########################################\n",
    "# invoke_stream mode \n",
    "########################################\n",
    "# for user_input in USER_INPUTS:\n",
    "#         print(f\"# User: '{user_input}'\")\n",
    "#         first_chunk = True\n",
    "#         # 4. Invoke the agent for the current message and print the response\n",
    "#         async for response in agent.invoke_stream(messages=user_input, thread=thread):\n",
    "#             thread = response.thread\n",
    "#             if first_chunk:\n",
    "#                 print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "#                 first_chunk = False\n",
    "#             print(response.content, end=\"\", flush=True)\n",
    "#         print()\n",
    "\n",
    "await thread.delete() if thread else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005cd7ce",
   "metadata": {},
   "source": [
    "# Use Multi Agent for group chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c76aae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApprovalTerminationStrategy(TerminationStrategy):\n",
    "    \"\"\"A strategy for determining when an agent should terminate.\"\"\"\n",
    "\n",
    "    async def should_agent_terminate(self, agent, history):\n",
    "        \"\"\"Check if the agent should terminate.\"\"\"\n",
    "        return \"approved\" in history[-1].content.lower()\n",
    "\n",
    "\n",
    "REVIEWER_NAME = \"ArtDirector\"\n",
    "REVIEWER_INSTRUCTIONS = \"\"\"\n",
    "You are an art director who has opinions about copywriting born of a love for David Ogilvy.\n",
    "The goal is to determine if the given copy is acceptable to print.\n",
    "If so, state that it is approved.  Do not use the word \"approve\" unless you are giving approval.\n",
    "If not, provide insight on how to refine suggested copy without example.\n",
    "\"\"\"\n",
    "\n",
    "COPYWRITER_NAME = \"CopyWriter\"\n",
    "COPYWRITER_INSTRUCTIONS = \"\"\"\n",
    "You are a copywriter with ten years of experience and are known for brevity and a dry humor.\n",
    "The goal is to refine and decide on the single best copy as an expert in the field.\n",
    "Only provide a single proposal per response.\n",
    "You're laser focused on the goal at hand.\n",
    "Don't waste time with chit chat.\n",
    "Consider suggestions when refining an idea.\n",
    "\"\"\"\n",
    "\n",
    "TASK = \"a slogan for a new line of electric cars.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9840b",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 3.1 group chat with Azure AI Agent \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bedbc3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AuthorRole.USER: 'a slogan for a new line of electric cars.'\n",
      "# AuthorRole.ASSISTANT - CopyWriter: '\"Charge Forward. Drive Future.\"'\n",
      "# AuthorRole.ASSISTANT - ArtDirector: 'The suggested slogan succinctly captures the essence of innovation and sustainability. It creates an emotional connection to progress, which is vital in persuasive copywriting. However, if it's meant to have broader appeal, consider ensuring it resonates with both environmental consciousness and technological advancement, so it speaks to a wider audience.'\n",
      "# AuthorRole.ASSISTANT - CopyWriter: 'Apologies for the repetition earlier. Let's refine the idea further. \n",
      "\n",
      "Proposed slogan: \"Silent Power. Bold Future.\"'\n",
      "# AuthorRole.ASSISTANT - ArtDirector: 'The proposed slogan effectively communicates the core benefits of electric vehicles, focusing on their quiet operation and promise for the future. To enhance it, consider ensuring the wording creates an emotional response that connects deeper with the values and aspirations of the target audience.'\n",
      "# AuthorRole.ASSISTANT - CopyWriter: '\"Silent Power. Bold Future.\"'\n",
      "# AuthorRole.ASSISTANT - ArtDirector: 'This slogan strikes a good balance by emphasizing the unique features of electric vehiclesâ€”quiet operation and forward-thinking technology. To make it more impactful, it could benefit from a stronger call to action or a hint of exclusivity to instill a sense of urgency or belonging among potential buyers.'\n",
      "# AuthorRole.ASSISTANT - CopyWriter: '\"Silent Power. Bold Future.\"'\n",
      "# AuthorRole.ASSISTANT - ArtDirector: 'This slogan effectively highlights key attributes of electric carsâ€”quiet operation paired with a modern vision. To refine it, consider creating a stronger emotional response by connecting with the audienceâ€™s aspirations or address how the cars integrate into their lifestyle while reinforcing the brand identity.'\n",
      "# AuthorRole.ASSISTANT - CopyWriter: '\"Silent Power. Bold Future.\"'\n",
      "# AuthorRole.ASSISTANT - ArtDirector: 'This slogan effectively highlights the unique features of electric carsâ€”quietness and innovation. To refine the impact, consider emphasizing an emotional connection that speaks to the audience's aspirations or lifestyle integration, enhancing the message's personal relevance and motivational power.'\n"
     ]
    }
   ],
   "source": [
    "TASK = \"a slogan for a new line of electric cars.\"\n",
    "\n",
    "ai_agent_settings = AzureAIAgentSettings.create()\n",
    "\n",
    "async with (\n",
    "    DefaultAzureCredential() as creds,\n",
    "    AzureAIAgent.create_client(credential=creds) as client,\n",
    "):\n",
    "    # 1. Create the reviewer agent on the Azure AI agent service\n",
    "    reviewer_agent_definition = await client.agents.create_agent(\n",
    "        model=ai_agent_settings.model_deployment_name,\n",
    "        name=REVIEWER_NAME,\n",
    "        instructions=REVIEWER_INSTRUCTIONS,\n",
    "    )\n",
    "\n",
    "    # 2. Create a Semantic Kernel agent for the reviewer Azure AI agent\n",
    "    agent_reviewer = AzureAIAgent(\n",
    "        client=client,\n",
    "        definition=reviewer_agent_definition,\n",
    "    )\n",
    "\n",
    "    # 3. Create the copy writer agent on the Azure AI agent service\n",
    "    copy_writer_agent_definition = await client.agents.create_agent(\n",
    "        model=ai_agent_settings.model_deployment_name,\n",
    "        name=COPYWRITER_NAME,\n",
    "        instructions=COPYWRITER_INSTRUCTIONS,\n",
    "    )\n",
    "\n",
    "    # 4. Create a Semantic Kernel agent for the copy writer Azure AI agent\n",
    "    agent_writer = AzureAIAgent(\n",
    "        client=client,\n",
    "        definition=copy_writer_agent_definition,\n",
    "    )\n",
    "\n",
    "    # 5. Place the agents in a group chat with a custom termination strategy\n",
    "    chat = AgentGroupChat(\n",
    "        agents=[agent_writer, agent_reviewer],\n",
    "        termination_strategy=ApprovalTerminationStrategy(agents=[agent_reviewer], maximum_iterations=10),\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # 6. Add the task as a message to the group chat\n",
    "        await chat.add_chat_message(message=TASK)\n",
    "        print(f\"# {AuthorRole.USER}: '{TASK}'\")\n",
    "        # 7. Invoke the chat\n",
    "        async for content in chat.invoke():\n",
    "            print(f\"# {content.role} - {content.name or '*'}: '{content.content}'\")\n",
    "    finally:\n",
    "        # 8. Cleanup: Delete the agents\n",
    "        await chat.reset()\n",
    "        await client.agents.delete_agent(agent_reviewer.id)\n",
    "        await client.agents.delete_agent(agent_writer.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eee1a1",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 4.2 group chat with ChatCompletionAgent\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "940c849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: a slogan for a new line of electric cars.\n",
      "# CopyWriter: \"Plug In. Drive Out. Save the Planet.\"\n",
      "# ArtDirector: The slogan is catchy and conveys a message of environmental responsibility, but it could be refined for greater emotional impact and clarity. Consider emphasizing the benefits of driving electric cars more directlyâ€”like innovation or freedomâ€”while maintaining an invitation to action. Focus on what sets the cars apart or how they enhance the driving experience.\n",
      "# CopyWriter: \"Go Electric. Drive the Future.\"\n",
      "# ArtDirector: The slogan is clear and forward-thinking, which aligns well with the innovative nature of electric cars. However, it could benefit from a stronger emotional connection. Consider infusing a sense of adventure or a vision for a sustainable future to inspire potential customers further. Aim for a phrase that not only informs but also resonates deeply with the audienceâ€™s desires and aspirations.\n",
      "# CopyWriter: \"Electrify Your Drive. Change the World.\"\n",
      "# ArtDirector: The slogan has strong motivational elements and encapsulates the transformative potential of electric vehicles. However, it could be refined to ensure the message is more concise and impactful. Consider focusing on the personal benefit of the experience while connecting it with the larger purpose. Strive for clarity and a memorable rhythm that encourages immediate recognition and recall.\n",
      "# CopyWriter: \"Charge Ahead. Drive Change.\"\n",
      "# ArtDirector: The slogan is succinct and conveys a sense of progress and action, which is fitting for electric cars. However, it might be improved by adding a clearer association with the benefits of switching to electric vehicles, such as sustainability or innovation. Ensure that the phrase resonates both on a personal level and within the broader context of environmental impact. A little more specificity could enhance its appeal.\n",
      "# CopyWriter: \"Drive Electric. Live Green.\"\n",
      "# ArtDirector: The slogan is clear and aligns well with the eco-friendly message of electric cars. Nonetheless, it could be refined by enhancing its emotional appeal or highlighting the lifestyle change that comes with choosing electric. Consider incorporating a sense of empowerment or excitement to make it more memorable and engaging for the audience. Strive for a balance between clarity and inspiration.\n"
     ]
    }
   ],
   "source": [
    "TASK = \"a slogan for a new line of electric cars.\"\n",
    "\n",
    "def _create_kernel_with_chat_completion(service_id: str) -> Kernel:\n",
    "    kernel = Kernel()\n",
    "    kernel.add_service(AzureChatCompletion(service_id=service_id))\n",
    "    return kernel\n",
    "\n",
    "# 1. Create the reviewer agent based on the chat completion service\n",
    "agent_reviewer = ChatCompletionAgent(\n",
    "    kernel=_create_kernel_with_chat_completion(\"artdirector\"),\n",
    "    name=REVIEWER_NAME,\n",
    "    instructions=REVIEWER_INSTRUCTIONS,\n",
    ")\n",
    "\n",
    "# 2. Create the copywriter agent based on the chat completion service\n",
    "agent_writer = ChatCompletionAgent(\n",
    "    kernel=_create_kernel_with_chat_completion(\"copywriter\"),\n",
    "    name=COPYWRITER_NAME,\n",
    "    instructions=COPYWRITER_INSTRUCTIONS,\n",
    ")\n",
    "\n",
    "# 3. Place the agents in a group chat with a custom termination strategy\n",
    "group_chat = AgentGroupChat(\n",
    "    agents=[\n",
    "        agent_writer,\n",
    "        agent_reviewer,\n",
    "    ],\n",
    "    termination_strategy=ApprovalTerminationStrategy(\n",
    "        agents=[agent_reviewer],\n",
    "        maximum_iterations=10,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 4. Add the task as a message to the group chat\n",
    "await group_chat.add_chat_message(message=TASK)\n",
    "print(f\"# User: {TASK}\")\n",
    "\n",
    "# 5. Invoke the chat\n",
    "async for content in group_chat.invoke():\n",
    "    print(f\"# {content.name}: {content.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5c01be",
   "metadata": {},
   "source": [
    "# Use tools to answer specific questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f8d674",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 5.1 code interpreter with Azure AI Agent \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c502bca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'Use code to determine the values in the Fibonacci sequence that that are less then the value of 101.'\n",
      "# Agent: # Let's generate the Fibonacci sequence and find the values less than 101.\n",
      "\n",
      "def fibonacci_under_101():\n",
      "    fibonacci_sequence = []\n",
      "    a, b = 0, 1\n",
      "    \n",
      "    while a < 101:\n",
      "        fibonacci_sequence.append(a)\n",
      "        a, b = b, a + b\n",
      "    \n",
      "    return fibonacci_sequence\n",
      "\n",
      "fibonacci_sequence_under_101 = fibonacci_under_101()\n",
      "fibonacci_sequence_under_101\n",
      "# Agent: The values in the Fibonacci sequence that are less than 101 are:\n",
      "\n",
      "\\[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89\\]\n"
     ]
    }
   ],
   "source": [
    "TASK = \"Use code to determine the values in the Fibonacci sequence that that are less then the value of 101.\"\n",
    "\n",
    "ai_agent_settings = AzureAIAgentSettings.create()\n",
    "\n",
    "async with (\n",
    "    DefaultAzureCredential() as creds,\n",
    "    AzureAIAgent.create_client(credential=creds) as client,\n",
    "):\n",
    "    # 1. Create an agent with a code interpreter on the Azure AI agent service\n",
    "    code_interpreter = CodeInterpreterTool()\n",
    "    agent_definition = await client.agents.create_agent(\n",
    "        model=ai_agent_settings.model_deployment_name,\n",
    "        tools=code_interpreter.definitions,\n",
    "        tool_resources=code_interpreter.resources,\n",
    "    )\n",
    "\n",
    "    # 2. Create a Semantic Kernel agent for the Azure AI agent\n",
    "    agent = AzureAIAgent(\n",
    "        client=client,\n",
    "        definition=agent_definition,\n",
    "    )\n",
    "\n",
    "    # 3. Create a thread for the agent\n",
    "    # If no thread is provided, a new thread will be\n",
    "    # created and returned with the initial response\n",
    "    thread: AzureAIAgentThread = None\n",
    "\n",
    "    try:\n",
    "        print(f\"# User: '{TASK}'\")\n",
    "        # 4. Invoke the agent for the specified thread for response\n",
    "        async for response in agent.invoke(messages=TASK, thread=thread):\n",
    "            if response.role != AuthorRole.TOOL:\n",
    "                print(f\"# Agent: {response}\")\n",
    "            thread = response.thread\n",
    "    finally:\n",
    "        # 6. Cleanup: Delete the thread and agent\n",
    "        await thread.delete() if thread else None\n",
    "        await client.agents.delete_agent(agent.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e22764b",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 5.2 open API with Azure AI Agent \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f81c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'What is the name and population of the country that uses currency with abbreviation KRW'\n",
      "# Agent: There was an issue retrieving the data automatically, but I can provide the information. The currency with the abbreviation \"KRW\" is the South Korean Won. The country that uses this currency is South Korea. As of the latest available estimates, the population of South Korea is approximately 52 million people.\n",
      "# User: 'What is the current weather in the capital city of the country?'\n",
      "# Agent: The current weather in Seoul, the capital city of South Korea, is clear with a temperature of 13Â°C (56Â°F). The wind is blowing from the west-northwest at a speed of 6 km/h (4 mph), and the humidity level is at 47%. The sky is clear with 0% cloud cover, and the visibility is good at 10 kilometers (6 miles).\n"
     ]
    }
   ],
   "source": [
    "USER_INPUTS = [\n",
    "    \"What is the name and population of the country that uses currency with abbreviation KRW\",\n",
    "    \"What is the current weather in the capital city of the country?\",\n",
    "]\n",
    "\n",
    "ai_agent_settings = AzureAIAgentSettings.create()\n",
    "\n",
    "async with (\n",
    "    DefaultAzureCredential() as creds,\n",
    "    AzureAIAgent.create_client(credential=creds) as client,\n",
    "):\n",
    "    # 1. Read in the OpenAPI spec files\n",
    "    openapi_spec_file_path = \"resources\"\n",
    "    with open(os.path.join(openapi_spec_file_path, \"weather.json\")) as weather_file:\n",
    "        weather_openapi_spec = json.loads(weather_file.read())\n",
    "    with open(os.path.join(openapi_spec_file_path, \"countries.json\")) as countries_file:\n",
    "        countries_openapi_spec = json.loads(countries_file.read())\n",
    "\n",
    "    # 2. Create OpenAPI tools\n",
    "    # Note that connection or managed identity auth setup requires additional setup in Azure\n",
    "    auth = OpenApiAnonymousAuthDetails()\n",
    "    openapi_weather = OpenApiTool(\n",
    "        name=\"get_weather\",\n",
    "        spec=weather_openapi_spec,\n",
    "        description=\"Retrieve weather information for a location\",\n",
    "        auth=auth,\n",
    "    )\n",
    "    openapi_countries = OpenApiTool(\n",
    "        name=\"get_country\",\n",
    "        spec=countries_openapi_spec,\n",
    "        description=\"Retrieve country information\",\n",
    "        auth=auth,\n",
    "    )\n",
    "\n",
    "    # 3. Create an agent on the Azure AI agent service with the OpenAPI tools\n",
    "    agent_definition = await client.agents.create_agent(\n",
    "        model=ai_agent_settings.model_deployment_name,\n",
    "        tools=openapi_weather.definitions + openapi_countries.definitions,\n",
    "    )\n",
    "\n",
    "    # 4. Create a Semantic Kernel agent for the Azure AI agent\n",
    "    agent = AzureAIAgent(\n",
    "        client=client,\n",
    "        definition=agent_definition,\n",
    "    )\n",
    "\n",
    "    # 5. Create a thread for the agent\n",
    "    # If no thread is provided, a new thread will be\n",
    "    # created and returned with the initial response\n",
    "    thread: AzureAIAgentThread = None\n",
    "\n",
    "    try:\n",
    "        for user_input in USER_INPUTS:\n",
    "            print(f\"# User: '{user_input}'\")\n",
    "            # 7. Invoke the agent for the specified thread for response\n",
    "            async for response in agent.invoke(messages=user_input, thread=thread):\n",
    "                if response.role != AuthorRole.TOOL:\n",
    "                    print(f\"# Agent: {response}\")\n",
    "                thread = response.thread\n",
    "    finally:\n",
    "        # 8. Cleanup: Delete the thread and agent\n",
    "        await client.agents.delete_thread(thread.id)\n",
    "        await client.agents.delete_agent(agent.id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be56f4a",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 5.3 bing search API as plugin with ChatCompletionAgent\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c636c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: What is today's weather in South Korea?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Host: Today's weather in South Korea, particularly in Seoul, is mostly clear with pleasant conditions. The maximum temperature is around 16Â°C (61Â°F), while the minimum temperature is expected to drop to about 6Â°C (43Â°F). Overall, the weather is quite mild for this time of year. \n",
      "\n",
      "For a wider view across South Korea, temperatures are generally chilly, with averages around 12Â°C (53.6Â°F) during the day and dropping to about 8Â°C (46.4Â°F) at night.\n",
      "\n",
      "Reference: [Bing Weather](https://www.bing.com/weather) \n"
     ]
    }
   ],
   "source": [
    "# Simulate a conversation with the agent\n",
    "USER_INPUTS = [\n",
    "    \"What is today's weather in South Korea?\"\n",
    "]\n",
    "from semantic_kernel.connectors.search.bing import BingSearch\n",
    "from semantic_kernel.functions import KernelArguments, KernelParameterMetadata, KernelPlugin\n",
    "\n",
    "webplugin = KernelPlugin.from_text_search_with_search(\n",
    "        BingSearch(api_key=os.getenv(\"BING_API_KEY\")),\n",
    "        plugin_name=\"bing\",\n",
    "        description=\"Search the web for information.\",\n",
    "        parameters=[\n",
    "            KernelParameterMetadata(\n",
    "                name=\"query\",\n",
    "                description=\"The search query.\",\n",
    "                type=\"str\",\n",
    "                is_required=True,\n",
    "                type_object=str,\n",
    "            ),\n",
    "            KernelParameterMetadata(\n",
    "                name=\"top\",\n",
    "                description=\"The number of results to return.\",\n",
    "                type=\"int\",\n",
    "                is_required=False,\n",
    "                default_value=1,\n",
    "                type_object=int,\n",
    "            ),\n",
    "            KernelParameterMetadata(\n",
    "                name=\"skip\",\n",
    "                description=\"The number of results to skip.\",\n",
    "                type=\"int\",\n",
    "                is_required=False,\n",
    "                default_value=0,\n",
    "                type_object=int,\n",
    "            ),\n",
    "            # KernelParameterMetadata(\n",
    "            #     name=\"site\",\n",
    "            #     description=\"The site to search.\",\n",
    "            #     default_value=\"https://github.com/microsoft/semantic-kernel/tree/main/python\",\n",
    "            #     type=\"str\",\n",
    "            #     is_required=False,\n",
    "            #     type_object=str,\n",
    "            # ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "agent = ChatCompletionAgent(\n",
    "        service=AzureChatCompletion(),\n",
    "        name=\"Host\",\n",
    "        instructions=\"Answer questions from web search results. Add the web search reference url to the answer.\",\n",
    "        plugins=[webplugin],\n",
    "    )\n",
    "\n",
    "# 2. Create a thread to hold the conversation\n",
    "# If no thread is provided, a new thread will be\n",
    "# created and returned with the initial response\n",
    "thread: ChatHistoryAgentThread = None\n",
    "\n",
    "for user_input in USER_INPUTS:\n",
    "    print(f\"# User: {user_input}\")\n",
    "    # 4. Invoke the agent for a response\n",
    "    response = await agent.get_response(messages=user_input, thread=thread)\n",
    "    print(f\"# {response.name}: {response} \")\n",
    "    thread = response.thread\n",
    "\n",
    "\n",
    "########################################\n",
    "# invoke_stream mode \n",
    "########################################\n",
    "# for user_input in USER_INPUTS:\n",
    "#         print(f\"# User: '{user_input}'\")\n",
    "#         first_chunk = True\n",
    "#         # 4. Invoke the agent for the current message and print the response\n",
    "#         async for response in agent.invoke_stream(messages=user_input, thread=thread):\n",
    "#             thread = response.thread\n",
    "#             if first_chunk:\n",
    "#                 print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "#                 first_chunk = False\n",
    "#             print(response.content, end=\"\", flush=True)\n",
    "#         print()\n",
    "\n",
    "await thread.delete() if thread else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bb7922",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 5.4 file search tool with AzureAssistantAgent (Open AI Asisstant)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88bb7af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'Who is the youngest employee?'\n",
      "# Agent: The youngest employee is Teodor Britton, who was born on January 9, 1997ã€4:0â€ sourceã€‘.\n",
      "# User: 'I have a customer request, who can help me?'\n",
      "# Agent: The file contains information that Brendon Hilpert is listed as an administrative assistant, which may be a good point of contact for customer requestsã€8:0â€ sourceã€‘.\n",
      "# User: 'Who works in sales?'\n",
      "# Agent: The employees who work in sales are:\n",
      "\n",
      "1. Mariam Jaslyn - Sales Representative (Born September 23, 1975)\n",
      "2. Hicran Bea - Sales Manager (Born October 15, 1991)\n",
      "3. Angelino Embla - Sales Representative (Born November 20, 1973)ã€12:0â€ sourceã€‘.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Simulate a conversation with the agent\n",
    "USER_INPUTS = {\n",
    "    \"Who is the youngest employee?\",\n",
    "    \"Who works in sales?\",\n",
    "    \"I have a customer request, who can help me?\",\n",
    "}\n",
    "\n",
    "\n",
    "# 1. Create the client using Azure OpenAI resources and configuration\n",
    "client, model = AzureAssistantAgent.setup_resources()\n",
    "\n",
    "# 2. Read and upload the file to the Azure OpenAI assistant service\n",
    "pdf_file_path = \"resources/employees.pdf\"\n",
    "\n",
    "\n",
    "with open(pdf_file_path, \"rb\") as file:\n",
    "    file = await client.files.create(file=file, purpose=\"assistants\")\n",
    "\n",
    "vector_store = await client.vector_stores.create(\n",
    "    name=\"step4_assistant_file_search\",\n",
    "    file_ids=[file.id],\n",
    ")\n",
    "\n",
    "# 3. Create file search tool with uploaded resources\n",
    "file_search_tool, file_search_tool_resources = AzureAssistantAgent.configure_file_search_tool(vector_store.id)\n",
    "\n",
    "# 4. Create the assistant on the Azure OpenAI service with the file search tool\n",
    "definition = await client.beta.assistants.create(\n",
    "    model=model,\n",
    "    instructions=\"Find answers to the user's questions in the provided file.\",\n",
    "    name=\"FileSearch\",\n",
    "    tools=file_search_tool,\n",
    "    tool_resources=file_search_tool_resources,\n",
    ")\n",
    "\n",
    "# 5. Create a Semantic Kernel agent for the Azure OpenAI assistant\n",
    "agent = AzureAssistantAgent(\n",
    "    client=client,\n",
    "    definition=definition,\n",
    ")\n",
    "\n",
    "# 6. Create a new thread for use with the assistant\n",
    "# If no thread is provided, a new thread will be\n",
    "# created and returned with the initial response\n",
    "thread: AssistantAgentThread = None\n",
    "\n",
    "try:\n",
    "    for user_input in USER_INPUTS:\n",
    "        print(f\"# User: '{user_input}'\")\n",
    "        # 7. Invoke the agent for the current thread and print the response\n",
    "        async for response in agent.invoke(messages=user_input, thread=thread):\n",
    "            print(f\"# Agent: {response}\")\n",
    "            thread = response.thread\n",
    "finally:\n",
    "    # 9. Clean up the resources\n",
    "    await client.files.delete(file.id)\n",
    "    await client.vector_stores.delete(vector_store.id)\n",
    "    await client.beta.threads.delete(thread.id)\n",
    "    await client.beta.assistants.delete(agent.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d8159",
   "metadata": {},
   "source": [
    "## ðŸ§ª Case 5.5 BingGrounding with Azure AI Agent (Optional)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ed132a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message, ID: msg_ocJBMUOoMiCY5Imm6lX8K2CB\n",
      "Messages: {'object': 'list', 'data': [{'id': 'msg_OraNcshlelmpio9pNp5KE1yR', 'object': 'thread.message', 'created_at': 1744198307, 'assistant_id': 'asst_BNeAiWk7nSSiltnTD37IZKgV', 'thread_id': 'thread_uIvSawffz1FaSoz0P4PZppNC', 'run_id': 'run_Nli8etflAa2aWQRicM18ItVG', 'role': 'assistant', 'content': [{'type': 'text', 'text': {'value': 'Today, April 9, 2025, the weather in Seoul, South Korea, is expected to be mild with a high of around 62Â°F (approximately 16.7Â°C) and a low of 50Â°F (approximately 10Â°C). There might be some light rain, with about 0.01 inches of precipitation expectedã€3:0â€ sourceã€‘.', 'annotations': [{'type': 'url_citation', 'text': 'ã€3:0â€ sourceã€‘', 'start_index': 250, 'end_index': 262, 'url_citation': {'url': 'https://www.weather25.com/asia/south-korea/seoul?page=month&month=April', 'title': 'Seoul weather in April 2025 | Seoul 14 day weather'}}]}}], 'attachments': [], 'metadata': {}}, {'id': 'msg_ocJBMUOoMiCY5Imm6lX8K2CB', 'object': 'thread.message', 'created_at': 1744198304, 'assistant_id': None, 'thread_id': 'thread_uIvSawffz1FaSoz0P4PZppNC', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': \"What is today's weather in South Korea?\", 'annotations': []}}], 'attachments': [], 'metadata': {}}], 'first_id': 'msg_OraNcshlelmpio9pNp5KE1yR', 'last_id': 'msg_ocJBMUOoMiCY5Imm6lX8K2CB', 'has_more': False}\n",
      "Message ID: msg_OraNcshlelmpio9pNp5KE1yR\n",
      "Role: assistant\n",
      "Content: Today, April 9, 2025, the weather in Seoul, South Korea, is expected to be mild with a high of around 62Â°F (approximately 16.7Â°C) and a low of 50Â°F (approximately 10Â°C). There might be some light rain, with about 0.01 inches of precipitation expectedã€3:0â€ sourceã€‘.\n",
      "Created At: 1744198307\n",
      "Metadata: {}\n",
      "URL: https://www.weather25.com/asia/south-korea/seoul?page=month&month=April\n",
      "Title: Seoul weather in April 2025 | Seoul 14 day weather\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects.models import BingGroundingTool\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "USER_INPUTS = [\n",
    "    \"What is today's weather in South Korea?\",\n",
    "    \"What is the new hotels in NYC 2025?\",\n",
    "]\n",
    "\n",
    "creds = DefaultAzureCredential()\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=creds,\n",
    "    conn_str=os.getenv(\"AZURE_AI_AGENT_PROJECT_CONNECTION_STRING\"),\n",
    ")\n",
    "bing_connection = project_client.connections.get(\n",
    "    connection_name=os.getenv(\"BING_GROUNDING_CONNECTION_NAME\"),\n",
    ")\n",
    "conn_id = bing_connection.id\n",
    "\n",
    "\n",
    "# 1. Create an agent with a code interpreter on the Azure AI agent service\n",
    "bing = BingGroundingTool(connection_id=conn_id)\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=os.getenv(\"AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME\"),\n",
    "        name=\"my-bing-agent\",\n",
    "        instructions=\"You are a helpful assistant\",\n",
    "        tools=bing.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"}\n",
    "    )\n",
    "    #if you want to use existing agent, you can use the following code\n",
    "    # agent = project_client.agents.get_agent(agent_id=\"your agent id\")\n",
    "    \n",
    "    # Create thread for communication\n",
    "    thread = project_client.agents.create_thread()\n",
    "    \n",
    "    # Create message to thread\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=USER_INPUTS[0],\n",
    "    )\n",
    "    print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=agent.id)\n",
    "    \n",
    "    run_steps = project_client.agents.list_run_steps(run_id=run.id, thread_id=thread.id)\n",
    "    run_steps_data = run_steps['data']\n",
    "    \n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "    # Delete the assistant when done\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    \n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(f\"Messages: {messages}\")\n",
    "    \n",
    "    for msg in messages['data']:\n",
    "        if msg['role'] == 'assistant':\n",
    "            print(f\"Message ID: {msg['id']}\")\n",
    "            print(f\"Role: {msg['role']}\")\n",
    "            print(f\"Content: {msg['content'][0]['text']['value']}\")\n",
    "            print(f\"Created At: {msg['created_at']}\")\n",
    "            print(f\"Metadata: {msg['metadata']}\")\n",
    "            \n",
    "            # Print URL information if available\n",
    "            annotations = msg['content'][0]['text'].get('annotations', [])\n",
    "            for annotation in annotations:\n",
    "                if annotation['type'] == 'url_citation':\n",
    "                    url_info = annotation['url_citation']\n",
    "                    print(f\"URL: {url_info['url']}\")\n",
    "                    print(f\"Title: {url_info['title']}\")\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a1438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
