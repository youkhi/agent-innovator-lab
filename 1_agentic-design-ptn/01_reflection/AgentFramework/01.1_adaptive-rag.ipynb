{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bbbcc5",
   "metadata": {},
   "source": [
    "# Adaptive RAG with Microsoft Agent Framework\n",
    "\n",
    "----\n",
    "\n",
    "Adaptive RAG predicts the **complexity of the input question** using a SLM/LLM and selects an appropriate processing workflow accordingly.\n",
    "\n",
    "- **Very simple question (No Retrieval)**: Generates answers without RAG.\n",
    "- **Simple question (Single-shot RAG)**: Efficiently generates answers through a single-step search and generation.\n",
    "- **Complex question (Iterative RAG)**: Provides accurate answers to complex questions through repeated multi-step search and generation.\n",
    "\n",
    "This notebook demonstrates how to implement Adaptive RAG using **Microsoft Agent Framework** with:\n",
    "- **Workflow-based orchestration** for multi-step processing\n",
    "- **Reflection pattern** for quality evaluation and retry logic\n",
    "- **Azure AI Search** for document retrieval\n",
    "- **Azure Evaluation SDK** for groundedness and relevance checking\n",
    "\n",
    "**Reference**\n",
    "\n",
    "- [Adaptive-RAG paper](https://arxiv.org/abs/2403.14403)\n",
    "- [Microsoft Agent Framework Documentation](https://learn.microsoft.com/en-us/agent-framework/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58602e0",
   "metadata": {},
   "source": [
    "## Setup\n",
    "---\n",
    "\n",
    "Install required packages and import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97fe602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Microsoft Agent Framework and required packages\n",
    "# %pip install agent-framework azure-search-documents azure-ai-evaluation azure-identity python-dotenv pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f4c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import Annotated, Any\n",
    "from uuid import uuid4\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Microsoft Agent Framework\n",
    "from agent_framework import (\n",
    "    AgentRunResponseUpdate,\n",
    "    AgentRunUpdateEvent,\n",
    "    ChatMessage,\n",
    "    Executor,\n",
    "    Role,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "# Azure services\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "# Azure AI Evaluation\n",
    "from azure.ai.evaluation import (\n",
    "    GroundednessEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    RetrievalEvaluator,\n",
    ")\n",
    "\n",
    "# Add parent directory to path for utils\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from utils.search_utils import web_search\n",
    "\n",
    "load_dotenv(override=True)\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e3373f",
   "metadata": {},
   "source": [
    "### Configure Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b9dc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment variables configured\n",
      "  - Azure OpenAI Endpoint: https://hyo-ai-foundry-pjt1-resource.openai.azure.com/\n",
      "  - Chat Deployment: gpt-4.1-mini\n",
      "  - Search Index: hotels-sample-index\n"
     ]
    }
   ],
   "source": [
    "# Azure OpenAI configuration\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_chat_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-08-01-preview\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\", \"text-embedding-ada-002\")\n",
    "\n",
    "# Azure AI Search configuration\n",
    "azure_ai_search_endpoint = os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\")\n",
    "azure_search_admin_key = os.getenv(\"AZURE_AI_SEARCH_API_KEY\", \"\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\", \"hotels-sample-index\")\n",
    "\n",
    "# Model configuration for evaluators\n",
    "model_config = {\n",
    "    \"azure_endpoint\": azure_openai_endpoint,\n",
    "    \"api_key\": azure_openai_key,\n",
    "    \"azure_deployment\": azure_openai_chat_deployment,\n",
    "    \"api_version\": azure_openai_api_version,\n",
    "    \"type\": \"azure_openai\",\n",
    "}\n",
    "\n",
    "print(\"✓ Environment variables configured\")\n",
    "print(f\"  - Azure OpenAI Endpoint: {azure_openai_endpoint}\")\n",
    "print(f\"  - Chat Deployment: {azure_openai_chat_deployment}\")\n",
    "print(f\"  - Search Index: {index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795311d",
   "metadata": {},
   "source": [
    "## 🧪 Step 1: Test and Construct Each Module\n",
    "---\n",
    "\n",
    "Before building the complete workflow, we'll test each component individually:\n",
    "\n",
    "1. **Intent Router**: Classifies query complexity (LLM, RAG, or WebSearch)\n",
    "2. **Retrieval**: Searches Azure AI Search for relevant documents\n",
    "3. **Retrieval Grader**: Evaluates relevance of retrieved documents\n",
    "4. **Question Rewriter**: Optimizes query for better retrieval\n",
    "5. **Answer Generator**: Generates response based on context\n",
    "6. **Groundedness Evaluator**: Checks for hallucinations\n",
    "7. **Relevance Evaluator**: Validates answer relevance\n",
    "8. **Web Search**: Fetches external information when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dceebc",
   "metadata": {},
   "source": [
    "### 1.1 Define Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5944df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data models defined\n"
     ]
    }
   ],
   "source": [
    "# Intent types for routing\n",
    "class IntentType(str, Enum):\n",
    "    LLM = \"LLM\"  # Simple conversation, no retrieval needed\n",
    "    RAG = \"RAG\"  # Requires document retrieval\n",
    "    WEBSEARCH = \"websearch\"  # Requires web search\n",
    "\n",
    "class IntentResponse(BaseModel):\n",
    "    intent_type: IntentType = Field(..., description=\"Detected intent type\")\n",
    "    reasoning: str = Field(..., description=\"Brief explanation of the classification\")\n",
    "\n",
    "# Request/Response structures for workflow\n",
    "@dataclass\n",
    "class ProcessingRequest:\n",
    "    \"\"\"Request passed through the workflow.\"\"\"\n",
    "    request_id: str\n",
    "    query: str\n",
    "    intent: str = \"\"\n",
    "    context: str = \"\"\n",
    "    response: str = \"\"\n",
    "    retrieval_score: float = 0.0\n",
    "    groundedness_score: float = 0.0\n",
    "    relevance_score: float = 0.0\n",
    "\n",
    "@dataclass\n",
    "class ReviewResponse:\n",
    "    \"\"\"Review result from evaluator.\"\"\"\n",
    "    request_id: str\n",
    "    approved: bool\n",
    "    feedback: str\n",
    "    groundedness_score: float = 0.0\n",
    "    relevance_score: float = 0.0\n",
    "\n",
    "print(\"✓ Data models defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1f5011",
   "metadata": {},
   "source": [
    "### 1.2 Test Intent Router\n",
    "\n",
    "The Intent Router analyzes the query and determines the processing path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16af70e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Intent Router:\n",
      "================================================================================\n",
      "\n",
      "Query: Hello, how are you?\n",
      "Intent: IntentType.LLM\n",
      "Reasoning: The query is a casual greeting, which fits the LLM category for casual conversation and greetings.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: Hello, how are you?\n",
      "Intent: IntentType.LLM\n",
      "Reasoning: The query is a casual greeting, which fits the LLM category for casual conversation and greetings.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: Can you recommend hotels with complimentary breakfast?\n",
      "Intent: IntentType.RAG\n",
      "Reasoning: The query asks for hotel recommendations with a specific amenity (complimentary breakfast), which relates to hotel information available until August 2024, fitting the RAG category.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: Can you recommend hotels with complimentary breakfast?\n",
      "Intent: IntentType.RAG\n",
      "Reasoning: The query asks for hotel recommendations with a specific amenity (complimentary breakfast), which relates to hotel information available until August 2024, fitting the RAG category.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: What are the latest hotel openings in NYC in 2025?\n",
      "Intent: IntentType.WEBSEARCH\n",
      "Reasoning: The query is about the latest hotel openings in NYC in 2025, which is beyond the available data range until Aug 2024 and requires current or future information that likely needs websearch to answer accurately.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: What are the latest hotel openings in NYC in 2025?\n",
      "Intent: IntentType.WEBSEARCH\n",
      "Reasoning: The query is about the latest hotel openings in NYC in 2025, which is beyond the available data range until Aug 2024 and requires current or future information that likely needs websearch to answer accurately.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create chat client for testing\n",
    "chat_client = AzureOpenAIChatClient(\n",
    "    model_id=azure_openai_chat_deployment,\n",
    "    endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    api_version=azure_openai_api_version\n",
    ")\n",
    "\n",
    "async def test_intent_router(query: str) -> IntentResponse:\n",
    "    \"\"\"Test intent classification.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"You are an intelligent intent classifier. Classify the query into one of:\n",
    "    \n",
    "- LLM: Casual conversation, greetings, general knowledge (no current info needed)\n",
    "- RAG: Hotel-related questions (data available until Aug 2024)\n",
    "- websearch: Recent events, news, or topics after Aug 2024\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Respond in JSON format with 'intent_type' and 'reasoning'.\"\"\"\n",
    "    \n",
    "    messages = [ChatMessage(role=Role.USER, text=prompt)]\n",
    "    \n",
    "    response = await chat_client.get_response(\n",
    "        messages=messages,\n",
    "        response_format=IntentResponse\n",
    "    )\n",
    "    \n",
    "    result = IntentResponse.model_validate_json(response.messages[-1].text)\n",
    "    return result\n",
    "\n",
    "# Test with different queries\n",
    "test_queries = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"Can you recommend hotels with complimentary breakfast?\",\n",
    "    \"What are the latest hotel openings in NYC in 2025?\"\n",
    "]\n",
    "\n",
    "print(\"Testing Intent Router:\")\n",
    "print(\"=\" * 80)\n",
    "for query in test_queries:\n",
    "    result = await test_intent_router(query)\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"Intent: {result.intent_type}\")\n",
    "    print(f\"Reasoning: {result.reasoning}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169ca5e",
   "metadata": {},
   "source": [
    "### 1.3 Test Retrieval from Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5460187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Retrieval for: 'Can you recommend hotels with complimentary breakfast?'\n",
      "================================================================================\n",
      "\n",
      "Retrieved Documents:\n",
      "Friendly Motor Inn: Close to historic sites, local attractions, and urban parks. Free Shuttle to the airport and casinos. Free breakfast and WiFi. (Tags: 24-hour front desk service, continental breakfast, free wifi)\n",
      "Thunderbird Motel: Book Now & Save. Clean, Comfortable rooms at the lowest price. Enjoy complimentary coffee and tea in common areas. (Tags: coffee in lobby, free parking, free wifi)\n",
      "Lion's Den Inn: Full breakfast buffet for 2 for only $1. Excited to show off our room upgrades, faster high speed WiFi, updated corridors & meeting space. Come relax and enjoy your stay. (Tags: laundry service, free wifi, restaurant)\n",
      "\n",
      "Retrieved Documents:\n",
      "Friendly Motor Inn: Close to historic sites, local attractions, and urban parks. Free Shuttle to the airport and casinos. Free breakfast and WiFi. (Tags: 24-hour front desk service, continental breakfast, free wifi)\n",
      "Thunderbird Motel: Book Now & Save. Clean, Comfortable rooms at the lowest price. Enjoy complimentary coffee and tea in common areas. (Tags: coffee in lobby, free parking, free wifi)\n",
      "Lion's Den Inn: Full breakfast buffet for 2 for only $1. Excited to show off our room upgrades, faster high speed WiFi, updated corridors & meeting space. Come relax and enjoy your stay. (Tags: laundry service, free wifi, restaurant)\n"
     ]
    }
   ],
   "source": [
    "# Create search client\n",
    "search_client = SearchClient(\n",
    "    endpoint=azure_ai_search_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(azure_search_admin_key),\n",
    ")\n",
    "\n",
    "async def test_retrieval(query: str, top_k: int = 3) -> str:\n",
    "    \"\"\"Test document retrieval.\"\"\"\n",
    "    \n",
    "    # Vector search query\n",
    "    vector_query = VectorizableTextQuery(\n",
    "        text=query,\n",
    "        k_nearest_neighbors=top_k,\n",
    "        fields=\"descriptionVector\",\n",
    "        exhaustive=True\n",
    "    )\n",
    "    \n",
    "    # Search\n",
    "    search_results = search_client.search(\n",
    "        search_text=query,\n",
    "        vector_queries=[vector_query],\n",
    "        select=\"Description,HotelName,Tags\",\n",
    "        top=top_k,\n",
    "    )\n",
    "    \n",
    "    # Format results\n",
    "    sources_formatted = \"\\n\".join([\n",
    "        f'{document[\"HotelName\"]}: {document[\"Description\"]} (Tags: {\", \".join(document[\"Tags\"])})'\n",
    "        for document in search_results\n",
    "    ])\n",
    "    \n",
    "    return sources_formatted\n",
    "\n",
    "# Test retrieval\n",
    "test_query = \"Can you recommend hotels with complimentary breakfast?\"\n",
    "print(f\"Testing Retrieval for: '{test_query}'\")\n",
    "print(\"=\" * 80)\n",
    "retrieved_context = await test_retrieval(test_query)\n",
    "print(\"\\nRetrieved Documents:\")\n",
    "print(retrieved_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4990223",
   "metadata": {},
   "source": [
    "### 1.4 Test Retrieval Grader\n",
    "\n",
    "Evaluates if retrieved documents are relevant to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e463e754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieval Evaluation:\n",
      "Score: 5.0\n",
      "Threshold: 3.0 (scores >= 3.0 are acceptable)\n",
      "Result: ✓ PASS\n"
     ]
    }
   ],
   "source": [
    "# Create retrieval evaluator\n",
    "retrieval_eval = RetrievalEvaluator(model_config)\n",
    "\n",
    "# Test retrieval quality\n",
    "query_response = {\n",
    "    \"query\": test_query,\n",
    "    \"context\": retrieved_context\n",
    "}\n",
    "\n",
    "retrieval_score = retrieval_eval(**query_response)\n",
    "print(\"\\nRetrieval Evaluation:\")\n",
    "print(f\"Score: {retrieval_score['retrieval']}\")\n",
    "print(f\"Threshold: 3.0 (scores >= 3.0 are acceptable)\")\n",
    "print(f\"Result: {'✓ PASS' if retrieval_score['retrieval'] >= 3.0 else '✗ FAIL - needs rewrite'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa6377d",
   "metadata": {},
   "source": [
    "### 1.5 Test Question Rewriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d98190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query: Can you recommend a few factories with complimentary breakfast?\n",
      "Rewritten Query: Can you recommend hotels that offer complimentary breakfast?\n",
      "Rewritten Query: Can you recommend hotels that offer complimentary breakfast?\n"
     ]
    }
   ],
   "source": [
    "async def test_question_rewriter(query: str) -> str:\n",
    "    \"\"\"Test query rewriting for better retrieval.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"You are a question re-writer that optimizes queries for vector search.\n",
    "Look at the input and reason about the underlying semantic intent based on hotel domain.\n",
    "Make the query more specific and searchable.\n",
    "\n",
    "Original Query: {query}\n",
    "\n",
    "Rewritten Query:\"\"\"\n",
    "    \n",
    "    messages = [ChatMessage(role=Role.USER, text=prompt)]\n",
    "    response = await chat_client.get_response(messages=messages)\n",
    "    \n",
    "    return response.messages[-1].text.strip()\n",
    "\n",
    "# Test with a poorly worded query\n",
    "poor_query = \"Can you recommend a few factories with complimentary breakfast?\"\n",
    "print(f\"Original Query: {poor_query}\")\n",
    "rewritten = await test_question_rewriter(poor_query)\n",
    "print(f\"Rewritten Query: {rewritten}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8a9e6",
   "metadata": {},
   "source": [
    "### 1.6 Test Answer Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "113f2ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Answer:\n",
      "I recommend Friendly Motor Inn—they offer free breakfast along with free WiFi and a shuttle service. Thunderbird Motel has complimentary coffee and tea but not a full breakfast. Lion's Den Inn has a breakfast buffet for $1, so not completely free.\n"
     ]
    }
   ],
   "source": [
    "async def test_answer_generator(query: str, context: str, intent: str = \"RAG\") -> str:\n",
    "    \"\"\"Test answer generation.\"\"\"\n",
    "    \n",
    "    if intent == \"LLM\":\n",
    "        prompt = f\"\"\"You are a kind and helpful assistant. Answer in a friendly, warm manner.\n",
    "Use emojis appropriately (1-3 per response). Be clear and concise.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    else:  # RAG or websearch\n",
    "        prompt = f\"\"\"Answer using ONLY the context below. Be friendly and concise.\n",
    "If there isn't enough information, say you don't know.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    messages = [ChatMessage(role=Role.USER, text=prompt)]\n",
    "    response = await chat_client.get_response(messages=messages)\n",
    "    \n",
    "    return response.messages[-1].text.strip()\n",
    "\n",
    "# Test answer generation\n",
    "answer = await test_answer_generator(test_query, retrieved_context, \"RAG\")\n",
    "print(f\"\\nGenerated Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6beefd",
   "metadata": {},
   "source": [
    "### 1.7 Test Groundedness and Relevance Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b582fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Groundedness Evaluation (Hallucination Check):\n",
      "Score: 5.0\n",
      "Threshold: 3.0\n",
      "Result: ✓ No hallucinations detected\n",
      "\n",
      "Relevance Evaluation:\n",
      "Score: 4.0\n",
      "Threshold: 3.0\n",
      "Result: ✓ Answer is relevant\n",
      "\n",
      "Relevance Evaluation:\n",
      "Score: 4.0\n",
      "Threshold: 3.0\n",
      "Result: ✓ Answer is relevant\n"
     ]
    }
   ],
   "source": [
    "# Create evaluators\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "\n",
    "# Test groundedness (checks for hallucinations)\n",
    "groundedness_input = {\n",
    "    \"query\": test_query,\n",
    "    \"context\": retrieved_context,\n",
    "    \"response\": answer\n",
    "}\n",
    "groundedness_score = groundedness_eval(**groundedness_input)\n",
    "\n",
    "print(\"\\nGroundedness Evaluation (Hallucination Check):\")\n",
    "print(f\"Score: {groundedness_score['groundedness']}\")\n",
    "print(f\"Threshold: 3.0\")\n",
    "print(f\"Result: {'✓ No hallucinations detected' if groundedness_score['groundedness'] >= 3.0 else '✗ Possible hallucination'}\")\n",
    "\n",
    "# Test relevance\n",
    "relevance_input = {\n",
    "    \"query\": test_query,\n",
    "    \"response\": answer\n",
    "}\n",
    "relevance_score = relevance_eval(**relevance_input)\n",
    "\n",
    "print(\"\\nRelevance Evaluation:\")\n",
    "print(f\"Score: {relevance_score['relevance']}\")\n",
    "print(f\"Threshold: 3.0\")\n",
    "print(f\"Result: {'✓ Answer is relevant' if relevance_score['relevance'] >= 3.0 else '✗ Answer not relevant'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87073c5",
   "metadata": {},
   "source": [
    "### 1.8 Test Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db53803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Web Search for: 'Latest hotel openings in NYC 2025'\n",
      "================================================================================\n",
      "\n",
      "Web Search Results:\n",
      "\n",
      "1. Here are some of the latest hotel openings in New York City for 2025, along with new entries that have recently opened:\n",
      "\n",
      "### Newly Opened Hotels in 2025\n",
      "\n",
      "1. **The Wall Street Hotel by Suiteness**\n",
      "   - **Opened:** June 2025\n",
      "   - **Location:** Near the National September 11 Memorial & Museum\n",
      "   - **Features:** Luxury accommodations with a terrace, restaurant, bar, and free Wi-Fi. Notable nearby landmarks include One World Observatory and Brooklyn Bridge.\n",
      "   - **Rating:** 5 stars【3:0†source】.\n",
      "\n",
      "2. **Faena New York**\n",
      "   - **Expected Opening:** Spring 2025\n",
      "   - **Location:** One High Line’s East Tower\n",
      "   - **Features:** This hotel will feature 120 rooms, a spa, a restaurant by a celebrity chef, and a live entertainment venue, offering views of the High Line and Hudson River【3:1†source】.\n",
      "\n",
      "3. **Kimpton Midtown NYC**\n",
      "   - **Expected Opening:** Late 2025\n",
      "   - **Location:** Rockefeller Center\n",
      "   - **Features:** This property will include 529 guestrooms, two restaurants, a rooftop bar, and a fitness center, along with meeting spaces【3:1†source】.\n",
      "\n",
      "4. **Plaza Athénée Nobu Hotel & Spa**\n",
      "   - **Expected Opening:** 2025\n",
      "   - **Location:** Upper East Side\n",
      "   - **Features:** Comprising 145 guestrooms and suites, the hotel will include a traditional onsen, wellness center, rooftop bar, and Nobu omakase dining【3:1†source】.\n",
      "\n",
      "5. **Xadia Hotel**\n",
      "   - **Expected Opening:** Mid-2025\n",
      "   - **Location:** Bryant Park\n",
      "   - **Features:** A 42-story hotel with 173 rooms, designed with an illuminated crown structure and a remarkable cantilever for impressive views【3:1†source】.\n",
      "\n",
      "### Recently Opened Hotels (2024)\n",
      "\n",
      "1. **Fasano Fifth Avenue I Private Members Club & Hotel**\n",
      "   - **Opened:** November 2024\n",
      "   - **Location:** Near the Museum of Modern Art\n",
      "   - **Features:** This luxury hotel offers a spa, terrace, allergy-free rooms, and a high-end restaurant【3:0†source】.\n",
      "\n",
      "2. **Warren Street Hotel**\n",
      "   - **Opened:** March 2024\n",
      "   - **Location:** Close to One World Observatory\n",
      "   - **Features:** Offers luxurious accommodations with a restaurant, bar, and private parking, along with various amenities for guests【3:0†source】.\n",
      "\n",
      "3. **The Fifth Avenue Hotel**\n",
      "   - **Opened:** August 2023\n",
      "   - **Location:** Near the Flatiron Building\n",
      "   - **Features:** Includes a fitness center, restaurant, and concierge services【3:0†source】.\n",
      "\n",
      "These new openings and upcoming hotels reflect New York City's ongoing evolution within the hospitality industry, boasting luxury amenities and prime locations for visitors. For more detailed information or to check availability, you can visit their respective websites.\n",
      "\n",
      "Web Search Results:\n",
      "\n",
      "1. Here are some of the latest hotel openings in New York City for 2025, along with new entries that have recently opened:\n",
      "\n",
      "### Newly Opened Hotels in 2025\n",
      "\n",
      "1. **The Wall Street Hotel by Suiteness**\n",
      "   - **Opened:** June 2025\n",
      "   - **Location:** Near the National September 11 Memorial & Museum\n",
      "   - **Features:** Luxury accommodations with a terrace, restaurant, bar, and free Wi-Fi. Notable nearby landmarks include One World Observatory and Brooklyn Bridge.\n",
      "   - **Rating:** 5 stars【3:0†source】.\n",
      "\n",
      "2. **Faena New York**\n",
      "   - **Expected Opening:** Spring 2025\n",
      "   - **Location:** One High Line’s East Tower\n",
      "   - **Features:** This hotel will feature 120 rooms, a spa, a restaurant by a celebrity chef, and a live entertainment venue, offering views of the High Line and Hudson River【3:1†source】.\n",
      "\n",
      "3. **Kimpton Midtown NYC**\n",
      "   - **Expected Opening:** Late 2025\n",
      "   - **Location:** Rockefeller Center\n",
      "   - **Features:** This property will include 529 guestrooms, two restaurants, a rooftop bar, and a fitness center, along with meeting spaces【3:1†source】.\n",
      "\n",
      "4. **Plaza Athénée Nobu Hotel & Spa**\n",
      "   - **Expected Opening:** 2025\n",
      "   - **Location:** Upper East Side\n",
      "   - **Features:** Comprising 145 guestrooms and suites, the hotel will include a traditional onsen, wellness center, rooftop bar, and Nobu omakase dining【3:1†source】.\n",
      "\n",
      "5. **Xadia Hotel**\n",
      "   - **Expected Opening:** Mid-2025\n",
      "   - **Location:** Bryant Park\n",
      "   - **Features:** A 42-story hotel with 173 rooms, designed with an illuminated crown structure and a remarkable cantilever for impressive views【3:1†source】.\n",
      "\n",
      "### Recently Opened Hotels (2024)\n",
      "\n",
      "1. **Fasano Fifth Avenue I Private Members Club & Hotel**\n",
      "   - **Opened:** November 2024\n",
      "   - **Location:** Near the Museum of Modern Art\n",
      "   - **Features:** This luxury hotel offers a spa, terrace, allergy-free rooms, and a high-end restaurant【3:0†source】.\n",
      "\n",
      "2. **Warren Street Hotel**\n",
      "   - **Opened:** March 2024\n",
      "   - **Location:** Close to One World Observatory\n",
      "   - **Features:** Offers luxurious accommodations with a restaurant, bar, and private parking, along with various amenities for guests【3:0†source】.\n",
      "\n",
      "3. **The Fifth Avenue Hotel**\n",
      "   - **Opened:** August 2023\n",
      "   - **Location:** Near the Flatiron Building\n",
      "   - **Features:** Includes a fitness center, restaurant, and concierge services【3:0†source】.\n",
      "\n",
      "These new openings and upcoming hotels reflect New York City's ongoing evolution within the hospitality industry, boasting luxury amenities and prime locations for visitors. For more detailed information or to check availability, you can visit their respective websites.\n"
     ]
    }
   ],
   "source": [
    "# Test web search\n",
    "web_query = \"Latest hotel openings in NYC 2025\"\n",
    "print(f\"Testing Web Search for: '{web_query}'\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "web_results = await web_search(\n",
    "    query=web_query,\n",
    "    max_result=3,\n",
    "    web_search_mode=\"bing\"\n",
    ")\n",
    "\n",
    "print(\"\\nWeb Search Results:\")\n",
    "if isinstance(web_results, list):\n",
    "    for i, result in enumerate(web_results, 1):\n",
    "        print(f\"\\n{i}. {result}\")\n",
    "else:\n",
    "    print(web_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3ba21",
   "metadata": {},
   "source": [
    "## 🧪 Step 2: Build the Adaptive RAG Workflow\n",
    "---\n",
    "\n",
    "Now we'll build the complete workflow using Microsoft Agent Framework's Workflow API.\n",
    "The workflow implements a **reflection pattern** where:\n",
    "\n",
    "1. **Worker** generates responses\n",
    "2. **Reviewer** evaluates quality\n",
    "3. If not approved, **Worker** regenerates with feedback\n",
    "4. Only approved responses are returned to the user\n",
    "\n",
    "### Workflow Architecture\n",
    "\n",
    "```\n",
    "User Query\n",
    "    |\n",
    "    v\n",
    "Intent Router\n",
    "    |\n",
    "    +---> LLM Path -------> Generate Answer ---+\n",
    "    |                                           |\n",
    "    +---> RAG Path -------> Retrieve Docs      |\n",
    "    |                           |               |\n",
    "    |                       Grade Quality       |\n",
    "    |                           |               |\n",
    "    |                       [Good/Bad]          |\n",
    "    |                           |               |\n",
    "    |                       Good: Generate      |\n",
    "    |                       Bad: Rewrite Query  |\n",
    "    |                                           |\n",
    "    +---> WebSearch -----> Fetch Web Data ---> |\n",
    "                                                |\n",
    "                                                v\n",
    "                                        Evaluate Quality\n",
    "                                                |\n",
    "                                        [Pass/Fail]\n",
    "                                                |\n",
    "                                        Pass: Return Answer\n",
    "                                        Fail: Retry with Feedback\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574ce595",
   "metadata": {},
   "source": [
    "### 2.1 Define Workflow Executors\n",
    "\n",
    "We'll create two main executors:\n",
    "- **AdaptiveRAGWorker**: Handles query processing and response generation\n",
    "- **ResponseReviewer**: Evaluates response quality and provides feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed366344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ResponseReviewer defined\n"
     ]
    }
   ],
   "source": [
    "class ResponseReviewer(Executor):\n",
    "    \"\"\"Executor that reviews generated responses for quality.\"\"\"\n",
    "    \n",
    "    def __init__(self, id: str, model_config: dict) -> None:\n",
    "        super().__init__(id=id)\n",
    "        self.groundedness_eval = GroundednessEvaluator(model_config)\n",
    "        self.relevance_eval = RelevanceEvaluator(model_config)\n",
    "    \n",
    "    @handler\n",
    "    async def review(self, request: ProcessingRequest, ctx: WorkflowContext[ReviewResponse]) -> None:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Reviewer: Evaluating response for request {request.request_id[:8]}...\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Skip evaluation for LLM-only responses (casual chat)\n",
    "        if request.intent == \"LLM\":\n",
    "            print(\"Reviewer: LLM-only response, auto-approving...\")\n",
    "            await ctx.send_message(\n",
    "                ReviewResponse(\n",
    "                    request_id=request.request_id,\n",
    "                    approved=True,\n",
    "                    feedback=\"LLM response - no evaluation needed\",\n",
    "                    groundedness_score=5.0,\n",
    "                    relevance_score=5.0\n",
    "                )\n",
    "            )\n",
    "            return\n",
    "        \n",
    "        # Evaluate groundedness (check for hallucinations)\n",
    "        groundedness_input = {\n",
    "            \"query\": request.query,\n",
    "            \"context\": request.context,\n",
    "            \"response\": request.response\n",
    "        }\n",
    "        groundedness_result = self.groundedness_eval(**groundedness_input)\n",
    "        groundedness_score = groundedness_result[\"groundedness\"]\n",
    "        \n",
    "        # Evaluate relevance\n",
    "        relevance_input = {\n",
    "            \"query\": request.query,\n",
    "            \"response\": request.response\n",
    "        }\n",
    "        relevance_result = self.relevance_eval(**relevance_input)\n",
    "        relevance_score = relevance_result[\"relevance\"]\n",
    "        \n",
    "        print(f\"Reviewer: Groundedness Score: {groundedness_score:.2f}/5.0\")\n",
    "        print(f\"Reviewer: Relevance Score: {relevance_score:.2f}/5.0\")\n",
    "        \n",
    "        # Determine if response is approved\n",
    "        threshold = 3.0\n",
    "        approved = groundedness_score >= threshold and relevance_score >= threshold\n",
    "        \n",
    "        if approved:\n",
    "            feedback = \"Response is grounded and relevant. Approved.\"\n",
    "            print(f\"Reviewer: ✓ APPROVED - {feedback}\")\n",
    "        else:\n",
    "            feedback_parts = []\n",
    "            if groundedness_score < threshold:\n",
    "                feedback_parts.append(\n",
    "                    f\"Response may contain hallucinations (groundedness: {groundedness_score:.2f}). \"\n",
    "                    \"Ensure all facts come from the provided context.\"\n",
    "                )\n",
    "            if relevance_score < threshold:\n",
    "                feedback_parts.append(\n",
    "                    f\"Response not sufficiently relevant (relevance: {relevance_score:.2f}). \"\n",
    "                    \"Focus more directly on answering the user's question.\"\n",
    "                )\n",
    "            feedback = \" \".join(feedback_parts)\n",
    "            print(f\"Reviewer: ✗ REJECTED - {feedback}\")\n",
    "        \n",
    "        # Send review result\n",
    "        await ctx.send_message(\n",
    "            ReviewResponse(\n",
    "                request_id=request.request_id,\n",
    "                approved=approved,\n",
    "                feedback=feedback,\n",
    "                groundedness_score=groundedness_score,\n",
    "                relevance_score=relevance_score\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(\"✓ ResponseReviewer defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1feef757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ AdaptiveRAGWorker defined\n"
     ]
    }
   ],
   "source": [
    "class AdaptiveRAGWorker(Executor):\n",
    "    \"\"\"Worker executor that processes queries through adaptive RAG pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        id: str,\n",
    "        chat_client: AzureOpenAIChatClient,\n",
    "        search_client: SearchClient,\n",
    "        model_config: dict\n",
    "    ) -> None:\n",
    "        super().__init__(id=id)\n",
    "        self.chat_client = chat_client\n",
    "        self.search_client = search_client\n",
    "        self.retrieval_eval = RetrievalEvaluator(model_config)\n",
    "        self._pending_requests: dict[str, ProcessingRequest] = {}\n",
    "    \n",
    "    @handler\n",
    "    async def process_query(self, user_messages: list[ChatMessage], ctx: WorkflowContext[ProcessingRequest]) -> None:\n",
    "        \"\"\"Main entry point for query processing.\"\"\"\n",
    "        # Extract query text from the last user message\n",
    "        query = user_messages[-1].text if user_messages else \"\"\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Worker: Processing new query\")\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        request = ProcessingRequest(\n",
    "            request_id=str(uuid4()),\n",
    "            query=query\n",
    "        )\n",
    "        \n",
    "        # Step 1: Classify intent\n",
    "        intent = await self._classify_intent(query)\n",
    "        request.intent = intent.intent_type\n",
    "        print(f\"\\nWorker: Intent Classification\")\n",
    "        print(f\"  - Intent: {intent.intent_type}\")\n",
    "        print(f\"  - Reasoning: {intent.reasoning}\")\n",
    "        \n",
    "        # Step 2: Process based on intent\n",
    "        if intent.intent_type == \"LLM\":\n",
    "            # Direct generation without retrieval\n",
    "            await self._generate_llm_response(request, ctx)\n",
    "        elif intent.intent_type == \"RAG\":\n",
    "            # RAG pipeline with quality checks\n",
    "            await self._process_rag_pipeline(request, ctx)\n",
    "        else:  # websearch\n",
    "            # Web search pipeline\n",
    "            await self._process_websearch_pipeline(request, ctx)\n",
    "    \n",
    "    @handler\n",
    "    async def handle_review(self, review: ReviewResponse, ctx: WorkflowContext[ProcessingRequest]) -> None:\n",
    "        \"\"\"Handle review feedback and retry if needed.\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Worker: Received review for request {review.request_id[:8]}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        if review.request_id not in self._pending_requests:\n",
    "            print(f\"Worker: Warning - Unknown request ID {review.request_id[:8]}\")\n",
    "            return\n",
    "        \n",
    "        request = self._pending_requests.pop(review.request_id)\n",
    "        \n",
    "        if review.approved:\n",
    "            print(\"Worker: ✓ Response approved, emitting to user...\")\n",
    "            # Emit approved response to external consumer\n",
    "            await ctx.add_event(\n",
    "                AgentRunUpdateEvent(\n",
    "                    self.id,\n",
    "                    data=AgentRunResponseUpdate(\n",
    "                        contents=[ChatMessage(role=Role.ASSISTANT, text=request.response)],\n",
    "                        role=Role.ASSISTANT\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            print(f\"\\nFinal Response Emitted:\")\n",
    "            print(f\"{'-'*80}\")\n",
    "            print(request.response)\n",
    "            print(f\"{'-'*80}\")\n",
    "        else:\n",
    "            print(f\"Worker: ✗ Response rejected, regenerating with feedback...\")\n",
    "            print(f\"Feedback: {review.feedback}\")\n",
    "            # Regenerate with feedback\n",
    "            await self._regenerate_with_feedback(request, review.feedback, ctx)\n",
    "    \n",
    "    async def _classify_intent(self, query: str) -> IntentResponse:\n",
    "        \"\"\"Classify query intent.\"\"\"\n",
    "        prompt = f\"\"\"You are an intelligent intent classifier. Classify the query into one of:\n",
    "\n",
    "- LLM: Casual conversation, greetings, general knowledge (no current info needed)\n",
    "- RAG: Hotel-related questions (data available until Aug 2024)\n",
    "- websearch: Recent events, news, or topics after Aug 2024\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Respond in JSON format with 'intent_type' and 'reasoning'.\"\"\"\n",
    "        \n",
    "        messages = [ChatMessage(role=Role.USER, text=prompt)]\n",
    "        response = await self.chat_client.get_response(\n",
    "            messages=messages,\n",
    "            response_format=IntentResponse\n",
    "        )\n",
    "        \n",
    "        return IntentResponse.model_validate_json(response.messages[-1].text)\n",
    "    \n",
    "    async def _generate_llm_response(self, request: ProcessingRequest, ctx: WorkflowContext[ProcessingRequest]) -> None:\n",
    "        \"\"\"Generate response without retrieval.\"\"\"\n",
    "        print(f\"\\nWorker: Generating LLM response (no retrieval)...\")\n",
    "        \n",
    "        prompt = f\"\"\"You are a kind and helpful assistant. Answer in a friendly, warm manner.\n",
    "Use emojis appropriately (1-3 per response). Be clear and concise.\n",
    "\n",
    "Query: {request.query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        messages = [ChatMessage(role=Role.USER, text=prompt)]\n",
    "        response = await self.chat_client.get_response(messages=messages)\n",
    "        \n",
    "        request.response = response.messages[-1].text.strip()\n",
    "        print(f\"Worker: Response generated: {request.response[:100]}...\")\n",
    "        \n",
    "        # Store and send for review\n",
    "        self._pending_requests[request.request_id] = request\n",
    "        await ctx.send_message(request)\n",
    "    \n",
    "    async def _process_rag_pipeline(self, request: ProcessingRequest, ctx: WorkflowContext[ProcessingRequest]) -> None:\n",
    "        \"\"\"Process RAG pipeline with retrieval and quality checks.\"\"\"\n",
    "        print(f\"\\nWorker: Starting RAG pipeline...\")\n",
    "        \n",
    "        # Retrieve documents\n",
    "        context = await self._retrieve_documents(request.query)\n",
    "        request.context = context\n",
    "        print(f\"Worker: Retrieved {len(context.split(chr(10)))} documents\")\n",
    "        \n",
    "        # Grade retrieval quality\n",
    "        retrieval_score = self.retrieval_eval(\n",
    "            query=request.query,\n",
    "            context=context\n",
    "        )[\"retrieval\"]\n",
    "        request.retrieval_score = retrieval_score\n",
    "        print(f\"Worker: Retrieval quality score: {retrieval_score:.2f}/5.0\")\n",
    "        \n",
    "        # If retrieval quality is low, rewrite query and retry\n",
    "        if retrieval_score < 3.0:\n",
    "            print(\"Worker: Low retrieval quality, rewriting query...\")\n",
    "            rewritten_query = await self._rewrite_query(request.query)\n",
    "            print(f\"Worker: Rewritten query: {rewritten_query}\")\n",
    "            \n",
    "            # Retry retrieval with rewritten query\n",
    "            context = await self._retrieve_documents(rewritten_query)\n",
    "            request.context = context\n",
    "            print(f\"Worker: Retrieved {len(context.split(chr(10)))} documents (retry)\")\n",
    "        \n",
    "        # Generate answer\n",
    "        await self._generate_rag_response(request, ctx)\n",
    "    \n",
    "    async def _process_websearch_pipeline(self, request: ProcessingRequest, ctx: WorkflowContext[ProcessingRequest]) -> None:\n",
    "        \"\"\"Process web search pipeline.\"\"\"\n",
    "        print(f\"\\nWorker: Starting web search pipeline...\")\n",
    "        \n",
    "        # Rewrite query for web search\n",
    "        search_query = await self._rewrite_for_websearch(request.query)\n",
    "        print(f\"Worker: Web search query: {search_query}\")\n",
    "        \n",
    "        # Perform web search\n",
    "        print(\"Worker: Performing web search...\")\n",
    "        web_results = await web_search(\n",
    "            query=search_query,\n",
    "            max_result=3,\n",
    "            web_search_mode=\"bing\"\n",
    "        )\n",
    "        \n",
    "        # Format web results as context\n",
    "        if isinstance(web_results, list):\n",
    "            request.context = \"\\n\\n\".join([str(result) for result in web_results])\n",
    "        else:\n",
    "            request.context = str(web_results)\n",
    "        \n",
    "        print(f\"Worker: Retrieved web results\")\n",
    "        \n",
    "        # Generate answer with web context\n",
    "        await self._generate_rag_response(request, ctx)\n",
    "    \n",
    "    async def _retrieve_documents(self, query: str) -> str:\n",
    "        \"\"\"Retrieve documents from Azure AI Search.\"\"\"\n",
    "        vector_query = VectorizableTextQuery(\n",
    "            text=query,\n",
    "            k_nearest_neighbors=3,\n",
    "            fields=\"descriptionVector\",\n",
    "            exhaustive=True\n",
    "        )\n",
    "        \n",
    "        search_results = self.search_client.search(\n",
    "            search_text=query,\n",
    "            vector_queries=[vector_query],\n",
    "            select=\"Description,HotelName,Tags\",\n",
    "            top=3,\n",
    "        )\n",
    "        \n",
    "        sources_formatted = \"\\n\".join([\n",
    "            f'{document[\"HotelName\"]}: {document[\"Description\"]} (Tags: {\", \".join(document[\"Tags\"])})'\n",
    "            for document in search_results\n",
    "        ])\n",
    "        \n",
    "        return sources_formatted\n",
    "    \n",
    "    async def _rewrite_query(self, query: str) -> str:\n",
    "        \"\"\"Rewrite query for better retrieval.\"\"\"\n",
    "        prompt = f\"\"\"You are a question re-writer that optimizes queries for vector search.\n",
    "Look at the input and reason about the underlying semantic intent based on hotel domain.\n",
    "Make the query more specific and searchable.\n",
    "\n",
    "Original Query: {query}\n",
    "\n",
    "Rewritten Query:\"\"\"\n",
    "        \n",
    "        messages = [ChatMessage(role=Role.USER, text=prompt)]\n",
    "        response = await self.chat_client.get_response(messages=messages)\n",
    "        \n",
    "        return response.messages[-1].text.strip()\n",
    "    \n",
    "    async def _rewrite_for_websearch(self, query: str) -> str:\n",
    "        \"\"\"Rewrite query as web search keywords.\"\"\"\n",
    "        prompt = f\"\"\"You are a keyword re-writer that converts queries to web search keywords.\n",
    "Generate search keywords that are specific and detailed for accurate web search results.\n",
    "Don't include extra context like location or date.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Search Keywords:\"\"\"\n",
    "        \n",
    "        messages = [ChatMessage(role=Role.USER, text=prompt)]\n",
    "        response = await self.chat_client.get_response(messages=messages)\n",
    "        \n",
    "        return response.messages[-1].text.strip()\n",
    "    \n",
    "    async def _generate_rag_response(self, request: ProcessingRequest, ctx: WorkflowContext[ProcessingRequest]) -> None:\n",
    "        \"\"\"Generate response with retrieval context.\"\"\"\n",
    "        print(f\"\\nWorker: Generating response with context...\")\n",
    "        \n",
    "        prompt = f\"\"\"Answer using ONLY the context below. Be friendly and concise.\n",
    "If there isn't enough information, say you don't know.\n",
    "\n",
    "Query: {request.query}\n",
    "\n",
    "Context:\n",
    "{request.context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        messages = [ChatMessage(role=Role.USER, text=prompt)]\n",
    "        response = await self.chat_client.get_response(messages=messages)\n",
    "        \n",
    "        request.response = response.messages[-1].text.strip()\n",
    "        print(f\"Worker: Response generated: {request.response[:100]}...\")\n",
    "        \n",
    "        # Store and send for review\n",
    "        self._pending_requests[request.request_id] = request\n",
    "        await ctx.send_message(request)\n",
    "    \n",
    "    async def _regenerate_with_feedback(self, request: ProcessingRequest, feedback: str, ctx: WorkflowContext[ProcessingRequest]) -> None:\n",
    "        \"\"\"Regenerate response incorporating feedback.\"\"\"\n",
    "        print(f\"\\nWorker: Regenerating response with feedback...\")\n",
    "        \n",
    "        prompt = f\"\"\"Previous response had issues. Please improve based on feedback.\n",
    "\n",
    "Query: {request.query}\n",
    "\n",
    "Context:\n",
    "{request.context}\n",
    "\n",
    "Previous Response:\n",
    "{request.response}\n",
    "\n",
    "Feedback:\n",
    "{feedback}\n",
    "\n",
    "Improved Answer:\"\"\"\n",
    "        \n",
    "        messages = [ChatMessage(role=Role.USER, text=prompt)]\n",
    "        response = await self.chat_client.get_response(messages=messages)\n",
    "        \n",
    "        request.response = response.messages[-1].text.strip()\n",
    "        print(f\"Worker: New response generated: {request.response[:100]}...\")\n",
    "        \n",
    "        # Store and send for re-review\n",
    "        self._pending_requests[request.request_id] = request\n",
    "        await ctx.send_message(request)\n",
    "\n",
    "print(\"✓ AdaptiveRAGWorker defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ffbf6",
   "metadata": {},
   "source": [
    "### 2.2 Build and Run the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5525104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Workflow runner defined\n"
     ]
    }
   ],
   "source": [
    "async def run_adaptive_rag_workflow(query: str):\n",
    "    \"\"\"Run the adaptive RAG workflow with reflection pattern.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"# Starting Adaptive RAG Workflow\")\n",
    "    print(f\"# Query: {query}\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    # Create chat client\n",
    "    chat_client = AzureOpenAIChatClient(\n",
    "        model_id=azure_openai_chat_deployment,\n",
    "        endpoint=azure_openai_endpoint,\n",
    "        api_key=azure_openai_key,\n",
    "        api_version=azure_openai_api_version\n",
    "    )\n",
    "    \n",
    "    # Create search client\n",
    "    search_client = SearchClient(\n",
    "        endpoint=azure_ai_search_endpoint,\n",
    "        index_name=index_name,\n",
    "        credential=AzureKeyCredential(azure_search_admin_key),\n",
    "    )\n",
    "    \n",
    "    # Create executors\n",
    "    worker = AdaptiveRAGWorker(\n",
    "        id=\"adaptive_rag_worker\",\n",
    "        chat_client=chat_client,\n",
    "        search_client=search_client,\n",
    "        model_config=model_config\n",
    "    )\n",
    "    \n",
    "    reviewer = ResponseReviewer(\n",
    "        id=\"response_reviewer\",\n",
    "        model_config=model_config\n",
    "    )\n",
    "    \n",
    "    # Build workflow with reflection pattern\n",
    "    print(\"\\nBuilding workflow with Worker ↔ Reviewer cycle...\")\n",
    "    agent = (\n",
    "        WorkflowBuilder()\n",
    "        .add_edge(worker, reviewer)  # Worker sends responses to Reviewer\n",
    "        .add_edge(reviewer, worker)  # Reviewer sends feedback to Worker\n",
    "        .set_start_executor(worker)\n",
    "        .build()\n",
    "        .as_agent()  # Wrap workflow as an agent\n",
    "    )\n",
    "    \n",
    "    print(\"Workflow built successfully!\")\n",
    "    print(\"\\nRunning workflow...\\n\")\n",
    "    \n",
    "    # Run the workflow\n",
    "    async for event in agent.run_stream(query):\n",
    "        # Only final approved responses will be emitted\n",
    "        if event.text:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"FINAL APPROVED RESPONSE:\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(event.text)\n",
    "            print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(\"\\n✓ Workflow completed successfully!\")\n",
    "\n",
    "print(\"✓ Workflow runner defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe5c24",
   "metadata": {},
   "source": [
    "## 🧪 Step 3: Test the Complete Workflow\n",
    "---\n",
    "\n",
    "Let's test the workflow with different types of queries to see adaptive routing in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea111bc5",
   "metadata": {},
   "source": [
    "### Test 1: Simple LLM Query (No Retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6f707b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "# Starting Adaptive RAG Workflow\n",
      "# Query: Hello! How are you today?\n",
      "################################################################################\n",
      "\n",
      "Building workflow with Worker ↔ Reviewer cycle...\n",
      "Workflow built successfully!\n",
      "\n",
      "Running workflow...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Worker: Processing new query\n",
      "Query: Hello! How are you today?\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Worker: Intent Classification\n",
      "  - Intent: IntentType.LLM\n",
      "  - Reasoning: The query 'Hello! How are you today?' is a casual greeting unrelated to hotels or recent events, thus best classified under LLM.\n",
      "\n",
      "Worker: Generating LLM response (no retrieval)...\n",
      "Worker: Response generated: Hello! I’m doing great, thank you for asking 😊 How about you? Hope you’re having a wonderful day! 🌟...\n",
      "\n",
      "================================================================================\n",
      "Reviewer: Evaluating response for request dfd4ae53...\n",
      "================================================================================\n",
      "Reviewer: LLM-only response, auto-approving...\n",
      "\n",
      "================================================================================\n",
      "Worker: Received review for request dfd4ae53\n",
      "================================================================================\n",
      "Worker: ✓ Response approved, emitting to user...\n",
      "\n",
      "Final Response Emitted:\n",
      "--------------------------------------------------------------------------------\n",
      "Hello! I’m doing great, thank you for asking 😊 How about you? Hope you’re having a wonderful day! 🌟\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Workflow completed successfully!\n",
      "Worker: Response generated: Hello! I’m doing great, thank you for asking 😊 How about you? Hope you’re having a wonderful day! 🌟...\n",
      "\n",
      "================================================================================\n",
      "Reviewer: Evaluating response for request dfd4ae53...\n",
      "================================================================================\n",
      "Reviewer: LLM-only response, auto-approving...\n",
      "\n",
      "================================================================================\n",
      "Worker: Received review for request dfd4ae53\n",
      "================================================================================\n",
      "Worker: ✓ Response approved, emitting to user...\n",
      "\n",
      "Final Response Emitted:\n",
      "--------------------------------------------------------------------------------\n",
      "Hello! I’m doing great, thank you for asking 😊 How about you? Hope you’re having a wonderful day! 🌟\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Workflow completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test with a simple conversational query\n",
    "await run_adaptive_rag_workflow(\"Hello! How are you today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b9a05e",
   "metadata": {},
   "source": [
    "### Test 2: RAG Query (Hotel Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1cb4cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "# Starting Adaptive RAG Workflow\n",
      "# Query: Can you recommend hotels with complimentary breakfast in downtown area?\n",
      "################################################################################\n",
      "\n",
      "Building workflow with Worker ↔ Reviewer cycle...\n",
      "Workflow built successfully!\n",
      "\n",
      "Running workflow...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Worker: Processing new query\n",
      "Query: Can you recommend hotels with complimentary breakfast in downtown area?\n",
      "================================================================================\n",
      "\n",
      "Worker: Intent Classification\n",
      "  - Intent: IntentType.RAG\n",
      "  - Reasoning: The query is about hotel recommendations with complimentary breakfast in a specific area, which is hotel-related and suitable for Retrieval-Augmented Generation using data available until Aug 2024.\n",
      "\n",
      "Worker: Starting RAG pipeline...\n",
      "\n",
      "Worker: Intent Classification\n",
      "  - Intent: IntentType.RAG\n",
      "  - Reasoning: The query is about hotel recommendations with complimentary breakfast in a specific area, which is hotel-related and suitable for Retrieval-Augmented Generation using data available until Aug 2024.\n",
      "\n",
      "Worker: Starting RAG pipeline...\n",
      "Worker: Retrieved 3 documents\n",
      "Worker: Retrieved 3 documents\n",
      "Worker: Retrieval quality score: 4.00/5.0\n",
      "\n",
      "Worker: Generating response with context...\n",
      "Worker: Retrieval quality score: 4.00/5.0\n",
      "\n",
      "Worker: Generating response with context...\n",
      "Worker: Response generated: I recommend the Friendly Motor Inn for complimentary breakfast in the downtown area. It offers free ...\n",
      "\n",
      "================================================================================\n",
      "Reviewer: Evaluating response for request a853df54...\n",
      "================================================================================\n",
      "Worker: Response generated: I recommend the Friendly Motor Inn for complimentary breakfast in the downtown area. It offers free ...\n",
      "\n",
      "================================================================================\n",
      "Reviewer: Evaluating response for request a853df54...\n",
      "================================================================================\n",
      "Reviewer: Groundedness Score: 3.00/5.0\n",
      "Reviewer: Relevance Score: 4.00/5.0\n",
      "Reviewer: ✓ APPROVED - Response is grounded and relevant. Approved.\n",
      "\n",
      "================================================================================\n",
      "Worker: Received review for request a853df54\n",
      "================================================================================\n",
      "Worker: ✓ Response approved, emitting to user...\n",
      "\n",
      "Final Response Emitted:\n",
      "--------------------------------------------------------------------------------\n",
      "I recommend the Friendly Motor Inn for complimentary breakfast in the downtown area. It offers free breakfast and WiFi and is close to local attractions. The Treehouse Hotel and City Center Summer Wind Resort don’t mention free breakfast.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Workflow completed successfully!\n",
      "Reviewer: Groundedness Score: 3.00/5.0\n",
      "Reviewer: Relevance Score: 4.00/5.0\n",
      "Reviewer: ✓ APPROVED - Response is grounded and relevant. Approved.\n",
      "\n",
      "================================================================================\n",
      "Worker: Received review for request a853df54\n",
      "================================================================================\n",
      "Worker: ✓ Response approved, emitting to user...\n",
      "\n",
      "Final Response Emitted:\n",
      "--------------------------------------------------------------------------------\n",
      "I recommend the Friendly Motor Inn for complimentary breakfast in the downtown area. It offers free breakfast and WiFi and is close to local attractions. The Treehouse Hotel and City Center Summer Wind Resort don’t mention free breakfast.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Workflow completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test with a hotel-related query\n",
    "await run_adaptive_rag_workflow(\"Can you recommend hotels with complimentary breakfast in downtown area?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c75001",
   "metadata": {},
   "source": [
    "### Test 3: Web Search Query (Recent Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ea0891d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "# Starting Adaptive RAG Workflow\n",
      "# Query: What are the latest hotel openings in New York City in 2025?\n",
      "################################################################################\n",
      "\n",
      "Building workflow with Worker ↔ Reviewer cycle...\n",
      "Workflow built successfully!\n",
      "\n",
      "Running workflow...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Worker: Processing new query\n",
      "Query: What are the latest hotel openings in New York City in 2025?\n",
      "================================================================================\n",
      "\n",
      "Worker: Intent Classification\n",
      "  - Intent: IntentType.WEBSEARCH\n",
      "  - Reasoning: The query asks for the latest hotel openings in New York City in 2025, which is a future event beyond the available data until August 2024, so current or future web search is needed.\n",
      "\n",
      "Worker: Starting web search pipeline...\n",
      "\n",
      "Worker: Intent Classification\n",
      "  - Intent: IntentType.WEBSEARCH\n",
      "  - Reasoning: The query asks for the latest hotel openings in New York City in 2025, which is a future event beyond the available data until August 2024, so current or future web search is needed.\n",
      "\n",
      "Worker: Starting web search pipeline...\n",
      "Worker: Web search query: latest hotel openings New York City 2025 new hotels opening NYC 2025 new hotel launches New York 2025 upcoming hotels NYC 2025\n",
      "Worker: Performing web search...\n",
      "Worker: Web search query: latest hotel openings New York City 2025 new hotels opening NYC 2025 new hotel launches New York 2025 upcoming hotels NYC 2025\n",
      "Worker: Performing web search...\n",
      "Worker: Retrieved web results\n",
      "\n",
      "Worker: Generating response with context...\n",
      "Worker: Response generated: The latest hotel openings in New York City for 2025 include:\n",
      "\n",
      "- **Voco Astoria** (August 2025) in As...\n",
      "\n",
      "================================================================================\n",
      "Reviewer: Evaluating response for request b1af887f...\n",
      "================================================================================\n",
      "Reviewer: Groundedness Score: 5.00/5.0\n",
      "Reviewer: Relevance Score: 4.00/5.0\n",
      "Reviewer: ✓ APPROVED - Response is grounded and relevant. Approved.\n",
      "\n",
      "================================================================================\n",
      "Worker: Received review for request b1af887f\n",
      "================================================================================\n",
      "Worker: ✓ Response approved, emitting to user...\n",
      "\n",
      "Final Response Emitted:\n",
      "--------------------------------------------------------------------------------\n",
      "The latest hotel openings in New York City for 2025 include:\n",
      "\n",
      "- **Voco Astoria** (August 2025) in Astoria, with pet-friendly modern rooms, restaurant, gym, and business center.\n",
      "- **Hyatt Regency Times Square** (July 2025), offering 795 renovated rooms, a restaurant, gym, and free internet.\n",
      "- **Waldorf Astoria New York** (July 2025), a restored historic luxury hotel on Park Avenue.\n",
      "- **Faena New York** (September 2025) in the One High Line development with luxury accommodations and wellness amenities.\n",
      "- **The Westin Flushing LaGuardia Airport** (June 2025), featuring an indoor pool, restaurant, and airport shuttle.\n",
      "- **The Wall Street Hotel by Suiteness** (June 2025), near the 9/11 Memorial with luxury rooms and dining options.\n",
      "\n",
      "Upcoming is **voco Times Square**, expected to open on December 1, 2025, offering modern stays in Times Square.\n",
      "\n",
      "Let me know if you want details on any of these!\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Workflow completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test with a query requiring web search\n",
    "await run_adaptive_rag_workflow(\"What are the latest hotel openings in New York City in 2025?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754a7b7c",
   "metadata": {},
   "source": [
    "### Test 4: Query with Poor Retrieval (Tests Rewriting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bf01e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "# Starting Adaptive RAG Workflow\n",
      "# Query: Can you recommend some factories with free breakfast?\n",
      "################################################################################\n",
      "\n",
      "Building workflow with Worker ↔ Reviewer cycle...\n",
      "Workflow built successfully!\n",
      "\n",
      "Running workflow...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Worker: Processing new query\n",
      "Query: Can you recommend some factories with free breakfast?\n",
      "================================================================================\n",
      "\n",
      "Worker: Intent Classification\n",
      "  - Intent: IntentType.RAG\n",
      "  - Reasoning: The query is related to requesting recommendations for factories offering free breakfast, which is similar to hotel-related questions involving amenities and services. Such queries fit the RAG category with data availability until August 2024.\n",
      "\n",
      "Worker: Starting RAG pipeline...\n",
      "\n",
      "Worker: Intent Classification\n",
      "  - Intent: IntentType.RAG\n",
      "  - Reasoning: The query is related to requesting recommendations for factories offering free breakfast, which is similar to hotel-related questions involving amenities and services. Such queries fit the RAG category with data availability until August 2024.\n",
      "\n",
      "Worker: Starting RAG pipeline...\n",
      "Worker: Retrieved 3 documents\n",
      "Worker: Retrieved 3 documents\n",
      "Worker: Retrieval quality score: 1.00/5.0\n",
      "Worker: Low retrieval quality, rewriting query...\n",
      "Worker: Retrieval quality score: 1.00/5.0\n",
      "Worker: Low retrieval quality, rewriting query...\n",
      "Worker: Rewritten query: Which hotels offer free breakfast and have on-site factory or workshop facilities?\n",
      "Worker: Rewritten query: Which hotels offer free breakfast and have on-site factory or workshop facilities?\n",
      "Worker: Retrieved 3 documents (retry)\n",
      "\n",
      "Worker: Generating response with context...\n",
      "Worker: Retrieved 3 documents (retry)\n",
      "\n",
      "Worker: Generating response with context...\n",
      "Worker: Response generated: I don’t have information about any factories with free breakfast. However, the Friendly Motor Inn of...\n",
      "\n",
      "================================================================================\n",
      "Reviewer: Evaluating response for request ad3fc736...\n",
      "================================================================================\n",
      "Worker: Response generated: I don’t have information about any factories with free breakfast. However, the Friendly Motor Inn of...\n",
      "\n",
      "================================================================================\n",
      "Reviewer: Evaluating response for request ad3fc736...\n",
      "================================================================================\n",
      "Reviewer: Groundedness Score: 2.00/5.0\n",
      "Reviewer: Relevance Score: 3.00/5.0\n",
      "Reviewer: ✗ REJECTED - Response may contain hallucinations (groundedness: 2.00). Ensure all facts come from the provided context.\n",
      "\n",
      "================================================================================\n",
      "Worker: Received review for request ad3fc736\n",
      "================================================================================\n",
      "Worker: ✗ Response rejected, regenerating with feedback...\n",
      "Feedback: Response may contain hallucinations (groundedness: 2.00). Ensure all facts come from the provided context.\n",
      "\n",
      "Worker: Regenerating response with feedback...\n",
      "Reviewer: Groundedness Score: 2.00/5.0\n",
      "Reviewer: Relevance Score: 3.00/5.0\n",
      "Reviewer: ✗ REJECTED - Response may contain hallucinations (groundedness: 2.00). Ensure all facts come from the provided context.\n",
      "\n",
      "================================================================================\n",
      "Worker: Received review for request ad3fc736\n",
      "================================================================================\n",
      "Worker: ✗ Response rejected, regenerating with feedback...\n",
      "Feedback: Response may contain hallucinations (groundedness: 2.00). Ensure all facts come from the provided context.\n",
      "\n",
      "Worker: Regenerating response with feedback...\n",
      "Worker: New response generated: Based on the information you provided, the Friendly Motor Inn offers free breakfast. The other optio...\n",
      "\n",
      "================================================================================\n",
      "Reviewer: Evaluating response for request ad3fc736...\n",
      "================================================================================\n",
      "Worker: New response generated: Based on the information you provided, the Friendly Motor Inn offers free breakfast. The other optio...\n",
      "\n",
      "================================================================================\n",
      "Reviewer: Evaluating response for request ad3fc736...\n",
      "================================================================================\n",
      "Reviewer: Groundedness Score: 5.00/5.0\n",
      "Reviewer: Relevance Score: 4.00/5.0\n",
      "Reviewer: ✓ APPROVED - Response is grounded and relevant. Approved.\n",
      "\n",
      "================================================================================\n",
      "Worker: Received review for request ad3fc736\n",
      "================================================================================\n",
      "Worker: ✓ Response approved, emitting to user...\n",
      "\n",
      "Final Response Emitted:\n",
      "--------------------------------------------------------------------------------\n",
      "Based on the information you provided, the Friendly Motor Inn offers free breakfast. The other options mentioned do not specify free breakfast. If you are specifically looking for factories with free breakfast, there is no information available in the context about any factories offering that.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Workflow completed successfully!\n",
      "Reviewer: Groundedness Score: 5.00/5.0\n",
      "Reviewer: Relevance Score: 4.00/5.0\n",
      "Reviewer: ✓ APPROVED - Response is grounded and relevant. Approved.\n",
      "\n",
      "================================================================================\n",
      "Worker: Received review for request ad3fc736\n",
      "================================================================================\n",
      "Worker: ✓ Response approved, emitting to user...\n",
      "\n",
      "Final Response Emitted:\n",
      "--------------------------------------------------------------------------------\n",
      "Based on the information you provided, the Friendly Motor Inn offers free breakfast. The other options mentioned do not specify free breakfast. If you are specifically looking for factories with free breakfast, there is no information available in the context about any factories offering that.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Workflow completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test with a poorly worded query to trigger query rewriting\n",
    "await run_adaptive_rag_workflow(\"Can you recommend some factories with free breakfast?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271c39e",
   "metadata": {},
   "source": [
    "## 📊 Summary\n",
    "---\n",
    "\n",
    "In this notebook, we implemented **Adaptive RAG** using Microsoft Agent Framework with the following features:\n",
    "\n",
    "### ✅ Key Components\n",
    "\n",
    "1. **Intent Classification**: Automatically routes queries to LLM, RAG, or Web Search\n",
    "2. **Retrieval with Quality Check**: Grades retrieved documents and rewrites queries if needed\n",
    "3. **Web Search Integration**: Fetches recent information when documents are outdated\n",
    "4. **Reflection Pattern**: Evaluates responses for quality and regenerates if needed\n",
    "5. **Quality Evaluators**: Uses Azure Evaluation SDK for:\n",
    "   - Retrieval quality assessment\n",
    "   - Groundedness checking (hallucination detection)\n",
    "   - Relevance validation\n",
    "\n",
    "### 🔄 Workflow Architecture\n",
    "\n",
    "- **Worker Executor**: Handles query processing, retrieval, and generation\n",
    "- **Reviewer Executor**: Evaluates response quality and provides feedback\n",
    "- **Cyclic Flow**: Worker ↔ Reviewer loop ensures high-quality outputs\n",
    "- **Event-Driven**: Only approved responses are emitted to users\n",
    "\n",
    "### 🎯 Benefits\n",
    "\n",
    "- **Adaptive**: Automatically selects the right processing strategy\n",
    "- **Robust**: Self-correcting through reflection and retry\n",
    "- **Transparent**: Detailed logging of decision-making process\n",
    "- **Scalable**: Workflow-based architecture easy to extend\n",
    "\n",
    "### 🔗 Learn More\n",
    "\n",
    "- [Microsoft Agent Framework Documentation](https://learn.microsoft.com/en-us/agent-framework/)\n",
    "- [Azure AI Search](https://learn.microsoft.com/en-us/azure/search/)\n",
    "- [Azure AI Evaluation SDK](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/evaluate-sdk)\n",
    "- [Adaptive RAG Paper](https://arxiv.org/abs/2403.14403)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_agentlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
